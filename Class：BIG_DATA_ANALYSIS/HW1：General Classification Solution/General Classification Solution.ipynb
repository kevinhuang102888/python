{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52ba4605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cedcad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#切資料/評估工具\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83c29267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#方法集\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dc88ac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv(\".\\\\data\\\\income_evaluation.csv\")\n",
    "data2_train=pd.read_csv(\".\\\\data\\\\arcene_train.data\",sep=\" \",header=None)\n",
    "data2_valid=pd.read_csv(\".\\\\data\\\\arcene_valid.data\",sep=\" \",header=None)\n",
    "data2_train_label=pd.read_csv(\".\\\\data\\\\arcene_train.labels\",sep=\" \",header=None)\n",
    "data2_valid_label=pd.read_csv(\".\\\\data\\\\arcene_valid.labels\",sep=\" \",header=None)\n",
    "data2_label=data2_train_label.append(data2_valid_label)\n",
    "data2_all=data2_train.append(data2_valid).dropna(axis='columns')\n",
    "data2=pd.concat([data2_all,data2_label],axis=1)\n",
    "data2.columns=[x for x in range(0,10001)]\n",
    "data3=pd.read_csv(\".\\\\data\\\\bank_all.csv\")\n",
    "data4=pd.read_csv(\".\\\\data\\\\Telco-Customer-Churn.csv\")\n",
    "data5=pd.read_csv(\".\\\\data\\\\online_shoppers_intention.csv\")\n",
    "data6=pd.read_csv(\".\\\\data\\\\Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcac11e",
   "metadata": {},
   "source": [
    "# 資料1：Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8f4e53de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype\n",
      "---  ------           --------------  -----\n",
      " 0   age              32561 non-null  int64\n",
      " 1    workclass       32561 non-null  int32\n",
      " 2    fnlwgt          32561 non-null  int64\n",
      " 3    education       32561 non-null  int32\n",
      " 4    education-num   32561 non-null  int64\n",
      " 5    marital-status  32561 non-null  int32\n",
      " 6    occupation      32561 non-null  int32\n",
      " 7    relationship    32561 non-null  int32\n",
      " 8    race            32561 non-null  int32\n",
      " 9    sex             32561 non-null  int32\n",
      " 10   capital-gain    32561 non-null  int64\n",
      " 11   capital-loss    32561 non-null  int64\n",
      " 12   hours-per-week  32561 non-null  int64\n",
      " 13   native-country  32561 non-null  int32\n",
      " 14   income          32561 non-null  int32\n",
      "dtypes: int32(9), int64(6)\n",
      "memory usage: 2.6 MB\n"
     ]
    }
   ],
   "source": [
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bbccb32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', ' workclass', ' fnlwgt', ' education', ' education-num',\n",
       "       ' marital-status', ' occupation', ' relationship', ' race', ' sex',\n",
       "       ' capital-gain', ' capital-loss', ' hours-per-week', ' native-country',\n",
       "       ' income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "be02cd4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24720\n",
       "1     7841\n",
       "Name:  income, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[\" income\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2cad15a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pie(data1[\" income\"].value_counts(), textprops = {\"fontsize\" : 10},autopct = \"%1.1f%%\")  \n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left',labels =data1[\" income\"].value_counts().index) \n",
    "plt.title('Dataset1 : Income', {\"fontsize\" : 18})\n",
    "plt.text(-1.2, -1.2, \"total:32561\",{\"fontsize\" : 12 })\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "57a10465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>77516</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>83311</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>215646</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>234721</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>338409</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   workclass   fnlwgt   education   education-num   marital-status  \\\n",
       "0   39           7    77516           9              13                4   \n",
       "1   50           6    83311           9              13                2   \n",
       "2   38           4   215646          11               9                0   \n",
       "3   53           4   234721           1               7                2   \n",
       "4   28           4   338409           9              13                2   \n",
       "\n",
       "    occupation   relationship   race   sex   capital-gain   capital-loss  \\\n",
       "0            1              1      4     1           2174              0   \n",
       "1            4              0      4     1              0              0   \n",
       "2            6              1      4     1              0              0   \n",
       "3            6              0      2     1              0              0   \n",
       "4           10              5      2     0              0              0   \n",
       "\n",
       "    hours-per-week   native-country   income  \n",
       "0               40               39        0  \n",
       "1               13               39        0  \n",
       "2               40               39        0  \n",
       "3               40               39        0  \n",
       "4               40                5        0  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "65bd1217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "data1[\" workclass\"]=labelencoder.fit_transform(data1[\" workclass\"])\n",
    "data1[\" education\"]=labelencoder.fit_transform(data1[\" education\"])\n",
    "data1[\" marital-status\"]=labelencoder.fit_transform(data1[\" marital-status\"])\n",
    "data1[\" occupation\"]=labelencoder.fit_transform(data1[\" occupation\"])\n",
    "data1[\" relationship\"]=labelencoder.fit_transform(data1[\" relationship\"])\n",
    "data1[\" race\"]=labelencoder.fit_transform(data1[\" race\"])\n",
    "data1[\" sex\"]=labelencoder.fit_transform(data1[\" sex\"])\n",
    "data1[\" native-country\"]=labelencoder.fit_transform(data1[\" native-country\"])\n",
    "data1[\" income\"]=labelencoder.fit_transform(data1[\" income\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d3da839d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype\n",
      "---  ------           --------------  -----\n",
      " 0   age              32561 non-null  int64\n",
      " 1    workclass       32561 non-null  int64\n",
      " 2    fnlwgt          32561 non-null  int64\n",
      " 3    education       32561 non-null  int64\n",
      " 4    education-num   32561 non-null  int64\n",
      " 5    marital-status  32561 non-null  int64\n",
      " 6    occupation      32561 non-null  int64\n",
      " 7    relationship    32561 non-null  int64\n",
      " 8    race            32561 non-null  int64\n",
      " 9    sex             32561 non-null  int64\n",
      " 10   capital-gain    32561 non-null  int64\n",
      " 11   capital-loss    32561 non-null  int64\n",
      " 12   hours-per-week  32561 non-null  int64\n",
      " 13   native-country  32561 non-null  int64\n",
      " 14   income          32561 non-null  int64\n",
      "dtypes: int64(15)\n",
      "memory usage: 3.7 MB\n"
     ]
    }
   ],
   "source": [
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0df8f217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>77516</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>83311</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>215646</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>234721</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>338409</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   workclass   fnlwgt   education   education-num   marital-status  \\\n",
       "0   39           7    77516           9              13                4   \n",
       "1   50           6    83311           9              13                2   \n",
       "2   38           4   215646          11               9                0   \n",
       "3   53           4   234721           1               7                2   \n",
       "4   28           4   338409           9              13                2   \n",
       "\n",
       "    occupation   relationship   race   sex   capital-gain   capital-loss  \\\n",
       "0            1              1      4     1           2174              0   \n",
       "1            4              0      4     1              0              0   \n",
       "2            6              1      4     1              0              0   \n",
       "3            6              0      2     1              0              0   \n",
       "4           10              5      2     0              0              0   \n",
       "\n",
       "    hours-per-week   native-country   income  \n",
       "0               40               39        0  \n",
       "1               13               39        0  \n",
       "2               40               39        0  \n",
       "3               40               39        0  \n",
       "4               40                5        0  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ffbd246b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training dataset: (24420, 15)\n",
      "Size of testing dataset: (8141, 15)\n"
     ]
    }
   ],
   "source": [
    "#切割資料，train:test=0.75:0.25\n",
    "train_data,test_data,train_labels,test_labels=train_test_split(data1,data1[\" income\"],test_size=0.25)\n",
    "print('Size of training dataset:', train_data.shape)\n",
    "print('Size of testing dataset:', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6d17ba72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.7792654465053434\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Create the model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Learn on the train subset\n",
    "knn.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the testing subset\n",
    "predicted = knn.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = knn.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "25d34549",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_knn=np.append (predicted,accuracy)\n",
    "predicted_knn=pd.DataFrame(predicted_knn)\n",
    "predicted_knn.to_csv('.\\\\predict data\\\\predicted_knn_1_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4c209ca6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.789952094337305\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Create the model\n",
    "lm = LogisticRegression(solver=\"lbfgs\")\n",
    "\n",
    "# Learn on the train subset\n",
    "lm.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the testing subset\n",
    "predicted =lm.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = lm.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "4edfb39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_LM=np.append (predicted,accuracy)\n",
    "predicted_LM=pd.DataFrame(predicted_LM)\n",
    "predicted_LM.to_csv('.\\\\predict data\\\\predicted_LM_1_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "82d9a307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Create the model\n",
    "RF = RandomForestClassifier()\n",
    "\n",
    "# Learn on the train subset\n",
    "RF.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the testing subset\n",
    "predicted =RF.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = RF.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e80ef3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_RF=np.append (predicted,accuracy)\n",
    "predicted_RF=pd.DataFrame(predicted_RF)\n",
    "predicted_RF.to_csv('.\\\\predict data\\\\predicted_RF_1_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "8820fa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.7936371453138436\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# Create the model\n",
    "MLP = MLPClassifier()\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "MLP.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted_MLP = MLP.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy =  MLP.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c735790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_MLP=np.append (predicted,accuracy)\n",
    "predicted_MLP=pd.DataFrame(predicted_MLP)\n",
    "predicted_MLP.to_csv('.\\\\predict data\\\\predicted_MLP_1_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "140fec59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.7940056504114974\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# Create the model\n",
    "svc = svm.SVC()\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "svc.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted_svc = svc.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = svc.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4f32bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_svc=np.append (predicted,accuracy)\n",
    "predicted_svc=pd.DataFrame(predicted_svc)\n",
    "predicted_svc.to_csv('.\\\\predict data\\\\predicted_svc_1_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "349984cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:36:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy of testing dataset:  1.0\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# Create the model\n",
    "XGB = XGBClassifier()\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "XGB.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted_XGB = XGB.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = XGB.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "df9f419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_XGB=np.append (predicted,accuracy)\n",
    "predicted_XGB=pd.DataFrame(predicted_XGB)\n",
    "predicted_XGB.to_csv('.\\\\predict data\\\\predicted_XGB_1_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "381e60f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.1271623\ttotal: 3.34ms\tremaining: 30.1ms\n",
      "1:\tlearn: 0.0427476\ttotal: 6.33ms\tremaining: 25.3ms\n",
      "2:\tlearn: 0.0153458\ttotal: 9.02ms\tremaining: 21.1ms\n",
      "3:\tlearn: 0.0056773\ttotal: 11.7ms\tremaining: 17.6ms\n",
      "4:\tlearn: 0.0021587\ttotal: 14.4ms\tremaining: 14.4ms\n",
      "5:\tlearn: 0.0008761\ttotal: 17.7ms\tremaining: 11.8ms\n",
      "6:\tlearn: 0.0003980\ttotal: 20.9ms\tremaining: 8.98ms\n",
      "7:\tlearn: 0.0001942\ttotal: 24.3ms\tremaining: 6.09ms\n",
      "8:\tlearn: 0.0001125\ttotal: 27.8ms\tremaining: 3.09ms\n",
      "9:\tlearn: 0.0000758\ttotal: 31.2ms\tremaining: 0us\n",
      "Accuracy of testing dataset:  1.0\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "# Create the model\n",
    "CAT = CatBoostClassifier(iterations=10,\n",
    "              learning_rate=1,\n",
    "              depth=2,\n",
    "              loss_function='MultiClass')\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "CAT.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = CAT.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = CAT.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ce53eca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_CAT=np.append (predicted,accuracy)\n",
    "predicted_CAT=pd.DataFrame(predicted_CAT)\n",
    "predicted_CAT.to_csv('.\\\\predict data\\\\predicted_CAT_1_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "9d838bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "Accuracy of testing dataset:  1.0\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "# Create the model\n",
    "LGBM = lgb.LGBMClassifier(application='multiclass', boosting='gbdt', learning_rate=0.1, max_depth=-5, feature_fraction=0.5, random_state=42)\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "LGBM.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = LGBM.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy =LGBM.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "6722cb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_LGBM=np.append (predicted,accuracy)\n",
    "predicted_LGBM=pd.DataFrame(predicted_LGBM)\n",
    "predicted_LGBM.to_csv('.\\\\predict data\\\\predicted_LGBM_1_4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c7a940",
   "metadata": {},
   "source": [
    "# 資料2：Arcene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83bc2349",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9991</th>\n",
       "      <th>9992</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9996</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "      <th>10000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>538</td>\n",
       "      <td>404</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>570</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>524</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>82</td>\n",
       "      <td>165</td>\n",
       "      <td>60</td>\n",
       "      <td>554</td>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>605</td>\n",
       "      <td>69</td>\n",
       "      <td>7</td>\n",
       "      <td>473</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>423</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>402</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>593</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>508</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>44</td>\n",
       "      <td>275</td>\n",
       "      <td>14</td>\n",
       "      <td>511</td>\n",
       "      <td>470</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>348</td>\n",
       "      <td>0</td>\n",
       "      <td>268</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>354</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0      0     71      0     95      0    538    404     20      0      0  ...   \n",
       "1      0     41     82    165     60    554    379      0     71      0  ...   \n",
       "2      0      0      1     40      0    451    402      0      0      0  ...   \n",
       "3      0     56     44    275     14    511    470      0      0      0  ...   \n",
       "4    105      0    141    348      0    268    329      0      0      1  ...   \n",
       "\n",
       "   9991   9992   9993   9994   9995   9996   9997   9998   9999   10000  \n",
       "0    570     86      0     36      0     80      0      0    524      1  \n",
       "1    605     69      7    473      0     57      0    284    423     -1  \n",
       "2    593     28      0     24      0     90      0     34    508      1  \n",
       "3    600      0     26     86      0    102      0      0    469      1  \n",
       "4      0      0      0      0    190    301      0      0    354     -1  \n",
       "\n",
       "[5 rows x 10001 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a81df071",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    112\n",
       " 1     88\n",
       "Name: 10000, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.iloc[:,-1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e932c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pie(data2.iloc[:,-1].value_counts(), textprops = {\"fontsize\" : 10},autopct = \"%1.1f%%\")  \n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left',labels =data2.iloc[:,-1].value_counts().index) \n",
    "plt.title('Dataset2 : Arcene', {\"fontsize\" : 18})\n",
    "plt.text(-1.2, -1.2, \"total:100\",{\"fontsize\" : 12 })\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26bfd8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.columns=[x for x in range(0,10001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e07c438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training dataset: (150, 10001)\n",
      "Size of testing dataset: (50, 10001)\n"
     ]
    }
   ],
   "source": [
    "#切割資料，train:test=0.75:0.25\n",
    "train_data,test_data,train_labels,test_labels=train_test_split(data2,data2.iloc[:,-1],test_size=0.25)\n",
    "print('Size of training dataset:', train_data.shape)\n",
    "print('Size of testing dataset:', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c88b2fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Create the model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Learn on the train subset\n",
    "knn.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the testing subset\n",
    "predicted = knn.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = knn.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "562bb248",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Create the model\n",
    "lm = LogisticRegression(solver=\"lbfgs\")\n",
    "\n",
    "# Learn on the train subset\n",
    "lm.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the testing subset\n",
    "predicted =lm.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = lm.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3072120f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Create the model\n",
    "RF = RandomForestRegressor()\n",
    "\n",
    "# Learn on the train subset\n",
    "RF.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the testing subset\n",
    "predicted =RF.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = RF.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e65a6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# Create the model\n",
    "MLP = MLPClassifier()\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "MLP.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = MLP.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy =  MLP.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e36d226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.72\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# Create the model\n",
    "svc = svm.SVC()\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "svc.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = svc.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = svc.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9760d1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:55:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy of testing dataset:  1.0\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# Create the model\n",
    "XGB = XGBClassifier()\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "XGB.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = XGB.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = XGB.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fcc6defe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.1639927\ttotal: 91.1ms\tremaining: 820ms\n",
      "1:\tlearn: 0.0658755\ttotal: 133ms\tremaining: 534ms\n",
      "2:\tlearn: 0.0339619\ttotal: 174ms\tremaining: 406ms\n",
      "3:\tlearn: 0.0212341\ttotal: 219ms\tremaining: 328ms\n",
      "4:\tlearn: 0.0146798\ttotal: 260ms\tremaining: 260ms\n",
      "5:\tlearn: 0.0112006\ttotal: 303ms\tremaining: 202ms\n",
      "6:\tlearn: 0.0089871\ttotal: 364ms\tremaining: 156ms\n",
      "7:\tlearn: 0.0074643\ttotal: 422ms\tremaining: 106ms\n",
      "8:\tlearn: 0.0063680\ttotal: 469ms\tremaining: 52.1ms\n",
      "9:\tlearn: 0.0055453\ttotal: 511ms\tremaining: 0us\n",
      "Accuracy of testing dataset:  1.0\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "# Create the model\n",
    "CAT = CatBoostClassifier(iterations=10,\n",
    "              learning_rate=1,\n",
    "              depth=2,\n",
    "              loss_function='MultiClass')\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "CAT.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = CAT.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = CAT.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c1f009a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "Accuracy of testing dataset:  1.0\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "# Create the model\n",
    "LGBM = lgb.LGBMClassifier(application='multiclass', boosting='gbdt', learning_rate=0.1, max_depth=-5, feature_fraction=0.5, random_state=42)\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "LGBM.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = LGBM.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy =LGBM.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f7fc86",
   "metadata": {},
   "source": [
    "# 資料3：Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6dc1b054",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  int64 \n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   default    45211 non-null  object\n",
      " 5   balance    45211 non-null  int64 \n",
      " 6   housing    45211 non-null  object\n",
      " 7   loan       45211 non-null  object\n",
      " 8   contact    45211 non-null  object\n",
      " 9   day        45211 non-null  int64 \n",
      " 10  month      45211 non-null  object\n",
      " 11  duration   45211 non-null  int64 \n",
      " 12  campaign   45211 non-null  int64 \n",
      " 13  pdays      45211 non-null  int64 \n",
      " 14  previous   45211 non-null  int64 \n",
      " 15  poutcome   45211 non-null  object\n",
      " 16  y          45211 non-null  object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70121805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
       "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
       "       'previous', 'poutcome', 'y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13a0cb73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     39922\n",
       "yes     5289\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3[\"y\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d605e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pie(data3[\"y\"].value_counts(), textprops = {\"fontsize\" : 10},autopct = \"%1.1f%%\")  \n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left',labels =data3[\"y\"].value_counts().index) \n",
    "plt.title('Dataset3 : Bank', {\"fontsize\" : 18})\n",
    "plt.text(-1.2, -1.2, \"total:45211\",{\"fontsize\" : 12 })\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8495984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "data3['job']=labelencoder.fit_transform(data3['job'])\n",
    "data3['marital']=labelencoder.fit_transform(data3['marital'])\n",
    "data3[\"education\"]=labelencoder.fit_transform(data3[\"education\"])\n",
    "data3[\"default\"]=labelencoder.fit_transform(data3[\"default\"])\n",
    "data3[\"housing\"]=labelencoder.fit_transform(data3[\"housing\"])\n",
    "data3[\"loan\"]=labelencoder.fit_transform(data3[\"loan\"])\n",
    "data3[\"contact\"]=labelencoder.fit_transform(data3[\"contact\"])\n",
    "data3[\"month\"]=labelencoder.fit_transform(data3[\"month\"])\n",
    "data3[\"poutcome\"]=labelencoder.fit_transform(data3[\"poutcome\"])\n",
    "data3[\"y\"]=labelencoder.fit_transform(data3[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27fbabe6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype\n",
      "---  ------     --------------  -----\n",
      " 0   age        45211 non-null  int64\n",
      " 1   job        45211 non-null  int32\n",
      " 2   marital    45211 non-null  int32\n",
      " 3   education  45211 non-null  int32\n",
      " 4   default    45211 non-null  int32\n",
      " 5   balance    45211 non-null  int64\n",
      " 6   housing    45211 non-null  int32\n",
      " 7   loan       45211 non-null  int32\n",
      " 8   contact    45211 non-null  int32\n",
      " 9   day        45211 non-null  int64\n",
      " 10  month      45211 non-null  int32\n",
      " 11  duration   45211 non-null  int64\n",
      " 12  campaign   45211 non-null  int64\n",
      " 13  pdays      45211 non-null  int64\n",
      " 14  previous   45211 non-null  int64\n",
      " 15  poutcome   45211 non-null  int32\n",
      " 16  y          45211 non-null  int32\n",
      "dtypes: int32(10), int64(7)\n",
      "memory usage: 4.1 MB\n"
     ]
    }
   ],
   "source": [
    "data3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de940d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1506</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  balance  housing  loan  contact  \\\n",
       "0   58    4        1          2        0     2143        1     0        2   \n",
       "1   44    9        2          1        0       29        1     0        2   \n",
       "2   33    2        1          1        0        2        1     1        2   \n",
       "3   47    1        1          3        0     1506        1     0        2   \n",
       "4   33   11        2          3        0        1        0     0        2   \n",
       "\n",
       "   day  month  duration  campaign  pdays  previous  poutcome  y  \n",
       "0    5      8       261         1     -1         0         3  0  \n",
       "1    5      8       151         1     -1         0         3  0  \n",
       "2    5      8        76         1     -1         0         3  0  \n",
       "3    5      8        92         1     -1         0         3  0  \n",
       "4    5      8       198         1     -1         0         3  0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4fd99ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training dataset: (33908, 17)\n",
      "Size of testing dataset: (11303, 17)\n"
     ]
    }
   ],
   "source": [
    "#切割資料，train:test=0.75:0.25\n",
    "train_data,test_data,train_labels,test_labels=train_test_split(data3,data3[\"y\"],test_size=0.25)\n",
    "print('Size of training dataset:', train_data.shape)\n",
    "print('Size of testing dataset:', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df691ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.8783508802972663\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Create the model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Learn on the train subset\n",
    "knn.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the testing subset\n",
    "predicted = knn.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = knn.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1025891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.9404582854109529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Create the model\n",
    "lm = LogisticRegression(solver=\"lbfgs\")\n",
    "\n",
    "# Learn on the train subset\n",
    "lm.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the testing subset\n",
    "predicted =lm.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = lm.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a9a0b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Create the model\n",
    "RF = RandomForestRegressor()\n",
    "\n",
    "# Learn on the train subset\n",
    "RF.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the testing subset\n",
    "predicted =RF.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = RF.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7726e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.9997345837388304\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# Create the model\n",
    "MLP = MLPClassifier()\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "MLP.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = MLP.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy =  MLP.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca2c20dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.8817128196054145\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# Create the model\n",
    "svc = svm.SVC()\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "svc.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = svc.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = svc.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b63346cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:56:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  1.0\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# Create the model\n",
    "XGB = XGBClassifier()\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "XGB.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = XGB.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = XGB.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ebbe34aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.1270967\ttotal: 41.1ms\tremaining: 370ms\n",
      "1:\tlearn: 0.0426955\ttotal: 47.6ms\tremaining: 190ms\n",
      "2:\tlearn: 0.0153144\ttotal: 53.6ms\tremaining: 125ms\n",
      "3:\tlearn: 0.0056273\ttotal: 60.3ms\tremaining: 90.5ms\n",
      "4:\tlearn: 0.0021112\ttotal: 66.2ms\tremaining: 66.2ms\n",
      "5:\tlearn: 0.0008320\ttotal: 72.1ms\tremaining: 48.1ms\n",
      "6:\tlearn: 0.0003592\ttotal: 78ms\tremaining: 33.4ms\n",
      "7:\tlearn: 0.0001722\ttotal: 82.9ms\tremaining: 20.7ms\n",
      "8:\tlearn: 0.0000974\ttotal: 87.8ms\tremaining: 9.76ms\n",
      "9:\tlearn: 0.0000642\ttotal: 92.8ms\tremaining: 0us\n",
      "Accuracy of testing dataset:  1.0\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "# Create the model\n",
    "CAT = CatBoostClassifier(iterations=10,\n",
    "              learning_rate=1,\n",
    "              depth=2,\n",
    "              loss_function='MultiClass')\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "CAT.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = CAT.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = CAT.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7c6f4839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "Accuracy of testing dataset:  1.0\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "# Create the model\n",
    "LGBM = lgb.LGBMClassifier(application='multiclass', boosting='gbdt', learning_rate=0.1, max_depth=-5, feature_fraction=0.5, random_state=42)\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "LGBM.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = LGBM.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy =LGBM.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace72dec",
   "metadata": {},
   "source": [
    "# 資料4：BlastChar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1f53c85b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   gender            7043 non-null   object \n",
      " 2   SeniorCitizen     7043 non-null   int64  \n",
      " 3   Partner           7043 non-null   object \n",
      " 4   Dependents        7043 non-null   object \n",
      " 5   tenure            7043 non-null   int64  \n",
      " 6   PhoneService      7043 non-null   object \n",
      " 7   MultipleLines     7043 non-null   object \n",
      " 8   InternetService   7043 non-null   object \n",
      " 9   OnlineSecurity    7043 non-null   object \n",
      " 10  OnlineBackup      7043 non-null   object \n",
      " 11  DeviceProtection  7043 non-null   object \n",
      " 12  TechSupport       7043 non-null   object \n",
      " 13  StreamingTV       7043 non-null   object \n",
      " 14  StreamingMovies   7043 non-null   object \n",
      " 15  Contract          7043 non-null   object \n",
      " 16  PaperlessBilling  7043 non-null   object \n",
      " 17  PaymentMethod     7043 non-null   object \n",
      " 18  MonthlyCharges    7043 non-null   float64\n",
      " 19  TotalCharges      7043 non-null   object \n",
      " 20  Churn             7043 non-null   object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "481f9e61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     5174\n",
       "Yes    1869\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data4[\"Churn\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c4640a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pie(data4[\"Churn\"].value_counts(), textprops = {\"fontsize\" : 10},autopct = \"%1.1f%%\")  \n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left',labels =data4[\"Churn\"].value_counts().index) \n",
    "plt.title('Dataset4 : BlastChar', {\"fontsize\" : 18})\n",
    "plt.text(-1.2, -1.2, \"total:7043\",{\"fontsize\" : 12 })\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cdb694f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
       "       'tenure', 'PhoneService', 'MultipleLines', 'InternetService',\n",
       "       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
       "       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
       "       'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ad113c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "data4['customerID']=labelencoder.fit_transform(data4['customerID'])\n",
    "data4['gender']=labelencoder.fit_transform(data4['gender'])\n",
    "data4['Partner']=labelencoder.fit_transform(data4['Partner'])\n",
    "data4['Dependents']=labelencoder.fit_transform(data4['Dependents'])\n",
    "data4['PhoneService']=labelencoder.fit_transform(data4['PhoneService'])\n",
    "data4['MultipleLines']=labelencoder.fit_transform(data4['MultipleLines'])\n",
    "data4['InternetService']=labelencoder.fit_transform(data4['InternetService'])\n",
    "data4['OnlineSecurity']=labelencoder.fit_transform(data4['OnlineSecurity'])\n",
    "data4['OnlineBackup']=labelencoder.fit_transform(data4['OnlineBackup'])\n",
    "data4['DeviceProtection']=labelencoder.fit_transform(data4['DeviceProtection'])\n",
    "data4['TechSupport']=labelencoder.fit_transform(data4['TechSupport'])\n",
    "data4['DeviceProtection']=labelencoder.fit_transform(data4['DeviceProtection'])\n",
    "data4['StreamingTV']=labelencoder.fit_transform(data4['StreamingTV'])\n",
    "data4['StreamingMovies']=labelencoder.fit_transform(data4['StreamingMovies'])\n",
    "data4['Contract']=labelencoder.fit_transform(data4['Contract'])\n",
    "data4['PaperlessBilling']=labelencoder.fit_transform(data4['PaperlessBilling'])\n",
    "data4['PaymentMethod']=labelencoder.fit_transform(data4['PaymentMethod'])\n",
    "data4['TotalCharges']=labelencoder.fit_transform(data4['TotalCharges'])\n",
    "data4['Churn']=labelencoder.fit_transform(data4['Churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8393baa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29.85</td>\n",
       "      <td>2505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3962</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2564</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>53.85</td>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5535</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6511</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>70.70</td>\n",
       "      <td>925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen  Partner  Dependents  tenure  \\\n",
       "0        5375       0              0        1           0       1   \n",
       "1        3962       1              0        0           0      34   \n",
       "2        2564       1              0        0           0       2   \n",
       "3        5535       1              0        0           0      45   \n",
       "4        6511       0              0        0           0       2   \n",
       "\n",
       "   PhoneService  MultipleLines  InternetService  OnlineSecurity  ...  \\\n",
       "0             0              1                0               0  ...   \n",
       "1             1              0                0               2  ...   \n",
       "2             1              0                0               2  ...   \n",
       "3             0              1                0               2  ...   \n",
       "4             1              0                1               0  ...   \n",
       "\n",
       "   DeviceProtection  TechSupport  StreamingTV  StreamingMovies  Contract  \\\n",
       "0                 0            0            0                0         0   \n",
       "1                 2            0            0                0         1   \n",
       "2                 0            0            0                0         0   \n",
       "3                 2            2            0                0         1   \n",
       "4                 0            0            0                0         0   \n",
       "\n",
       "   PaperlessBilling  PaymentMethod  MonthlyCharges  TotalCharges  Churn  \n",
       "0                 1              2           29.85          2505      0  \n",
       "1                 0              3           56.95          1466      0  \n",
       "2                 1              3           53.85           157      1  \n",
       "3                 0              0           42.30          1400      0  \n",
       "4                 1              2           70.70           925      1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7bb0739f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training dataset: (5282, 21)\n",
      "Size of testing dataset: (1761, 21)\n"
     ]
    }
   ],
   "source": [
    "#切割資料，train:test=0.75:0.25\n",
    "train_data,test_data,train_labels,test_labels=train_test_split(data4,data4[\"Churn\"],test_size=0.25)\n",
    "print('Size of training dataset:', train_data.shape)\n",
    "print('Size of testing dataset:', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0fd39c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.6842703009653606\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Create the model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Learn on the train subset\n",
    "knn.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the testing subset\n",
    "predicted = knn.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = knn.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6e718603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.9943214082907439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Create the model\n",
    "lm = LogisticRegression(solver=\"lbfgs\")\n",
    "\n",
    "# Learn on the train subset\n",
    "lm.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the testing subset\n",
    "predicted =lm.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = lm.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4cbeebab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Create the model\n",
    "RF = RandomForestRegressor()\n",
    "\n",
    "# Learn on the train subset\n",
    "RF.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the testing subset\n",
    "predicted =RF.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = RF.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8564e92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.9647927314026121\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# Create the model\n",
    "MLP = MLPClassifier()\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "MLP.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = MLP.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy =  MLP.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b9fabca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.7331061896649631\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# Create the model\n",
    "svc = svm.SVC()\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "svc.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = svc.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = svc.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5f6f4488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:56:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy of testing dataset:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# Create the model\n",
    "XGB = XGBClassifier()\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "XGB.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = XGB.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = XGB.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b50370f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.1280103\ttotal: 2.17ms\tremaining: 19.6ms\n",
      "1:\tlearn: 0.0433946\ttotal: 3.97ms\tremaining: 15.9ms\n",
      "2:\tlearn: 0.0159271\ttotal: 5.64ms\tremaining: 13.2ms\n",
      "3:\tlearn: 0.0062041\ttotal: 7.11ms\tremaining: 10.7ms\n",
      "4:\tlearn: 0.0026121\ttotal: 9.35ms\tremaining: 9.35ms\n",
      "5:\tlearn: 0.0012609\ttotal: 11ms\tremaining: 7.32ms\n",
      "6:\tlearn: 0.0007170\ttotal: 12.6ms\tremaining: 5.39ms\n",
      "7:\tlearn: 0.0004732\ttotal: 14.1ms\tremaining: 3.53ms\n",
      "8:\tlearn: 0.0003457\ttotal: 15.6ms\tremaining: 1.73ms\n",
      "9:\tlearn: 0.0002702\ttotal: 17.5ms\tremaining: 0us\n",
      "Accuracy of testing dataset:  1.0\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "# Create the model\n",
    "CAT = CatBoostClassifier(iterations=10,\n",
    "              learning_rate=1,\n",
    "              depth=2,\n",
    "              loss_function='MultiClass')\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "CAT.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = CAT.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = CAT.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5a0a8ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "Accuracy of testing dataset:  1.0\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "# Create the model\n",
    "LGBM = lgb.LGBMClassifier(application='multiclass', boosting='gbdt', learning_rate=0.1, max_depth=-5, feature_fraction=0.5, random_state=42)\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "LGBM.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = LGBM.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy =LGBM.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df16c08",
   "metadata": {},
   "source": [
    "# 資料5：Shoppers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "19a75dae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12330 entries, 0 to 12329\n",
      "Data columns (total 18 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Administrative           12330 non-null  int64  \n",
      " 1   Administrative_Duration  12330 non-null  float64\n",
      " 2   Informational            12330 non-null  int64  \n",
      " 3   Informational_Duration   12330 non-null  float64\n",
      " 4   ProductRelated           12330 non-null  int64  \n",
      " 5   ProductRelated_Duration  12330 non-null  float64\n",
      " 6   BounceRates              12330 non-null  float64\n",
      " 7   ExitRates                12330 non-null  float64\n",
      " 8   PageValues               12330 non-null  float64\n",
      " 9   SpecialDay               12330 non-null  float64\n",
      " 10  Month                    12330 non-null  object \n",
      " 11  OperatingSystems         12330 non-null  int64  \n",
      " 12  Browser                  12330 non-null  int64  \n",
      " 13  Region                   12330 non-null  int64  \n",
      " 14  TrafficType              12330 non-null  int64  \n",
      " 15  VisitorType              12330 non-null  object \n",
      " 16  Weekend                  12330 non-null  bool   \n",
      " 17  Revenue                  12330 non-null  bool   \n",
      "dtypes: bool(2), float64(7), int64(7), object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a5dca63e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    10422\n",
       "True      1908\n",
       "Name: Revenue, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data5[\"Revenue\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3d1f80cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pie(data5[\"Revenue\"].value_counts(), textprops = {\"fontsize\" : 10},autopct = \"%1.1f%%\")  \n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left',labels =data5[\"Revenue\"].value_counts().index) \n",
    "plt.title('Dataset5 : Shoppers', {\"fontsize\" : 18})\n",
    "plt.text(-1.2, -1.2, \"total:12330\",{\"fontsize\" : 12 })\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "72c92f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Administrative', 'Administrative_Duration', 'Informational',\n",
       "       'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration',\n",
       "       'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay', 'Month',\n",
       "       'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType',\n",
       "       'Weekend', 'Revenue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data5.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0598c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "data5['SpecialDay']=labelencoder.fit_transform(data5['SpecialDay'])\n",
    "data5['Month']=labelencoder.fit_transform(data5['Month'])\n",
    "data5['VisitorType']=labelencoder.fit_transform(data5['VisitorType'])\n",
    "data5['Weekend']=labelencoder.fit_transform(data5['Weekend'])\n",
    "data5['Revenue']=labelencoder.fit_transform(data5['Revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8b975d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                 0.000000   \n",
       "1                     0.0               2                64.000000   \n",
       "2                     0.0               1                 0.000000   \n",
       "3                     0.0               2                 2.666667   \n",
       "4                     0.0              10               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay  Month  OperatingSystems  \\\n",
       "0         0.20       0.20         0.0           0      2                 1   \n",
       "1         0.00       0.10         0.0           0      2                 2   \n",
       "2         0.20       0.20         0.0           0      2                 4   \n",
       "3         0.05       0.14         0.0           0      2                 3   \n",
       "4         0.02       0.05         0.0           0      2                 3   \n",
       "\n",
       "   Browser  Region  TrafficType  VisitorType  Weekend  Revenue  \n",
       "0        1       1            1            2        0        0  \n",
       "1        2       1            2            2        0        0  \n",
       "2        1       9            3            2        0        0  \n",
       "3        2       2            4            2        0        0  \n",
       "4        3       1            4            2        1        0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6344c18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training dataset: (9247, 18)\n",
      "Size of testing dataset: (3083, 18)\n"
     ]
    }
   ],
   "source": [
    "#切割資料，train:test=0.75:0.25\n",
    "train_data,test_data,train_labels,test_labels=train_test_split(data5,data5['Revenue'],test_size=0.25)\n",
    "print('Size of training dataset:', train_data.shape)\n",
    "print('Size of testing dataset:', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cfa80ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.8679857281868311\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Create the model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Learn on the train subset\n",
    "knn.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the testing subset\n",
    "predicted = knn.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = knn.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "44664b1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.8910152448913397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Create the model\n",
    "lm = LogisticRegression(solver=\"lbfgs\")\n",
    "\n",
    "# Learn on the train subset\n",
    "lm.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the testing subset\n",
    "predicted =lm.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = lm.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4fb744d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Create the model\n",
    "RF = RandomForestRegressor()\n",
    "\n",
    "# Learn on the train subset\n",
    "RF.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the testing subset\n",
    "predicted =RF.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = RF.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "12d30062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.9928640934155044\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# Create the model\n",
    "MLP = MLPClassifier()\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "MLP.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = MLP.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy =  MLP.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8916b873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.8456049302627311\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# Create the model\n",
    "svc = svm.SVC()\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "svc.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = svc.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = svc.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a6c295b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:56:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy of testing dataset:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# Create the model\n",
    "XGB = XGBClassifier()\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "XGB.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = XGB.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = XGB.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1d140cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.1275464\ttotal: 2.58ms\tremaining: 23.2ms\n",
      "1:\tlearn: 0.0430443\ttotal: 5.04ms\tremaining: 20.2ms\n",
      "2:\tlearn: 0.0155053\ttotal: 7.23ms\tremaining: 16.9ms\n",
      "3:\tlearn: 0.0058253\ttotal: 9.57ms\tremaining: 14.4ms\n",
      "4:\tlearn: 0.0023431\ttotal: 11.8ms\tremaining: 11.8ms\n",
      "5:\tlearn: 0.0010253\ttotal: 14.1ms\tremaining: 9.41ms\n",
      "6:\tlearn: 0.0004772\ttotal: 16.7ms\tremaining: 7.17ms\n",
      "7:\tlearn: 0.0002940\ttotal: 19.2ms\tremaining: 4.79ms\n",
      "8:\tlearn: 0.0001857\ttotal: 21.6ms\tremaining: 2.4ms\n",
      "9:\tlearn: 0.0001317\ttotal: 24ms\tremaining: 0us\n",
      "Accuracy of testing dataset:  1.0\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "# Create the model\n",
    "CAT = CatBoostClassifier(iterations=10,\n",
    "              learning_rate=1,\n",
    "              depth=2,\n",
    "              loss_function='MultiClass')\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "CAT.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = CAT.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = CAT.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "57282221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "Accuracy of testing dataset:  1.0\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "# Create the model\n",
    "LGBM = lgb.LGBMClassifier(application='multiclass', boosting='gbdt', learning_rate=0.1, max_depth=-5, feature_fraction=0.5, random_state=42)\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "LGBM.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = LGBM.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy =LGBM.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe7f4dc",
   "metadata": {},
   "source": [
    "# 資料6：Shrutime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5598887f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data6.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cf78616e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data6[\"Exited\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f895df87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pie(data6[\"Exited\"].value_counts(), textprops = {\"fontsize\" : 10},autopct = \"%1.1f%%\")  \n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left',labels =data6[\"Exited\"].value_counts().index) \n",
    "plt.title('Dataset6 : Shrutime', {\"fontsize\" : 18})\n",
    "plt.text(-1.2, -1.2, \"total:10000\",{\"fontsize\" : 12 })\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aa0f03c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
       "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data6.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f7a28522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "data6['Surname']=labelencoder.fit_transform(data6['Surname'])\n",
    "data6['Geography']=labelencoder.fit_transform(data6['Geography'])\n",
    "data6['Gender']=labelencoder.fit_transform(data6['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ea586be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>1115</td>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>1177</td>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>2040</td>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>289</td>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>1822</td>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId  Surname  CreditScore  Geography  Gender  Age  \\\n",
       "0          1    15634602     1115          619          0       0   42   \n",
       "1          2    15647311     1177          608          2       0   41   \n",
       "2          3    15619304     2040          502          0       0   42   \n",
       "3          4    15701354      289          699          0       0   39   \n",
       "4          5    15737888     1822          850          2       0   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "30fa54b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training dataset: (7500, 14)\n",
      "Size of testing dataset: (2500, 14)\n"
     ]
    }
   ],
   "source": [
    "#切割資料，train:test=0.75:0.25\n",
    "train_data,test_data,train_labels,test_labels=train_test_split(data6,data6['Exited'],test_size=0.25)\n",
    "print('Size of training dataset:', train_data.shape)\n",
    "print('Size of testing dataset:', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5479393d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.7672\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Create the model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Learn on the train subset\n",
    "knn.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the testing subset\n",
    "predicted = knn.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = knn.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "284bd332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.7968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Create the model\n",
    "lm = LogisticRegression(solver=\"lbfgs\")\n",
    "\n",
    "# Learn on the train subset\n",
    "lm.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the testing subset\n",
    "predicted =lm.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = lm.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d64517ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Create the model\n",
    "RF = RandomForestRegressor()\n",
    "\n",
    "# Learn on the train subset\n",
    "RF.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the testing subset\n",
    "predicted =RF.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = RF.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a13f21fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.7968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# Create the model\n",
    "MLP = MLPClassifier()\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "MLP.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = MLP.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy =  MLP.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "96bbe1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of testing dataset:  0.7968\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# Create the model\n",
    "svc = svm.SVC()\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "svc.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = svc.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = svc.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b421b38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:56:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy of testing dataset:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# Create the model\n",
    "XGB = XGBClassifier()\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "XGB.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = XGB.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = XGB.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "61c3cae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.1276904\ttotal: 1.94ms\tremaining: 17.5ms\n",
      "1:\tlearn: 0.0431548\ttotal: 3.81ms\tremaining: 15.2ms\n",
      "2:\tlearn: 0.0156862\ttotal: 5.75ms\tremaining: 13.4ms\n",
      "3:\tlearn: 0.0059991\ttotal: 7.55ms\tremaining: 11.3ms\n",
      "4:\tlearn: 0.0024683\ttotal: 9.36ms\tremaining: 9.36ms\n",
      "5:\tlearn: 0.0011452\ttotal: 11.1ms\tremaining: 7.42ms\n",
      "6:\tlearn: 0.0005990\ttotal: 12.9ms\tremaining: 5.54ms\n",
      "7:\tlearn: 0.0003699\ttotal: 14.7ms\tremaining: 3.68ms\n",
      "8:\tlearn: 0.0002277\ttotal: 16.4ms\tremaining: 1.82ms\n",
      "9:\tlearn: 0.0001798\ttotal: 18.1ms\tremaining: 0us\n",
      "Accuracy of testing dataset:  1.0\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "# Create the model\n",
    "CAT = CatBoostClassifier(iterations=10,\n",
    "              learning_rate=1,\n",
    "              depth=2,\n",
    "              loss_function='MultiClass')\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "CAT.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = CAT.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = CAT.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "34c5f891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "Accuracy of testing dataset:  1.0\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "# Create the model\n",
    "LGBM = lgb.LGBMClassifier(application='multiclass', boosting='gbdt', learning_rate=0.1, max_depth=-5, feature_fraction=0.5, random_state=42)\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "LGBM.fit(train_data, train_labels)\n",
    "\n",
    "# Predict the value of the digit on the testing subset\n",
    "predicted = LGBM.predict(test_data)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy =LGBM.score(test_data,test_labels)\n",
    "print('Accuracy of testing dataset: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc4252c",
   "metadata": {},
   "source": [
    "# 創建function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c1806029",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv(\"income_evaluation.csv\")\n",
    "data2_train=pd.read_csv(\"arcene_train.data\",sep=\" \",header=None)\n",
    "data2_valid=pd.read_csv(\"arcene_valid.data\",sep=\" \",header=None)\n",
    "data2_train_label=pd.read_csv(\"arcene_train.labels\",sep=\" \",header=None)\n",
    "data2_valid_label=pd.read_csv(\"arcene_valid.labels\",sep=\" \",header=None)\n",
    "data2_label=data2_train_label.append(data2_valid_label)\n",
    "data2_all=data2_train.append(data2_valid).dropna(axis='columns')\n",
    "data2=pd.concat([data2_all,data2_label],axis=1)\n",
    "data2.columns=[x for x in range(0,10001)]\n",
    "data3=pd.read_csv(\".\\\\bank\\\\bank_all.csv\")\n",
    "data4=pd.read_csv(\"Telco-Customer-Churn.csv\")\n",
    "data5=pd.read_csv(\"online_shoppers_intention.csv\")\n",
    "data6=pd.read_csv(\"Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "25628147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12330 entries, 0 to 12329\n",
      "Data columns (total 18 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Administrative           12330 non-null  int64  \n",
      " 1   Administrative_Duration  12330 non-null  float64\n",
      " 2   Informational            12330 non-null  int64  \n",
      " 3   Informational_Duration   12330 non-null  float64\n",
      " 4   ProductRelated           12330 non-null  int64  \n",
      " 5   ProductRelated_Duration  12330 non-null  float64\n",
      " 6   BounceRates              12330 non-null  float64\n",
      " 7   ExitRates                12330 non-null  float64\n",
      " 8   PageValues               12330 non-null  float64\n",
      " 9   SpecialDay               12330 non-null  float64\n",
      " 10  Month                    12330 non-null  object \n",
      " 11  OperatingSystems         12330 non-null  int64  \n",
      " 12  Browser                  12330 non-null  int64  \n",
      " 13  Region                   12330 non-null  int64  \n",
      " 14  TrafficType              12330 non-null  int64  \n",
      " 15  VisitorType              12330 non-null  object \n",
      " 16  Weekend                  12330 non-null  bool   \n",
      " 17  Revenue                  12330 non-null  bool   \n",
      "dtypes: bool(2), float64(7), int64(7), object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "81d075c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the type of data \n",
    "def data_type_change(data):\n",
    "    columns=data.columns\n",
    "    for one in columns:\n",
    "        if (data[one].dtypes==\"O\")or(data[one].dtypes=='bool'):\n",
    "            labelencoder = LabelEncoder()\n",
    "            data[one]=labelencoder.fit_transform(data[one])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b8733761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_spliter(data,Supervised_or_not,test_ratio):\n",
    "    if Supervised_or_not is True:\n",
    "        train_data,test_data,train_labels,test_labels=train_test_split(data,data.iloc[:,-1],test_size=test_ratio)\n",
    "    else:\n",
    "        train=data.sample(n=50,replace=False)\n",
    "        test=data.drop(train.index)\n",
    "        train_data=train.iloc[:,:-2]\n",
    "        train_labels=train.iloc[:,-1]\n",
    "        test_data=test.iloc[:,:-2]\n",
    "        test_labels=test.iloc[:,-1]\n",
    "    return train_data,test_data,train_labels,test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6b9a77a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model_accuracy(data,Supervised_or_not,test_ratio):\n",
    "    #split data\n",
    "    train_data,test_data,train_labels,test_labels=train_test_spliter(data,Supervised_or_not,test_ratio)\n",
    "    #set model1\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(train_data, train_labels)\n",
    "    accuracy_knn = metrics.accuracy_score(test_labels, knn.predict(test_data))\n",
    "    #set model2\n",
    "    lm = LogisticRegression(solver=\"lbfgs\")\n",
    "    lm.fit(train_data, train_labels)\n",
    "    accuracy_lm = metrics.accuracy_score(test_labels, lm.predict(test_data))\n",
    "    #set model3\n",
    "    RF = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "    RF.fit(train_data, train_labels)\n",
    "    accuracy_RF = metrics.accuracy_score(test_labels, RF.predict(test_data))\n",
    "    #set model4\n",
    "    MLP = MLPClassifier()\n",
    "    MLP.fit(train_data, train_labels)\n",
    "    accuracy_MLP = metrics.accuracy_score(test_labels,MLP.predict(test_data))\n",
    "    #set model5\n",
    "    svc = svm.SVC()\n",
    "    svc.fit(train_data, train_labels)\n",
    "    accuracy_svm = metrics.accuracy_score(test_labels,svc.predict(test_data))\n",
    "    #set model6\n",
    "    XGB = XGBClassifier()\n",
    "    XGB.fit(train_data, train_labels)\n",
    "    accuracy_XGB = metrics.accuracy_score(test_labels,XGB.predict(test_data))\n",
    "    #set model7\n",
    "    CAT = CatBoostClassifier(iterations=10,\n",
    "                  learning_rate=1,\n",
    "                  depth=2,\n",
    "                  loss_function='MultiClass')\n",
    "    CAT.fit(train_data, train_labels)\n",
    "    accuracy_CAT = metrics.accuracy_score(test_labels,CAT.predict(test_data))\n",
    "    #set model8\n",
    "    LGBM = lgb.LGBMClassifier(application='multiclass', boosting='gbdt', learning_rate=0.1, max_depth=-5, feature_fraction=0.5, random_state=42)\n",
    "    LGBM.fit(train_data, train_labels)\n",
    "    accuracy_LGBM = metrics.accuracy_score(test_labels,LGBM.predict(test_data))\n",
    "\n",
    "    # create accuracy_table\n",
    "    accuracy_table=pd.DataFrame([accuracy_knn,accuracy_lm,accuracy_RF,accuracy_MLP,accuracy_svm,accuracy_XGB,accuracy_CAT,accuracy_LGBM],\n",
    "                                index=[\"KNN\",\"LM\",\"RF\",\"MLP\",\"SVM\",\"XGB\",\"CAT\",\"LGBM\"],columns=[\"Accuracy\"])\n",
    "    return accuracy_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6e69744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model_AUC(data,Supervised_or_not,test_ratio):\n",
    "    #split data\n",
    "    train_data,test_data,train_labels,test_labels=train_test_spliter(data,Supervised_or_not,test_ratio)\n",
    "    #set model1\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(train_data, train_labels)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_labels, knn.predict(test_data))\n",
    "    auc.knn =metrics.auc(fpr, tpr)\n",
    "    #set model2\n",
    "    lm = LogisticRegression(solver=\"lbfgs\")\n",
    "    lm.fit(train_data, train_labels)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_labels, lm.predict(test_data))\n",
    "    auc.lm =metrics.auc(fpr, tpr)\n",
    "    #set model3\n",
    "    RF = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "    RF.fit(train_data, train_labels)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_labels, RF.predict(test_data))\n",
    "    auc.RF =metrics.auc(fpr, tpr)\n",
    "    #set model4\n",
    "    MLP = MLPClassifier()\n",
    "    MLP.fit(train_data, train_labels)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_labels, MLP.predict(test_data))\n",
    "    auc.MLP =metrics.auc(fpr, tpr)\n",
    "    #set model5\n",
    "    svc = svm.SVC()\n",
    "    svc.fit(train_data, train_labels)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_labels, svc.predict(test_data))\n",
    "    auc.svm =metrics.auc(fpr, tpr)\n",
    "    #set model6\n",
    "    XGB = XGBClassifier()\n",
    "    XGB.fit(train_data, train_labels)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_labels, XGB.predict(test_data))\n",
    "    auc.XGB =metrics.auc(fpr, tpr)\n",
    "    #set model7\n",
    "    CAT = CatBoostClassifier(iterations=10,\n",
    "                  learning_rate=1,\n",
    "                  depth=2,\n",
    "                  loss_function='MultiClass')\n",
    "    CAT.fit(train_data, train_labels)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_labels, CAT.predict(test_data))\n",
    "    auc.CAT =metrics.auc(fpr, tpr)\n",
    "    #set model8\n",
    "    LGBM = lgb.LGBMClassifier(application='multiclass', boosting='gbdt', learning_rate=0.1, max_depth=-5, feature_fraction=0.5, random_state=42)\n",
    "    LGBM.fit(train_data, train_labels)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_labels, LGBM.predict(test_data))\n",
    "    auc.LGBM =metrics.auc(fpr, tpr)\n",
    "\n",
    "    # create accuracy_table\n",
    "    AUC_table=pd.DataFrame([auc.knn,auc.lm,auc.RF,auc.MLP,auc.svm,auc.XGB,auc.CAT,auc.LGBM],index=[\"KNN\",\"LM\",\"RF\",\"MLP\",\"SVM\",\"XGB\",\"CAT\",\"LGBM\"],columns=[\"AUC\"])\n",
    "    return AUC_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f3ae47",
   "metadata": {},
   "source": [
    "# supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a0513830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:57:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1271623\ttotal: 3.88ms\tremaining: 34.9ms\n",
      "1:\tlearn: 0.0427476\ttotal: 7.39ms\tremaining: 29.6ms\n",
      "2:\tlearn: 0.0153461\ttotal: 10.9ms\tremaining: 25.5ms\n",
      "3:\tlearn: 0.0056775\ttotal: 14.4ms\tremaining: 21.7ms\n",
      "4:\tlearn: 0.0021590\ttotal: 17.9ms\tremaining: 17.9ms\n",
      "5:\tlearn: 0.0008761\ttotal: 21.9ms\tremaining: 14.6ms\n",
      "6:\tlearn: 0.0003980\ttotal: 25.4ms\tremaining: 10.9ms\n",
      "7:\tlearn: 0.0001944\ttotal: 29.2ms\tremaining: 7.29ms\n",
      "8:\tlearn: 0.0001126\ttotal: 32.5ms\tremaining: 3.62ms\n",
      "9:\tlearn: 0.0000759\ttotal: 35.8ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:57:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1271623\ttotal: 3.58ms\tremaining: 32.2ms\n",
      "1:\tlearn: 0.0427476\ttotal: 7.26ms\tremaining: 29ms\n",
      "2:\tlearn: 0.0153454\ttotal: 10.8ms\tremaining: 25.1ms\n",
      "3:\tlearn: 0.0056772\ttotal: 14.4ms\tremaining: 21.5ms\n",
      "4:\tlearn: 0.0021588\ttotal: 17.8ms\tremaining: 17.8ms\n",
      "5:\tlearn: 0.0008761\ttotal: 21.7ms\tremaining: 14.4ms\n",
      "6:\tlearn: 0.0003980\ttotal: 25.3ms\tremaining: 10.8ms\n",
      "7:\tlearn: 0.0001943\ttotal: 28.8ms\tremaining: 7.2ms\n",
      "8:\tlearn: 0.0001125\ttotal: 32.4ms\tremaining: 3.6ms\n",
      "9:\tlearn: 0.0000758\ttotal: 37.1ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:57:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1271623\ttotal: 3.63ms\tremaining: 32.7ms\n",
      "1:\tlearn: 0.0427476\ttotal: 7.74ms\tremaining: 31ms\n",
      "2:\tlearn: 0.0153450\ttotal: 12.4ms\tremaining: 28.9ms\n",
      "3:\tlearn: 0.0056771\ttotal: 15.8ms\tremaining: 23.8ms\n",
      "4:\tlearn: 0.0021588\ttotal: 19.3ms\tremaining: 19.3ms\n",
      "5:\tlearn: 0.0008761\ttotal: 22.7ms\tremaining: 15.1ms\n",
      "6:\tlearn: 0.0003980\ttotal: 26.1ms\tremaining: 11.2ms\n",
      "7:\tlearn: 0.0001943\ttotal: 29.5ms\tremaining: 7.37ms\n",
      "8:\tlearn: 0.0001125\ttotal: 33ms\tremaining: 3.66ms\n",
      "9:\tlearn: 0.0000757\ttotal: 36.6ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:58:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1271623\ttotal: 3.35ms\tremaining: 30.2ms\n",
      "1:\tlearn: 0.0427476\ttotal: 7.4ms\tremaining: 29.6ms\n",
      "2:\tlearn: 0.0153458\ttotal: 11.1ms\tremaining: 26ms\n",
      "3:\tlearn: 0.0056774\ttotal: 14.6ms\tremaining: 21.9ms\n",
      "4:\tlearn: 0.0021588\ttotal: 18.1ms\tremaining: 18.1ms\n",
      "5:\tlearn: 0.0008761\ttotal: 21.8ms\tremaining: 14.5ms\n",
      "6:\tlearn: 0.0003980\ttotal: 25.8ms\tremaining: 11ms\n",
      "7:\tlearn: 0.0001943\ttotal: 29.5ms\tremaining: 7.38ms\n",
      "8:\tlearn: 0.0001126\ttotal: 33ms\tremaining: 3.67ms\n",
      "9:\tlearn: 0.0000758\ttotal: 36.7ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:58:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1271623\ttotal: 4ms\tremaining: 36ms\n",
      "1:\tlearn: 0.0427476\ttotal: 7.8ms\tremaining: 31.2ms\n",
      "2:\tlearn: 0.0153461\ttotal: 11.4ms\tremaining: 26.5ms\n",
      "3:\tlearn: 0.0056775\ttotal: 15.2ms\tremaining: 22.8ms\n",
      "4:\tlearn: 0.0021585\ttotal: 18.8ms\tremaining: 18.8ms\n",
      "5:\tlearn: 0.0008760\ttotal: 22.3ms\tremaining: 14.8ms\n",
      "6:\tlearn: 0.0003980\ttotal: 25.5ms\tremaining: 10.9ms\n",
      "7:\tlearn: 0.0001941\ttotal: 28.7ms\tremaining: 7.18ms\n",
      "8:\tlearn: 0.0001123\ttotal: 32.1ms\tremaining: 3.56ms\n",
      "9:\tlearn: 0.0000756\ttotal: 35.5ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:58:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1632236\ttotal: 99.8ms\tremaining: 898ms\n",
      "1:\tlearn: 0.0667293\ttotal: 145ms\tremaining: 580ms\n",
      "2:\tlearn: 0.0342985\ttotal: 191ms\tremaining: 446ms\n",
      "3:\tlearn: 0.0212003\ttotal: 241ms\tremaining: 361ms\n",
      "4:\tlearn: 0.0149109\ttotal: 294ms\tremaining: 294ms\n",
      "5:\tlearn: 0.0108587\ttotal: 355ms\tremaining: 237ms\n",
      "6:\tlearn: 0.0083644\ttotal: 404ms\tremaining: 173ms\n",
      "7:\tlearn: 0.0067100\ttotal: 453ms\tremaining: 113ms\n",
      "8:\tlearn: 0.0057686\ttotal: 503ms\tremaining: 55.9ms\n",
      "9:\tlearn: 0.0049037\ttotal: 553ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:58:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1639706\ttotal: 87.6ms\tremaining: 789ms\n",
      "1:\tlearn: 0.0681062\ttotal: 134ms\tremaining: 535ms\n",
      "2:\tlearn: 0.0342572\ttotal: 181ms\tremaining: 423ms\n",
      "3:\tlearn: 0.0212757\ttotal: 230ms\tremaining: 345ms\n",
      "4:\tlearn: 0.0147863\ttotal: 289ms\tremaining: 289ms\n",
      "5:\tlearn: 0.0108239\ttotal: 351ms\tremaining: 234ms\n",
      "6:\tlearn: 0.0085927\ttotal: 399ms\tremaining: 171ms\n",
      "7:\tlearn: 0.0070646\ttotal: 448ms\tremaining: 112ms\n",
      "8:\tlearn: 0.0060064\ttotal: 499ms\tremaining: 55.4ms\n",
      "9:\tlearn: 0.0052279\ttotal: 556ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:58:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1633913\ttotal: 176ms\tremaining: 1.58s\n",
      "1:\tlearn: 0.0633135\ttotal: 246ms\tremaining: 985ms\n",
      "2:\tlearn: 0.0303703\ttotal: 321ms\tremaining: 749ms\n",
      "3:\tlearn: 0.0193422\ttotal: 429ms\tremaining: 643ms\n",
      "4:\tlearn: 0.0126944\ttotal: 507ms\tremaining: 507ms\n",
      "5:\tlearn: 0.0093055\ttotal: 558ms\tremaining: 372ms\n",
      "6:\tlearn: 0.0071152\ttotal: 611ms\tremaining: 262ms\n",
      "7:\tlearn: 0.0060030\ttotal: 666ms\tremaining: 167ms\n",
      "8:\tlearn: 0.0052237\ttotal: 727ms\tremaining: 80.8ms\n",
      "9:\tlearn: 0.0045871\ttotal: 786ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:59:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1609924\ttotal: 89.6ms\tremaining: 806ms\n",
      "1:\tlearn: 0.0681681\ttotal: 152ms\tremaining: 608ms\n",
      "2:\tlearn: 0.0361408\ttotal: 250ms\tremaining: 582ms\n",
      "3:\tlearn: 0.0222877\ttotal: 341ms\tremaining: 512ms\n",
      "4:\tlearn: 0.0154552\ttotal: 406ms\tremaining: 406ms\n",
      "5:\tlearn: 0.0116941\ttotal: 468ms\tremaining: 312ms\n",
      "6:\tlearn: 0.0092523\ttotal: 520ms\tremaining: 223ms\n",
      "7:\tlearn: 0.0072911\ttotal: 585ms\tremaining: 146ms\n",
      "8:\tlearn: 0.0060234\ttotal: 670ms\tremaining: 74.5ms\n",
      "9:\tlearn: 0.0051413\ttotal: 805ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:59:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1632355\ttotal: 83ms\tremaining: 747ms\n",
      "1:\tlearn: 0.0692554\ttotal: 131ms\tremaining: 524ms\n",
      "2:\tlearn: 0.0363653\ttotal: 179ms\tremaining: 418ms\n",
      "3:\tlearn: 0.0225473\ttotal: 230ms\tremaining: 345ms\n",
      "4:\tlearn: 0.0147863\ttotal: 294ms\tremaining: 294ms\n",
      "5:\tlearn: 0.0108031\ttotal: 351ms\tremaining: 234ms\n",
      "6:\tlearn: 0.0086588\ttotal: 406ms\tremaining: 174ms\n",
      "7:\tlearn: 0.0071938\ttotal: 469ms\tremaining: 117ms\n",
      "8:\tlearn: 0.0061425\ttotal: 523ms\tremaining: 58.1ms\n",
      "9:\tlearn: 0.0053294\ttotal: 593ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1270967\ttotal: 5.09ms\tremaining: 45.8ms\n",
      "1:\tlearn: 0.0426955\ttotal: 9.35ms\tremaining: 37.4ms\n",
      "2:\tlearn: 0.0153144\ttotal: 13.7ms\tremaining: 32ms\n",
      "3:\tlearn: 0.0056271\ttotal: 18ms\tremaining: 27.1ms\n",
      "4:\tlearn: 0.0021107\ttotal: 22.2ms\tremaining: 22.2ms\n",
      "5:\tlearn: 0.0008319\ttotal: 26.9ms\tremaining: 17.9ms\n",
      "6:\tlearn: 0.0003593\ttotal: 31.2ms\tremaining: 13.4ms\n",
      "7:\tlearn: 0.0001722\ttotal: 35.3ms\tremaining: 8.83ms\n",
      "8:\tlearn: 0.0000975\ttotal: 39.5ms\tremaining: 4.38ms\n",
      "9:\tlearn: 0.0000643\ttotal: 43.6ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1270967\ttotal: 5.19ms\tremaining: 46.8ms\n",
      "1:\tlearn: 0.0426954\ttotal: 10.6ms\tremaining: 42.6ms\n",
      "2:\tlearn: 0.0153143\ttotal: 15.3ms\tremaining: 35.7ms\n",
      "3:\tlearn: 0.0056273\ttotal: 19.8ms\tremaining: 29.7ms\n",
      "4:\tlearn: 0.0021112\ttotal: 24ms\tremaining: 24ms\n",
      "5:\tlearn: 0.0008322\ttotal: 28ms\tremaining: 18.6ms\n",
      "6:\tlearn: 0.0003593\ttotal: 31.9ms\tremaining: 13.7ms\n",
      "7:\tlearn: 0.0001722\ttotal: 36.1ms\tremaining: 9.03ms\n",
      "8:\tlearn: 0.0000975\ttotal: 40.2ms\tremaining: 4.47ms\n",
      "9:\tlearn: 0.0000643\ttotal: 44.4ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1270967\ttotal: 6.94ms\tremaining: 62.5ms\n",
      "1:\tlearn: 0.0426955\ttotal: 11.1ms\tremaining: 44.5ms\n",
      "2:\tlearn: 0.0153144\ttotal: 15.6ms\tremaining: 36.3ms\n",
      "3:\tlearn: 0.0056277\ttotal: 19.6ms\tremaining: 29.5ms\n",
      "4:\tlearn: 0.0021108\ttotal: 24.3ms\tremaining: 24.3ms\n",
      "5:\tlearn: 0.0008312\ttotal: 28.4ms\tremaining: 19ms\n",
      "6:\tlearn: 0.0003589\ttotal: 32.5ms\tremaining: 13.9ms\n",
      "7:\tlearn: 0.0001748\ttotal: 36.6ms\tremaining: 9.14ms\n",
      "8:\tlearn: 0.0001004\ttotal: 40.5ms\tremaining: 4.5ms\n",
      "9:\tlearn: 0.0000668\ttotal: 44.8ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1270967\ttotal: 5.16ms\tremaining: 46.4ms\n",
      "1:\tlearn: 0.0426954\ttotal: 9.43ms\tremaining: 37.7ms\n",
      "2:\tlearn: 0.0153143\ttotal: 14.1ms\tremaining: 32.9ms\n",
      "3:\tlearn: 0.0056279\ttotal: 18.6ms\tremaining: 27.9ms\n",
      "4:\tlearn: 0.0021113\ttotal: 22.7ms\tremaining: 22.7ms\n",
      "5:\tlearn: 0.0008322\ttotal: 26.7ms\tremaining: 17.8ms\n",
      "6:\tlearn: 0.0003594\ttotal: 30.8ms\tremaining: 13.2ms\n",
      "7:\tlearn: 0.0001750\ttotal: 34.9ms\tremaining: 8.73ms\n",
      "8:\tlearn: 0.0001005\ttotal: 39ms\tremaining: 4.33ms\n",
      "9:\tlearn: 0.0000669\ttotal: 43.4ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1270967\ttotal: 5.13ms\tremaining: 46.2ms\n",
      "1:\tlearn: 0.0426954\ttotal: 10.1ms\tremaining: 40.6ms\n",
      "2:\tlearn: 0.0153143\ttotal: 16.1ms\tremaining: 37.5ms\n",
      "3:\tlearn: 0.0056273\ttotal: 20.8ms\tremaining: 31.2ms\n",
      "4:\tlearn: 0.0021109\ttotal: 24.9ms\tremaining: 24.9ms\n",
      "5:\tlearn: 0.0008319\ttotal: 29.5ms\tremaining: 19.6ms\n",
      "6:\tlearn: 0.0003592\ttotal: 33.5ms\tremaining: 14.4ms\n",
      "7:\tlearn: 0.0001722\ttotal: 37.6ms\tremaining: 9.39ms\n",
      "8:\tlearn: 0.0000975\ttotal: 41.6ms\tremaining: 4.63ms\n",
      "9:\tlearn: 0.0000643\ttotal: 46.3ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1280104\ttotal: 1.48ms\tremaining: 13.3ms\n",
      "1:\tlearn: 0.0433946\ttotal: 2.74ms\tremaining: 11ms\n",
      "2:\tlearn: 0.0159272\ttotal: 3.97ms\tremaining: 9.27ms\n",
      "3:\tlearn: 0.0062045\ttotal: 5.12ms\tremaining: 7.68ms\n",
      "4:\tlearn: 0.0026119\ttotal: 6.36ms\tremaining: 6.36ms\n",
      "5:\tlearn: 0.0012605\ttotal: 7.58ms\tremaining: 5.05ms\n",
      "6:\tlearn: 0.0007162\ttotal: 8.84ms\tremaining: 3.79ms\n",
      "7:\tlearn: 0.0004727\ttotal: 10ms\tremaining: 2.51ms\n",
      "8:\tlearn: 0.0003454\ttotal: 11.5ms\tremaining: 1.28ms\n",
      "9:\tlearn: 0.0002699\ttotal: 12.8ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1280103\ttotal: 1.46ms\tremaining: 13.1ms\n",
      "1:\tlearn: 0.0433952\ttotal: 2.85ms\tremaining: 11.4ms\n",
      "2:\tlearn: 0.0159273\ttotal: 4.08ms\tremaining: 9.51ms\n",
      "3:\tlearn: 0.0062042\ttotal: 5.31ms\tremaining: 7.96ms\n",
      "4:\tlearn: 0.0026136\ttotal: 6.61ms\tremaining: 6.61ms\n",
      "5:\tlearn: 0.0012625\ttotal: 7.88ms\tremaining: 5.25ms\n",
      "6:\tlearn: 0.0007165\ttotal: 9.24ms\tremaining: 3.96ms\n",
      "7:\tlearn: 0.0004734\ttotal: 10.5ms\tremaining: 2.63ms\n",
      "8:\tlearn: 0.0003461\ttotal: 11.8ms\tremaining: 1.31ms\n",
      "9:\tlearn: 0.0002705\ttotal: 13ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1280104\ttotal: 1.48ms\tremaining: 13.3ms\n",
      "1:\tlearn: 0.0433954\ttotal: 2.93ms\tremaining: 11.7ms\n",
      "2:\tlearn: 0.0159274\ttotal: 4.23ms\tremaining: 9.88ms\n",
      "3:\tlearn: 0.0062043\ttotal: 5.57ms\tremaining: 8.35ms\n",
      "4:\tlearn: 0.0026141\ttotal: 6.88ms\tremaining: 6.88ms\n",
      "5:\tlearn: 0.0012629\ttotal: 8.18ms\tremaining: 5.45ms\n",
      "6:\tlearn: 0.0007318\ttotal: 9.43ms\tremaining: 4.04ms\n",
      "7:\tlearn: 0.0004772\ttotal: 10.7ms\tremaining: 2.67ms\n",
      "8:\tlearn: 0.0003464\ttotal: 11.9ms\tremaining: 1.32ms\n",
      "9:\tlearn: 0.0002697\ttotal: 13.1ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1280104\ttotal: 1.59ms\tremaining: 14.3ms\n",
      "1:\tlearn: 0.0433952\ttotal: 3.12ms\tremaining: 12.5ms\n",
      "2:\tlearn: 0.0159274\ttotal: 4.5ms\tremaining: 10.5ms\n",
      "3:\tlearn: 0.0062045\ttotal: 5.73ms\tremaining: 8.6ms\n",
      "4:\tlearn: 0.0026135\ttotal: 6.93ms\tremaining: 6.93ms\n",
      "5:\tlearn: 0.0012623\ttotal: 8.19ms\tremaining: 5.46ms\n",
      "6:\tlearn: 0.0007169\ttotal: 9.41ms\tremaining: 4.04ms\n",
      "7:\tlearn: 0.0004735\ttotal: 10.8ms\tremaining: 2.7ms\n",
      "8:\tlearn: 0.0003461\ttotal: 12.1ms\tremaining: 1.34ms\n",
      "9:\tlearn: 0.0002705\ttotal: 13.3ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1280104\ttotal: 1.41ms\tremaining: 12.7ms\n",
      "1:\tlearn: 0.0433953\ttotal: 2.89ms\tremaining: 11.6ms\n",
      "2:\tlearn: 0.0159274\ttotal: 4.27ms\tremaining: 9.97ms\n",
      "3:\tlearn: 0.0062044\ttotal: 5.59ms\tremaining: 8.38ms\n",
      "4:\tlearn: 0.0026139\ttotal: 6.87ms\tremaining: 6.87ms\n",
      "5:\tlearn: 0.0012627\ttotal: 8.32ms\tremaining: 5.54ms\n",
      "6:\tlearn: 0.0007173\ttotal: 9.61ms\tremaining: 4.12ms\n",
      "7:\tlearn: 0.0004738\ttotal: 10.9ms\tremaining: 2.72ms\n",
      "8:\tlearn: 0.0003464\ttotal: 12.2ms\tremaining: 1.35ms\n",
      "9:\tlearn: 0.0002708\ttotal: 13.6ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1275464\ttotal: 2.7ms\tremaining: 24.3ms\n",
      "1:\tlearn: 0.0430443\ttotal: 4.88ms\tremaining: 19.5ms\n",
      "2:\tlearn: 0.0155052\ttotal: 6.89ms\tremaining: 16.1ms\n",
      "3:\tlearn: 0.0058246\ttotal: 8.89ms\tremaining: 13.3ms\n",
      "4:\tlearn: 0.0023427\ttotal: 11ms\tremaining: 11ms\n",
      "5:\tlearn: 0.0010255\ttotal: 13.1ms\tremaining: 8.71ms\n",
      "6:\tlearn: 0.0004767\ttotal: 15.1ms\tremaining: 6.45ms\n",
      "7:\tlearn: 0.0002933\ttotal: 17.1ms\tremaining: 4.27ms\n",
      "8:\tlearn: 0.0001852\ttotal: 19.3ms\tremaining: 2.15ms\n",
      "9:\tlearn: 0.0001312\ttotal: 21.4ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1275464\ttotal: 2.28ms\tremaining: 20.6ms\n",
      "1:\tlearn: 0.0430443\ttotal: 4.39ms\tremaining: 17.6ms\n",
      "2:\tlearn: 0.0155032\ttotal: 6.39ms\tremaining: 14.9ms\n",
      "3:\tlearn: 0.0058250\ttotal: 8.41ms\tremaining: 12.6ms\n",
      "4:\tlearn: 0.0023431\ttotal: 10.4ms\tremaining: 10.4ms\n",
      "5:\tlearn: 0.0010247\ttotal: 12.6ms\tremaining: 8.41ms\n",
      "6:\tlearn: 0.0004766\ttotal: 14.9ms\tremaining: 6.39ms\n",
      "7:\tlearn: 0.0002667\ttotal: 16.9ms\tremaining: 4.24ms\n",
      "8:\tlearn: 0.0001746\ttotal: 19ms\tremaining: 2.12ms\n",
      "9:\tlearn: 0.0001277\ttotal: 21ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1275464\ttotal: 2.17ms\tremaining: 19.5ms\n",
      "1:\tlearn: 0.0430443\ttotal: 4.37ms\tremaining: 17.5ms\n",
      "2:\tlearn: 0.0155976\ttotal: 6.45ms\tremaining: 15.1ms\n",
      "3:\tlearn: 0.0058656\ttotal: 8.44ms\tremaining: 12.7ms\n",
      "4:\tlearn: 0.0023580\ttotal: 10.4ms\tremaining: 10.4ms\n",
      "5:\tlearn: 0.0010309\ttotal: 12.6ms\tremaining: 8.41ms\n",
      "6:\tlearn: 0.0004791\ttotal: 14.6ms\tremaining: 6.27ms\n",
      "7:\tlearn: 0.0002877\ttotal: 16.7ms\tremaining: 4.19ms\n",
      "8:\tlearn: 0.0001860\ttotal: 18.8ms\tremaining: 2.09ms\n",
      "9:\tlearn: 0.0001332\ttotal: 20.8ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1275464\ttotal: 2.19ms\tremaining: 19.8ms\n",
      "1:\tlearn: 0.0430443\ttotal: 4.28ms\tremaining: 17.1ms\n",
      "2:\tlearn: 0.0155009\ttotal: 6.42ms\tremaining: 15ms\n",
      "3:\tlearn: 0.0058212\ttotal: 8.46ms\tremaining: 12.7ms\n",
      "4:\tlearn: 0.0023410\ttotal: 10.6ms\tremaining: 10.6ms\n",
      "5:\tlearn: 0.0010242\ttotal: 12.6ms\tremaining: 8.38ms\n",
      "6:\tlearn: 0.0004764\ttotal: 14.6ms\tremaining: 6.26ms\n",
      "7:\tlearn: 0.0002934\ttotal: 16.5ms\tremaining: 4.13ms\n",
      "8:\tlearn: 0.0001847\ttotal: 18.5ms\tremaining: 2.05ms\n",
      "9:\tlearn: 0.0001309\ttotal: 20.5ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1275464\ttotal: 2.06ms\tremaining: 18.5ms\n",
      "1:\tlearn: 0.0430443\ttotal: 4.21ms\tremaining: 16.8ms\n",
      "2:\tlearn: 0.0155009\ttotal: 6.27ms\tremaining: 14.6ms\n",
      "3:\tlearn: 0.0058256\ttotal: 8.31ms\tremaining: 12.5ms\n",
      "4:\tlearn: 0.0023434\ttotal: 10.2ms\tremaining: 10.2ms\n",
      "5:\tlearn: 0.0010260\ttotal: 12.3ms\tremaining: 8.17ms\n",
      "6:\tlearn: 0.0004773\ttotal: 14.2ms\tremaining: 6.1ms\n",
      "7:\tlearn: 0.0002938\ttotal: 16.2ms\tremaining: 4.06ms\n",
      "8:\tlearn: 0.0001855\ttotal: 18.2ms\tremaining: 2.03ms\n",
      "9:\tlearn: 0.0001385\ttotal: 20.2ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:03:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1276904\ttotal: 1.81ms\tremaining: 16.3ms\n",
      "1:\tlearn: 0.0431547\ttotal: 3.49ms\tremaining: 14ms\n",
      "2:\tlearn: 0.0156821\ttotal: 5.06ms\tremaining: 11.8ms\n",
      "3:\tlearn: 0.0059975\ttotal: 6.64ms\tremaining: 9.96ms\n",
      "4:\tlearn: 0.0024677\ttotal: 8.25ms\tremaining: 8.25ms\n",
      "5:\tlearn: 0.0011451\ttotal: 9.8ms\tremaining: 6.53ms\n",
      "6:\tlearn: 0.0006005\ttotal: 11.5ms\tremaining: 4.93ms\n",
      "7:\tlearn: 0.0003707\ttotal: 13.2ms\tremaining: 3.3ms\n",
      "8:\tlearn: 0.0002282\ttotal: 14.7ms\tremaining: 1.63ms\n",
      "9:\tlearn: 0.0001802\ttotal: 16.1ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:03:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1276904\ttotal: 1.85ms\tremaining: 16.6ms\n",
      "1:\tlearn: 0.0431548\ttotal: 3.52ms\tremaining: 14.1ms\n",
      "2:\tlearn: 0.0156826\ttotal: 5.22ms\tremaining: 12.2ms\n",
      "3:\tlearn: 0.0059979\ttotal: 6.87ms\tremaining: 10.3ms\n",
      "4:\tlearn: 0.0024679\ttotal: 8.45ms\tremaining: 8.45ms\n",
      "5:\tlearn: 0.0011450\ttotal: 10.1ms\tremaining: 6.75ms\n",
      "6:\tlearn: 0.0005997\ttotal: 11.7ms\tremaining: 5.03ms\n",
      "7:\tlearn: 0.0003700\ttotal: 13.3ms\tremaining: 3.33ms\n",
      "8:\tlearn: 0.0002278\ttotal: 15ms\tremaining: 1.66ms\n",
      "9:\tlearn: 0.0001800\ttotal: 16.6ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:03:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1276904\ttotal: 1.74ms\tremaining: 15.7ms\n",
      "1:\tlearn: 0.0431548\ttotal: 3.4ms\tremaining: 13.6ms\n",
      "2:\tlearn: 0.0156842\ttotal: 5.02ms\tremaining: 11.7ms\n",
      "3:\tlearn: 0.0059983\ttotal: 6.67ms\tremaining: 10ms\n",
      "4:\tlearn: 0.0024680\ttotal: 8.46ms\tremaining: 8.46ms\n",
      "5:\tlearn: 0.0011447\ttotal: 10.3ms\tremaining: 6.86ms\n",
      "6:\tlearn: 0.0005999\ttotal: 12ms\tremaining: 5.13ms\n",
      "7:\tlearn: 0.0003702\ttotal: 13.7ms\tremaining: 3.42ms\n",
      "8:\tlearn: 0.0002279\ttotal: 15.3ms\tremaining: 1.7ms\n",
      "9:\tlearn: 0.0001799\ttotal: 17ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:03:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1276904\ttotal: 10.8ms\tremaining: 96.9ms\n",
      "1:\tlearn: 0.0431547\ttotal: 12.8ms\tremaining: 51.2ms\n",
      "2:\tlearn: 0.0156815\ttotal: 14.5ms\tremaining: 33.9ms\n",
      "3:\tlearn: 0.0059972\ttotal: 16.4ms\tremaining: 24.5ms\n",
      "4:\tlearn: 0.0024675\ttotal: 18.1ms\tremaining: 18.1ms\n",
      "5:\tlearn: 0.0011440\ttotal: 19.8ms\tremaining: 13.2ms\n",
      "6:\tlearn: 0.0005988\ttotal: 21.5ms\tremaining: 9.22ms\n",
      "7:\tlearn: 0.0003691\ttotal: 23.2ms\tremaining: 5.81ms\n",
      "8:\tlearn: 0.0002273\ttotal: 24.9ms\tremaining: 2.77ms\n",
      "9:\tlearn: 0.0001796\ttotal: 26.5ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[00:03:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1276904\ttotal: 2.04ms\tremaining: 18.3ms\n",
      "1:\tlearn: 0.0431547\ttotal: 3.75ms\tremaining: 15ms\n",
      "2:\tlearn: 0.0156840\ttotal: 5.27ms\tremaining: 12.3ms\n",
      "3:\tlearn: 0.0059983\ttotal: 6.71ms\tremaining: 10.1ms\n",
      "4:\tlearn: 0.0024682\ttotal: 8.1ms\tremaining: 8.1ms\n",
      "5:\tlearn: 0.0011452\ttotal: 9.52ms\tremaining: 6.35ms\n",
      "6:\tlearn: 0.0005996\ttotal: 11ms\tremaining: 4.7ms\n",
      "7:\tlearn: 0.0003704\ttotal: 12.5ms\tremaining: 3.13ms\n",
      "8:\tlearn: 0.0002280\ttotal: 14ms\tremaining: 1.55ms\n",
      "9:\tlearn: 0.0001799\ttotal: 15.5ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "data_1=data_type_change(data1)\n",
    "data_2=data2\n",
    "data_3=data_type_change(data3)\n",
    "data_4=data_type_change(data4)\n",
    "data_5=data_type_change(data5)\n",
    "data_6=data_type_change(data6)\n",
    "accuracy_table_all=pd.DataFrame()\n",
    "for one_data in [data_1,data_2,data_3,data_4,data_5,data_6]:\n",
    "    accuracy_table_in_dataset=pd.DataFrame()\n",
    "    for time in range(0,5) :\n",
    "        accuracy_table_in_dataset=pd.concat([accuracy_table_in_dataset,set_model_accuracy(one_data,True,0.25)],axis=1)\n",
    "    accuracy_table_all=pd.concat([accuracy_table_all,accuracy_table_in_dataset.mean(axis=1)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "03067ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Arcene</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BlastChar</th>\n",
       "      <th>Shopper</th>\n",
       "      <th>SHrutime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.772338</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.880563</td>\n",
       "      <td>0.692788</td>\n",
       "      <td>0.858644</td>\n",
       "      <td>0.75952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LM</th>\n",
       "      <td>0.789584</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.915881</td>\n",
       "      <td>0.992618</td>\n",
       "      <td>0.884009</td>\n",
       "      <td>0.79232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.787053</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.988764</td>\n",
       "      <td>0.922658</td>\n",
       "      <td>0.976776</td>\n",
       "      <td>0.75048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.793637</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.882721</td>\n",
       "      <td>0.740148</td>\n",
       "      <td>0.840156</td>\n",
       "      <td>0.79232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Income  Arcene      Bank  BlastChar   Shopper  SHrutime\n",
       "KNN   0.772338   0.816  0.880563   0.692788  0.858644   0.75952\n",
       "LM    0.789584   0.868  0.915881   0.992618  0.884009   0.79232\n",
       "RF    1.000000   0.820  1.000000   1.000000  1.000000   1.00000\n",
       "MLP   0.787053   0.680  0.988764   0.922658  0.976776   0.75048\n",
       "SVM   0.793637   0.700  0.882721   0.740148  0.840156   0.79232\n",
       "XGB   1.000000   1.000  1.000000   1.000000  1.000000   1.00000\n",
       "CAT   1.000000   1.000  1.000000   1.000000  1.000000   1.00000\n",
       "LGBM  1.000000   1.000  1.000000   1.000000  1.000000   1.00000"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_table_all.columns=[\"Income\",\"Arcene\",\"Bank\",\"BlastChar\",\"Shopper\",\"SHrutime\"]\n",
    "accuracy_table_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "db91e02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:03:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1271623\ttotal: 3.72ms\tremaining: 33.5ms\n",
      "1:\tlearn: 0.0427476\ttotal: 7.58ms\tremaining: 30.3ms\n",
      "2:\tlearn: 0.0153457\ttotal: 11.3ms\tremaining: 26.5ms\n",
      "3:\tlearn: 0.0056774\ttotal: 14.9ms\tremaining: 22.3ms\n",
      "4:\tlearn: 0.0021587\ttotal: 18.3ms\tremaining: 18.3ms\n",
      "5:\tlearn: 0.0008761\ttotal: 22.2ms\tremaining: 14.8ms\n",
      "6:\tlearn: 0.0003980\ttotal: 25.7ms\tremaining: 11ms\n",
      "7:\tlearn: 0.0001944\ttotal: 29.4ms\tremaining: 7.36ms\n",
      "8:\tlearn: 0.0001126\ttotal: 33.2ms\tremaining: 3.69ms\n",
      "9:\tlearn: 0.0000759\ttotal: 36.6ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:03:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1271623\ttotal: 7.97ms\tremaining: 71.7ms\n",
      "1:\tlearn: 0.0427476\ttotal: 16.4ms\tremaining: 65.4ms\n",
      "2:\tlearn: 0.0153467\ttotal: 20.6ms\tremaining: 48.2ms\n",
      "3:\tlearn: 0.0056777\ttotal: 25.9ms\tremaining: 38.9ms\n",
      "4:\tlearn: 0.0021586\ttotal: 30ms\tremaining: 30ms\n",
      "5:\tlearn: 0.0008760\ttotal: 34.2ms\tremaining: 22.8ms\n",
      "6:\tlearn: 0.0003980\ttotal: 38.3ms\tremaining: 16.4ms\n",
      "7:\tlearn: 0.0001941\ttotal: 43.3ms\tremaining: 10.8ms\n",
      "8:\tlearn: 0.0001124\ttotal: 47.4ms\tremaining: 5.26ms\n",
      "9:\tlearn: 0.0000756\ttotal: 51.9ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:04:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1271623\ttotal: 3.79ms\tremaining: 34.1ms\n",
      "1:\tlearn: 0.0427476\ttotal: 7.4ms\tremaining: 29.6ms\n",
      "2:\tlearn: 0.0153454\ttotal: 10.9ms\tremaining: 25.5ms\n",
      "3:\tlearn: 0.0056772\ttotal: 14.5ms\tremaining: 21.8ms\n",
      "4:\tlearn: 0.0021586\ttotal: 18.2ms\tremaining: 18.2ms\n",
      "5:\tlearn: 0.0008760\ttotal: 21.9ms\tremaining: 14.6ms\n",
      "6:\tlearn: 0.0003980\ttotal: 25.6ms\tremaining: 11ms\n",
      "7:\tlearn: 0.0001942\ttotal: 29.1ms\tremaining: 7.28ms\n",
      "8:\tlearn: 0.0001125\ttotal: 32.5ms\tremaining: 3.61ms\n",
      "9:\tlearn: 0.0000757\ttotal: 36ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:04:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1271623\ttotal: 4.22ms\tremaining: 38ms\n",
      "1:\tlearn: 0.0427476\ttotal: 7.86ms\tremaining: 31.4ms\n",
      "2:\tlearn: 0.0153450\ttotal: 11.3ms\tremaining: 26.3ms\n",
      "3:\tlearn: 0.0056771\ttotal: 15ms\tremaining: 22.5ms\n",
      "4:\tlearn: 0.0021587\ttotal: 18.6ms\tremaining: 18.6ms\n",
      "5:\tlearn: 0.0008761\ttotal: 22.5ms\tremaining: 15ms\n",
      "6:\tlearn: 0.0003980\ttotal: 26.2ms\tremaining: 11.2ms\n",
      "7:\tlearn: 0.0001944\ttotal: 29.8ms\tremaining: 7.44ms\n",
      "8:\tlearn: 0.0001126\ttotal: 33.4ms\tremaining: 3.71ms\n",
      "9:\tlearn: 0.0000759\ttotal: 37.1ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:04:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1271623\ttotal: 4.14ms\tremaining: 37.3ms\n",
      "1:\tlearn: 0.0427476\ttotal: 7.61ms\tremaining: 30.5ms\n",
      "2:\tlearn: 0.0153450\ttotal: 11.1ms\tremaining: 25.9ms\n",
      "3:\tlearn: 0.0056771\ttotal: 14.3ms\tremaining: 21.4ms\n",
      "4:\tlearn: 0.0021589\ttotal: 18.1ms\tremaining: 18.1ms\n",
      "5:\tlearn: 0.0008762\ttotal: 21.6ms\tremaining: 14.4ms\n",
      "6:\tlearn: 0.0003981\ttotal: 24.8ms\tremaining: 10.6ms\n",
      "7:\tlearn: 0.0001943\ttotal: 28.2ms\tremaining: 7.04ms\n",
      "8:\tlearn: 0.0001125\ttotal: 31.5ms\tremaining: 3.5ms\n",
      "9:\tlearn: 0.0000758\ttotal: 34.8ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:04:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1629448\ttotal: 102ms\tremaining: 918ms\n",
      "1:\tlearn: 0.0696726\ttotal: 170ms\tremaining: 678ms\n",
      "2:\tlearn: 0.0366559\ttotal: 242ms\tremaining: 564ms\n",
      "3:\tlearn: 0.0218941\ttotal: 327ms\tremaining: 491ms\n",
      "4:\tlearn: 0.0153147\ttotal: 386ms\tremaining: 386ms\n",
      "5:\tlearn: 0.0110621\ttotal: 440ms\tremaining: 294ms\n",
      "6:\tlearn: 0.0086922\ttotal: 496ms\tremaining: 212ms\n",
      "7:\tlearn: 0.0072650\ttotal: 554ms\tremaining: 139ms\n",
      "8:\tlearn: 0.0062037\ttotal: 611ms\tremaining: 67.9ms\n",
      "9:\tlearn: 0.0053548\ttotal: 696ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:05:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1632769\ttotal: 116ms\tremaining: 1.04s\n",
      "1:\tlearn: 0.0688085\ttotal: 239ms\tremaining: 957ms\n",
      "2:\tlearn: 0.0355608\ttotal: 347ms\tremaining: 810ms\n",
      "3:\tlearn: 0.0216024\ttotal: 426ms\tremaining: 639ms\n",
      "4:\tlearn: 0.0150871\ttotal: 509ms\tremaining: 509ms\n",
      "5:\tlearn: 0.0108026\ttotal: 580ms\tremaining: 387ms\n",
      "6:\tlearn: 0.0086024\ttotal: 649ms\tremaining: 278ms\n",
      "7:\tlearn: 0.0063927\ttotal: 729ms\tremaining: 182ms\n",
      "8:\tlearn: 0.0055328\ttotal: 806ms\tremaining: 89.6ms\n",
      "9:\tlearn: 0.0048222\ttotal: 883ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:05:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1630148\ttotal: 126ms\tremaining: 1.13s\n",
      "1:\tlearn: 0.0695902\ttotal: 227ms\tremaining: 907ms\n",
      "2:\tlearn: 0.0353136\ttotal: 302ms\tremaining: 705ms\n",
      "3:\tlearn: 0.0193073\ttotal: 374ms\tremaining: 560ms\n",
      "4:\tlearn: 0.0138645\ttotal: 456ms\tremaining: 456ms\n",
      "5:\tlearn: 0.0095213\ttotal: 534ms\tremaining: 356ms\n",
      "6:\tlearn: 0.0074350\ttotal: 611ms\tremaining: 262ms\n",
      "7:\tlearn: 0.0060983\ttotal: 690ms\tremaining: 173ms\n",
      "8:\tlearn: 0.0053198\ttotal: 770ms\tremaining: 85.6ms\n",
      "9:\tlearn: 0.0045445\ttotal: 850ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:05:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1639479\ttotal: 96.1ms\tremaining: 865ms\n",
      "1:\tlearn: 0.0683190\ttotal: 152ms\tremaining: 608ms\n",
      "2:\tlearn: 0.0356116\ttotal: 206ms\tremaining: 481ms\n",
      "3:\tlearn: 0.0220051\ttotal: 256ms\tremaining: 385ms\n",
      "4:\tlearn: 0.0154315\ttotal: 307ms\tremaining: 307ms\n",
      "5:\tlearn: 0.0109257\ttotal: 358ms\tremaining: 239ms\n",
      "6:\tlearn: 0.0088117\ttotal: 407ms\tremaining: 175ms\n",
      "7:\tlearn: 0.0073243\ttotal: 459ms\tremaining: 115ms\n",
      "8:\tlearn: 0.0062318\ttotal: 510ms\tremaining: 56.7ms\n",
      "9:\tlearn: 0.0054295\ttotal: 561ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:05:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1640096\ttotal: 88ms\tremaining: 792ms\n",
      "1:\tlearn: 0.0699927\ttotal: 142ms\tremaining: 569ms\n",
      "2:\tlearn: 0.0363437\ttotal: 194ms\tremaining: 453ms\n",
      "3:\tlearn: 0.0196333\ttotal: 252ms\tremaining: 378ms\n",
      "4:\tlearn: 0.0140340\ttotal: 302ms\tremaining: 302ms\n",
      "5:\tlearn: 0.0103519\ttotal: 356ms\tremaining: 237ms\n",
      "6:\tlearn: 0.0083932\ttotal: 405ms\tremaining: 174ms\n",
      "7:\tlearn: 0.0069693\ttotal: 457ms\tremaining: 114ms\n",
      "8:\tlearn: 0.0058318\ttotal: 507ms\tremaining: 56.3ms\n",
      "9:\tlearn: 0.0050276\ttotal: 559ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:06:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1270967\ttotal: 4.86ms\tremaining: 43.7ms\n",
      "1:\tlearn: 0.0426954\ttotal: 10.2ms\tremaining: 40.9ms\n",
      "2:\tlearn: 0.0153143\ttotal: 17ms\tremaining: 39.7ms\n",
      "3:\tlearn: 0.0056266\ttotal: 21.9ms\tremaining: 32.9ms\n",
      "4:\tlearn: 0.0021107\ttotal: 28.7ms\tremaining: 28.7ms\n",
      "5:\tlearn: 0.0008318\ttotal: 33.4ms\tremaining: 22.3ms\n",
      "6:\tlearn: 0.0003593\ttotal: 38.2ms\tremaining: 16.4ms\n",
      "7:\tlearn: 0.0001722\ttotal: 44.6ms\tremaining: 11.2ms\n",
      "8:\tlearn: 0.0000974\ttotal: 49.6ms\tremaining: 5.51ms\n",
      "9:\tlearn: 0.0000643\ttotal: 54.6ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:07:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1270967\ttotal: 11.5ms\tremaining: 103ms\n",
      "1:\tlearn: 0.0426954\ttotal: 16.9ms\tremaining: 67.4ms\n",
      "2:\tlearn: 0.0153143\ttotal: 22.4ms\tremaining: 52.3ms\n",
      "3:\tlearn: 0.0056279\ttotal: 27.5ms\tremaining: 41.3ms\n",
      "4:\tlearn: 0.0021115\ttotal: 32.6ms\tremaining: 32.6ms\n",
      "5:\tlearn: 0.0008322\ttotal: 37.6ms\tremaining: 25ms\n",
      "6:\tlearn: 0.0003594\ttotal: 42.5ms\tremaining: 18.2ms\n",
      "7:\tlearn: 0.0001722\ttotal: 47.6ms\tremaining: 11.9ms\n",
      "8:\tlearn: 0.0000975\ttotal: 52.6ms\tremaining: 5.85ms\n",
      "9:\tlearn: 0.0000643\ttotal: 57.4ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:07:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1270967\ttotal: 6.92ms\tremaining: 62.3ms\n",
      "1:\tlearn: 0.0426955\ttotal: 12.1ms\tremaining: 48.2ms\n",
      "2:\tlearn: 0.0153144\ttotal: 16.9ms\tremaining: 39.5ms\n",
      "3:\tlearn: 0.0056277\ttotal: 21.8ms\tremaining: 32.8ms\n",
      "4:\tlearn: 0.0021110\ttotal: 26.4ms\tremaining: 26.4ms\n",
      "5:\tlearn: 0.0008321\ttotal: 30.7ms\tremaining: 20.5ms\n",
      "6:\tlearn: 0.0003593\ttotal: 35.7ms\tremaining: 15.3ms\n",
      "7:\tlearn: 0.0001723\ttotal: 40.2ms\tremaining: 10ms\n",
      "8:\tlearn: 0.0000975\ttotal: 44.6ms\tremaining: 4.96ms\n",
      "9:\tlearn: 0.0000643\ttotal: 48.9ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:08:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1270967\ttotal: 14.6ms\tremaining: 131ms\n",
      "1:\tlearn: 0.0426954\ttotal: 25.3ms\tremaining: 101ms\n",
      "2:\tlearn: 0.0153143\ttotal: 32.5ms\tremaining: 75.8ms\n",
      "3:\tlearn: 0.0056277\ttotal: 40.7ms\tremaining: 61.1ms\n",
      "4:\tlearn: 0.0021111\ttotal: 49.1ms\tremaining: 49.1ms\n",
      "5:\tlearn: 0.0008323\ttotal: 57.8ms\tremaining: 38.5ms\n",
      "6:\tlearn: 0.0003594\ttotal: 64.8ms\tremaining: 27.8ms\n",
      "7:\tlearn: 0.0001723\ttotal: 73.9ms\tremaining: 18.5ms\n",
      "8:\tlearn: 0.0000975\ttotal: 81.6ms\tremaining: 9.07ms\n",
      "9:\tlearn: 0.0000643\ttotal: 90.3ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:09:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1270967\ttotal: 4.74ms\tremaining: 42.7ms\n",
      "1:\tlearn: 0.0426954\ttotal: 9.61ms\tremaining: 38.4ms\n",
      "2:\tlearn: 0.0153143\ttotal: 15.1ms\tremaining: 35.2ms\n",
      "3:\tlearn: 0.0056275\ttotal: 23.3ms\tremaining: 34.9ms\n",
      "4:\tlearn: 0.0021113\ttotal: 28.9ms\tremaining: 28.9ms\n",
      "5:\tlearn: 0.0008323\ttotal: 36ms\tremaining: 24ms\n",
      "6:\tlearn: 0.0003595\ttotal: 40.7ms\tremaining: 17.4ms\n",
      "7:\tlearn: 0.0001723\ttotal: 45.6ms\tremaining: 11.4ms\n",
      "8:\tlearn: 0.0000975\ttotal: 52.7ms\tremaining: 5.85ms\n",
      "9:\tlearn: 0.0000643\ttotal: 57.7ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:09:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1280104\ttotal: 1.55ms\tremaining: 13.9ms\n",
      "1:\tlearn: 0.0433949\ttotal: 3.13ms\tremaining: 12.5ms\n",
      "2:\tlearn: 0.0159272\ttotal: 4.71ms\tremaining: 11ms\n",
      "3:\tlearn: 0.0062042\ttotal: 6.32ms\tremaining: 9.49ms\n",
      "4:\tlearn: 0.0026129\ttotal: 9.55ms\tremaining: 9.55ms\n",
      "5:\tlearn: 0.0012617\ttotal: 11.7ms\tremaining: 7.81ms\n",
      "6:\tlearn: 0.0007178\ttotal: 13.2ms\tremaining: 5.66ms\n",
      "7:\tlearn: 0.0004738\ttotal: 14.6ms\tremaining: 3.64ms\n",
      "8:\tlearn: 0.0003462\ttotal: 16ms\tremaining: 1.77ms\n",
      "9:\tlearn: 0.0002686\ttotal: 17.3ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:09:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1280104\ttotal: 1.43ms\tremaining: 12.9ms\n",
      "1:\tlearn: 0.0433938\ttotal: 2.79ms\tremaining: 11.2ms\n",
      "2:\tlearn: 0.0159268\ttotal: 4.09ms\tremaining: 9.54ms\n",
      "3:\tlearn: 0.0062042\ttotal: 5.42ms\tremaining: 8.13ms\n",
      "4:\tlearn: 0.0026103\ttotal: 6.72ms\tremaining: 6.72ms\n",
      "5:\tlearn: 0.0012591\ttotal: 8ms\tremaining: 5.33ms\n",
      "6:\tlearn: 0.0007149\ttotal: 9.26ms\tremaining: 3.97ms\n",
      "7:\tlearn: 0.0004718\ttotal: 10.6ms\tremaining: 2.66ms\n",
      "8:\tlearn: 0.0003447\ttotal: 12ms\tremaining: 1.33ms\n",
      "9:\tlearn: 0.0002694\ttotal: 13.2ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:09:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1280103\ttotal: 1.65ms\tremaining: 14.8ms\n",
      "1:\tlearn: 0.0433949\ttotal: 3.25ms\tremaining: 13ms\n",
      "2:\tlearn: 0.0159271\ttotal: 4.74ms\tremaining: 11.1ms\n",
      "3:\tlearn: 0.0062040\ttotal: 6.46ms\tremaining: 9.69ms\n",
      "4:\tlearn: 0.0026128\ttotal: 7.97ms\tremaining: 7.97ms\n",
      "5:\tlearn: 0.0012616\ttotal: 9.45ms\tremaining: 6.3ms\n",
      "6:\tlearn: 0.0007166\ttotal: 10.9ms\tremaining: 4.69ms\n",
      "7:\tlearn: 0.0004732\ttotal: 12.5ms\tremaining: 3.12ms\n",
      "8:\tlearn: 0.0003459\ttotal: 14ms\tremaining: 1.55ms\n",
      "9:\tlearn: 0.0002703\ttotal: 15.6ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:09:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1280103\ttotal: 2.14ms\tremaining: 19.3ms\n",
      "1:\tlearn: 0.0433945\ttotal: 3.74ms\tremaining: 15ms\n",
      "2:\tlearn: 0.0159268\ttotal: 5.45ms\tremaining: 12.7ms\n",
      "3:\tlearn: 0.0062038\ttotal: 6.99ms\tremaining: 10.5ms\n",
      "4:\tlearn: 0.0026118\ttotal: 8.48ms\tremaining: 8.48ms\n",
      "5:\tlearn: 0.0012607\ttotal: 10ms\tremaining: 6.68ms\n",
      "6:\tlearn: 0.0007149\ttotal: 11.6ms\tremaining: 4.97ms\n",
      "7:\tlearn: 0.0004722\ttotal: 14.3ms\tremaining: 3.57ms\n",
      "8:\tlearn: 0.0003452\ttotal: 17.6ms\tremaining: 1.96ms\n",
      "9:\tlearn: 0.0002684\ttotal: 19.2ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:09:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1280104\ttotal: 8.03ms\tremaining: 72.3ms\n",
      "1:\tlearn: 0.0433955\ttotal: 10.1ms\tremaining: 40.3ms\n",
      "2:\tlearn: 0.0159274\ttotal: 11.8ms\tremaining: 27.5ms\n",
      "3:\tlearn: 0.0062046\ttotal: 16ms\tremaining: 23.9ms\n",
      "4:\tlearn: 0.0026143\ttotal: 19.6ms\tremaining: 19.6ms\n",
      "5:\tlearn: 0.0012632\ttotal: 21.5ms\tremaining: 14.3ms\n",
      "6:\tlearn: 0.0007323\ttotal: 23.4ms\tremaining: 10ms\n",
      "7:\tlearn: 0.0004774\ttotal: 25.2ms\tremaining: 6.3ms\n",
      "8:\tlearn: 0.0003465\ttotal: 27ms\tremaining: 3ms\n",
      "9:\tlearn: 0.0002698\ttotal: 32ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:09:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1275464\ttotal: 2.35ms\tremaining: 21.2ms\n",
      "1:\tlearn: 0.0430443\ttotal: 4.66ms\tremaining: 18.6ms\n",
      "2:\tlearn: 0.0155053\ttotal: 7.1ms\tremaining: 16.6ms\n",
      "3:\tlearn: 0.0058261\ttotal: 9.45ms\tremaining: 14.2ms\n",
      "4:\tlearn: 0.0023427\ttotal: 11.6ms\tremaining: 11.6ms\n",
      "5:\tlearn: 0.0010260\ttotal: 13.9ms\tremaining: 9.24ms\n",
      "6:\tlearn: 0.0004774\ttotal: 16.3ms\tremaining: 6.99ms\n",
      "7:\tlearn: 0.0002670\ttotal: 18.8ms\tremaining: 4.71ms\n",
      "8:\tlearn: 0.0001748\ttotal: 21.2ms\tremaining: 2.35ms\n",
      "9:\tlearn: 0.0001279\ttotal: 23.6ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:09:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1275464\ttotal: 16.8ms\tremaining: 152ms\n",
      "1:\tlearn: 0.0430443\ttotal: 19.1ms\tremaining: 76.4ms\n",
      "2:\tlearn: 0.0155032\ttotal: 21.2ms\tremaining: 49.6ms\n",
      "3:\tlearn: 0.0058223\ttotal: 23.4ms\tremaining: 35.1ms\n",
      "4:\tlearn: 0.0023422\ttotal: 25.6ms\tremaining: 25.6ms\n",
      "5:\tlearn: 0.0010240\ttotal: 28ms\tremaining: 18.6ms\n",
      "6:\tlearn: 0.0004761\ttotal: 30.2ms\tremaining: 12.9ms\n",
      "7:\tlearn: 0.0002666\ttotal: 32.5ms\tremaining: 8.13ms\n",
      "8:\tlearn: 0.0001747\ttotal: 34.8ms\tremaining: 3.87ms\n",
      "9:\tlearn: 0.0001270\ttotal: 37ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:09:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1275464\ttotal: 2.73ms\tremaining: 24.5ms\n",
      "1:\tlearn: 0.0430443\ttotal: 7.79ms\tremaining: 31.2ms\n",
      "2:\tlearn: 0.0155009\ttotal: 10.6ms\tremaining: 24.7ms\n",
      "3:\tlearn: 0.0058193\ttotal: 13.1ms\tremaining: 19.6ms\n",
      "4:\tlearn: 0.0023407\ttotal: 15.6ms\tremaining: 15.6ms\n",
      "5:\tlearn: 0.0010236\ttotal: 18.4ms\tremaining: 12.2ms\n",
      "6:\tlearn: 0.0004761\ttotal: 21.9ms\tremaining: 9.39ms\n",
      "7:\tlearn: 0.0002656\ttotal: 24.7ms\tremaining: 6.18ms\n",
      "8:\tlearn: 0.0001735\ttotal: 27.6ms\tremaining: 3.07ms\n",
      "9:\tlearn: 0.0001263\ttotal: 30.3ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:09:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1275464\ttotal: 2.23ms\tremaining: 20.1ms\n",
      "1:\tlearn: 0.0430443\ttotal: 4.54ms\tremaining: 18.2ms\n",
      "2:\tlearn: 0.0155053\ttotal: 6.71ms\tremaining: 15.7ms\n",
      "3:\tlearn: 0.0058255\ttotal: 8.77ms\tremaining: 13.1ms\n",
      "4:\tlearn: 0.0023434\ttotal: 10.9ms\tremaining: 10.9ms\n",
      "5:\tlearn: 0.0010252\ttotal: 12.9ms\tremaining: 8.62ms\n",
      "6:\tlearn: 0.0004772\ttotal: 15ms\tremaining: 6.42ms\n",
      "7:\tlearn: 0.0002939\ttotal: 17ms\tremaining: 4.26ms\n",
      "8:\tlearn: 0.0001850\ttotal: 19.3ms\tremaining: 2.14ms\n",
      "9:\tlearn: 0.0001378\ttotal: 21.5ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:09:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1275464\ttotal: 3.3ms\tremaining: 29.7ms\n",
      "1:\tlearn: 0.0430443\ttotal: 7.15ms\tremaining: 28.6ms\n",
      "2:\tlearn: 0.0154959\ttotal: 10.2ms\tremaining: 23.7ms\n",
      "3:\tlearn: 0.0058215\ttotal: 13.7ms\tremaining: 20.5ms\n",
      "4:\tlearn: 0.0023421\ttotal: 17.3ms\tremaining: 17.3ms\n",
      "5:\tlearn: 0.0010253\ttotal: 20.8ms\tremaining: 13.9ms\n",
      "6:\tlearn: 0.0004768\ttotal: 23.7ms\tremaining: 10.2ms\n",
      "7:\tlearn: 0.0002937\ttotal: 26.6ms\tremaining: 6.64ms\n",
      "8:\tlearn: 0.0001851\ttotal: 29.7ms\tremaining: 3.3ms\n",
      "9:\tlearn: 0.0001311\ttotal: 34.7ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:09:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1276904\ttotal: 1.81ms\tremaining: 16.3ms\n",
      "1:\tlearn: 0.0431547\ttotal: 3.6ms\tremaining: 14.4ms\n",
      "2:\tlearn: 0.0156844\ttotal: 5.2ms\tremaining: 12.1ms\n",
      "3:\tlearn: 0.0059986\ttotal: 6.93ms\tremaining: 10.4ms\n",
      "4:\tlearn: 0.0024686\ttotal: 8.59ms\tremaining: 8.59ms\n",
      "5:\tlearn: 0.0011456\ttotal: 10.4ms\tremaining: 6.9ms\n",
      "6:\tlearn: 0.0005999\ttotal: 12ms\tremaining: 5.15ms\n",
      "7:\tlearn: 0.0003704\ttotal: 13.6ms\tremaining: 3.41ms\n",
      "8:\tlearn: 0.0002281\ttotal: 15.3ms\tremaining: 1.7ms\n",
      "9:\tlearn: 0.0001803\ttotal: 17ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:10:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1276904\ttotal: 12.4ms\tremaining: 112ms\n",
      "1:\tlearn: 0.0431547\ttotal: 14.4ms\tremaining: 57.5ms\n",
      "2:\tlearn: 0.0156837\ttotal: 16.3ms\tremaining: 37.9ms\n",
      "3:\tlearn: 0.0059983\ttotal: 18.1ms\tremaining: 27.2ms\n",
      "4:\tlearn: 0.0024683\ttotal: 19.9ms\tremaining: 19.9ms\n",
      "5:\tlearn: 0.0011454\ttotal: 21.8ms\tremaining: 14.5ms\n",
      "6:\tlearn: 0.0005995\ttotal: 23.6ms\tremaining: 10.1ms\n",
      "7:\tlearn: 0.0003700\ttotal: 25.4ms\tremaining: 6.35ms\n",
      "8:\tlearn: 0.0002279\ttotal: 27.5ms\tremaining: 3.06ms\n",
      "9:\tlearn: 0.0001800\ttotal: 29.7ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:10:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1276904\ttotal: 11.4ms\tremaining: 103ms\n",
      "1:\tlearn: 0.0431547\ttotal: 13.2ms\tremaining: 52.7ms\n",
      "2:\tlearn: 0.0156834\ttotal: 14.8ms\tremaining: 34.6ms\n",
      "3:\tlearn: 0.0059981\ttotal: 16.4ms\tremaining: 24.6ms\n",
      "4:\tlearn: 0.0024679\ttotal: 18.1ms\tremaining: 18.1ms\n",
      "5:\tlearn: 0.0011448\ttotal: 19.5ms\tremaining: 13ms\n",
      "6:\tlearn: 0.0006002\ttotal: 21.1ms\tremaining: 9.03ms\n",
      "7:\tlearn: 0.0003703\ttotal: 22.6ms\tremaining: 5.66ms\n",
      "8:\tlearn: 0.0002281\ttotal: 24.1ms\tremaining: 2.68ms\n",
      "9:\tlearn: 0.0001802\ttotal: 25.6ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:10:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1276904\ttotal: 1.68ms\tremaining: 15.2ms\n",
      "1:\tlearn: 0.0431548\ttotal: 3.26ms\tremaining: 13.1ms\n",
      "2:\tlearn: 0.0156833\ttotal: 4.92ms\tremaining: 11.5ms\n",
      "3:\tlearn: 0.0059980\ttotal: 6.55ms\tremaining: 9.82ms\n",
      "4:\tlearn: 0.0024679\ttotal: 8.19ms\tremaining: 8.19ms\n",
      "5:\tlearn: 0.0011446\ttotal: 9.74ms\tremaining: 6.49ms\n",
      "6:\tlearn: 0.0005996\ttotal: 11.3ms\tremaining: 4.86ms\n",
      "7:\tlearn: 0.0003694\ttotal: 13ms\tremaining: 3.25ms\n",
      "8:\tlearn: 0.0002275\ttotal: 14.6ms\tremaining: 1.63ms\n",
      "9:\tlearn: 0.0001798\ttotal: 16.3ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:10:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.1276904\ttotal: 1.84ms\tremaining: 16.6ms\n",
      "1:\tlearn: 0.0431547\ttotal: 3.5ms\tremaining: 14ms\n",
      "2:\tlearn: 0.0156809\ttotal: 5.08ms\tremaining: 11.9ms\n",
      "3:\tlearn: 0.0059972\ttotal: 6.61ms\tremaining: 9.92ms\n",
      "4:\tlearn: 0.0024676\ttotal: 8.09ms\tremaining: 8.09ms\n",
      "5:\tlearn: 0.0011448\ttotal: 9.76ms\tremaining: 6.51ms\n",
      "6:\tlearn: 0.0005987\ttotal: 11.3ms\tremaining: 4.84ms\n",
      "7:\tlearn: 0.0003701\ttotal: 12.8ms\tremaining: 3.19ms\n",
      "8:\tlearn: 0.0002279\ttotal: 14.3ms\tremaining: 1.58ms\n",
      "9:\tlearn: 0.0001799\ttotal: 15.8ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    }
   ],
   "source": [
    "data_1=data_type_change(data1)\n",
    "data_2=data2\n",
    "data_3=data_type_change(data3)\n",
    "data_4=data_type_change(data4)\n",
    "data_5=data_type_change(data5)\n",
    "data_6=data_type_change(data6)\n",
    "AUC_table_all=pd.DataFrame()\n",
    "for one_data in [data_1,data_2,data_3,data_4,data_5,data_6]:\n",
    "    AUC_table_in_dataset=pd.DataFrame()\n",
    "    for time in range(0,5) :\n",
    "        AUC_table_in_dataset=pd.concat([AUC_table_in_dataset,set_model_AUC(one_data,True,0.25)],axis=1)\n",
    "    AUC_table_all=pd.concat([AUC_table_all,AUC_table_in_dataset.mean(axis=1)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b86e3c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Arcene</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BlastChar</th>\n",
       "      <th>Shopper</th>\n",
       "      <th>SHrutime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.619629</td>\n",
       "      <td>0.866108</td>\n",
       "      <td>0.622745</td>\n",
       "      <td>0.511902</td>\n",
       "      <td>0.630587</td>\n",
       "      <td>0.506629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LM</th>\n",
       "      <td>0.618982</td>\n",
       "      <td>0.900348</td>\n",
       "      <td>0.711459</td>\n",
       "      <td>0.936378</td>\n",
       "      <td>0.723103</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880962</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.567403</td>\n",
       "      <td>0.768537</td>\n",
       "      <td>0.933518</td>\n",
       "      <td>0.815219</td>\n",
       "      <td>0.905690</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.573949</td>\n",
       "      <td>0.715253</td>\n",
       "      <td>0.502929</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.506843</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Income    Arcene      Bank  BlastChar   Shopper  SHrutime\n",
       "KNN   0.619629  0.866108  0.622745   0.511902  0.630587  0.506629\n",
       "LM    0.618982  0.900348  0.711459   0.936378  0.723103  0.500000\n",
       "RF    1.000000  0.880962  1.000000   1.000000  1.000000  1.000000\n",
       "MLP   0.567403  0.768537  0.933518   0.815219  0.905690  0.500000\n",
       "SVM   0.573949  0.715253  0.502929   0.500000  0.506843  0.500000\n",
       "XGB   1.000000  1.000000  1.000000   1.000000  1.000000  1.000000\n",
       "CAT   1.000000  1.000000  1.000000   1.000000  1.000000  1.000000\n",
       "LGBM  1.000000  1.000000  1.000000   1.000000  1.000000  1.000000"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC_table_all.columns=[\"Income\",\"Arcene\",\"Bank\",\"BlastChar\",\"Shopper\",\"SHrutime\"]\n",
    "AUC_table_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732e3a76",
   "metadata": {},
   "source": [
    "# semi‐supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8db66b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:10:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.5225538\ttotal: 8.18ms\tremaining: 73.6ms\n",
      "1:\tlearn: 0.4432039\ttotal: 8.52ms\tremaining: 34.1ms\n",
      "2:\tlearn: 0.3605193\ttotal: 8.75ms\tremaining: 20.4ms\n",
      "3:\tlearn: 0.3395930\ttotal: 8.99ms\tremaining: 13.5ms\n",
      "4:\tlearn: 0.3316988\ttotal: 9.26ms\tremaining: 9.26ms\n",
      "5:\tlearn: 0.2922636\ttotal: 9.46ms\tremaining: 6.31ms\n",
      "6:\tlearn: 0.2717269\ttotal: 9.66ms\tremaining: 4.14ms\n",
      "7:\tlearn: 0.2608563\ttotal: 9.85ms\tremaining: 2.46ms\n",
      "8:\tlearn: 0.2385462\ttotal: 10ms\tremaining: 1.11ms\n",
      "9:\tlearn: 0.2209228\ttotal: 10.2ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:10:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.5726303\ttotal: 376us\tremaining: 3.38ms\n",
      "1:\tlearn: 0.5036356\ttotal: 690us\tremaining: 2.76ms\n",
      "2:\tlearn: 0.4196716\ttotal: 901us\tremaining: 2.1ms\n",
      "3:\tlearn: 0.3583088\ttotal: 1.22ms\tremaining: 1.82ms\n",
      "4:\tlearn: 0.3222525\ttotal: 1.44ms\tremaining: 1.44ms\n",
      "5:\tlearn: 0.2721374\ttotal: 1.67ms\tremaining: 1.11ms\n",
      "6:\tlearn: 0.2520968\ttotal: 1.88ms\tremaining: 805us\n",
      "7:\tlearn: 0.2184319\ttotal: 2.09ms\tremaining: 522us\n",
      "8:\tlearn: 0.2017259\ttotal: 2.3ms\tremaining: 255us\n",
      "9:\tlearn: 0.1940117\ttotal: 2.51ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:10:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.4891543\ttotal: 336us\tremaining: 3.03ms\n",
      "1:\tlearn: 0.3833185\ttotal: 704us\tremaining: 2.82ms\n",
      "2:\tlearn: 0.3107604\ttotal: 1.01ms\tremaining: 2.36ms\n",
      "3:\tlearn: 0.2341610\ttotal: 1.29ms\tremaining: 1.93ms\n",
      "4:\tlearn: 0.1889227\ttotal: 1.51ms\tremaining: 1.51ms\n",
      "5:\tlearn: 0.1524910\ttotal: 1.75ms\tremaining: 1.17ms\n",
      "6:\tlearn: 0.1396017\ttotal: 2.02ms\tremaining: 865us\n",
      "7:\tlearn: 0.1338824\ttotal: 2.25ms\tremaining: 563us\n",
      "8:\tlearn: 0.1207025\ttotal: 2.47ms\tremaining: 274us\n",
      "9:\tlearn: 0.1159048\ttotal: 2.72ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:10:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.4824192\ttotal: 8.3ms\tremaining: 74.7ms\n",
      "1:\tlearn: 0.4531771\ttotal: 8.66ms\tremaining: 34.6ms\n",
      "2:\tlearn: 0.4191586\ttotal: 8.96ms\tremaining: 20.9ms\n",
      "3:\tlearn: 0.3729748\ttotal: 9.27ms\tremaining: 13.9ms\n",
      "4:\tlearn: 0.3651113\ttotal: 9.51ms\tremaining: 9.51ms\n",
      "5:\tlearn: 0.2849635\ttotal: 9.79ms\tremaining: 6.53ms\n",
      "6:\tlearn: 0.2741564\ttotal: 9.99ms\tremaining: 4.28ms\n",
      "7:\tlearn: 0.2643273\ttotal: 10.2ms\tremaining: 2.56ms\n",
      "8:\tlearn: 0.2350933\ttotal: 10.6ms\tremaining: 1.17ms\n",
      "9:\tlearn: 0.2160385\ttotal: 10.8ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:10:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.5165152\ttotal: 313us\tremaining: 2.82ms\n",
      "1:\tlearn: 0.4792571\ttotal: 624us\tremaining: 2.5ms\n",
      "2:\tlearn: 0.4642162\ttotal: 855us\tremaining: 2ms\n",
      "3:\tlearn: 0.4494676\ttotal: 1.16ms\tremaining: 1.74ms\n",
      "4:\tlearn: 0.3964342\ttotal: 1.38ms\tremaining: 1.38ms\n",
      "5:\tlearn: 0.3752815\ttotal: 1.6ms\tremaining: 1.06ms\n",
      "6:\tlearn: 0.3670142\ttotal: 1.82ms\tremaining: 779us\n",
      "7:\tlearn: 0.3439803\ttotal: 2.03ms\tremaining: 506us\n",
      "8:\tlearn: 0.3294563\ttotal: 2.23ms\tremaining: 247us\n",
      "9:\tlearn: 0.3168986\ttotal: 2.43ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:10:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.4915293\ttotal: 63ms\tremaining: 567ms\n",
      "1:\tlearn: 0.3853737\ttotal: 87.7ms\tremaining: 351ms\n",
      "2:\tlearn: 0.3209252\ttotal: 112ms\tremaining: 262ms\n",
      "3:\tlearn: 0.2919695\ttotal: 137ms\tremaining: 206ms\n",
      "4:\tlearn: 0.2570790\ttotal: 163ms\tremaining: 163ms\n",
      "5:\tlearn: 0.1976661\ttotal: 188ms\tremaining: 125ms\n",
      "6:\tlearn: 0.1568831\ttotal: 214ms\tremaining: 91.7ms\n",
      "7:\tlearn: 0.1294295\ttotal: 241ms\tremaining: 60.1ms\n",
      "8:\tlearn: 0.1021524\ttotal: 268ms\tremaining: 29.7ms\n",
      "9:\tlearn: 0.0809784\ttotal: 305ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:10:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.5852918\ttotal: 81.2ms\tremaining: 730ms\n",
      "1:\tlearn: 0.5357673\ttotal: 119ms\tremaining: 475ms\n",
      "2:\tlearn: 0.4877306\ttotal: 148ms\tremaining: 345ms\n",
      "3:\tlearn: 0.4401704\ttotal: 176ms\tremaining: 264ms\n",
      "4:\tlearn: 0.3341409\ttotal: 205ms\tremaining: 205ms\n",
      "5:\tlearn: 0.2634588\ttotal: 265ms\tremaining: 177ms\n",
      "6:\tlearn: 0.2157975\ttotal: 312ms\tremaining: 134ms\n",
      "7:\tlearn: 0.1727044\ttotal: 339ms\tremaining: 84.8ms\n",
      "8:\tlearn: 0.1512428\ttotal: 373ms\tremaining: 41.5ms\n",
      "9:\tlearn: 0.1084153\ttotal: 401ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:10:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.4454943\ttotal: 77.6ms\tremaining: 699ms\n",
      "1:\tlearn: 0.3603969\ttotal: 111ms\tremaining: 443ms\n",
      "2:\tlearn: 0.3018290\ttotal: 138ms\tremaining: 323ms\n",
      "3:\tlearn: 0.2852706\ttotal: 165ms\tremaining: 248ms\n",
      "4:\tlearn: 0.2217326\ttotal: 194ms\tremaining: 194ms\n",
      "5:\tlearn: 0.1742720\ttotal: 223ms\tremaining: 149ms\n",
      "6:\tlearn: 0.1519383\ttotal: 252ms\tremaining: 108ms\n",
      "7:\tlearn: 0.1273768\ttotal: 288ms\tremaining: 72.1ms\n",
      "8:\tlearn: 0.0879246\ttotal: 324ms\tremaining: 36ms\n",
      "9:\tlearn: 0.0671441\ttotal: 365ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:10:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.5297909\ttotal: 49.1ms\tremaining: 442ms\n",
      "1:\tlearn: 0.4500405\ttotal: 74.9ms\tremaining: 300ms\n",
      "2:\tlearn: 0.3506118\ttotal: 101ms\tremaining: 236ms\n",
      "3:\tlearn: 0.2359659\ttotal: 128ms\tremaining: 192ms\n",
      "4:\tlearn: 0.2193297\ttotal: 160ms\tremaining: 160ms\n",
      "5:\tlearn: 0.1649906\ttotal: 187ms\tremaining: 125ms\n",
      "6:\tlearn: 0.1234147\ttotal: 214ms\tremaining: 91.7ms\n",
      "7:\tlearn: 0.1030457\ttotal: 241ms\tremaining: 60.4ms\n",
      "8:\tlearn: 0.0888145\ttotal: 270ms\tremaining: 30ms\n",
      "9:\tlearn: 0.0770072\ttotal: 298ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:10:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.4307614\ttotal: 67.5ms\tremaining: 608ms\n",
      "1:\tlearn: 0.3883144\ttotal: 92.1ms\tremaining: 368ms\n",
      "2:\tlearn: 0.3352003\ttotal: 118ms\tremaining: 275ms\n",
      "3:\tlearn: 0.2739400\ttotal: 153ms\tremaining: 230ms\n",
      "4:\tlearn: 0.2063555\ttotal: 185ms\tremaining: 185ms\n",
      "5:\tlearn: 0.1704987\ttotal: 218ms\tremaining: 146ms\n",
      "6:\tlearn: 0.1233415\ttotal: 251ms\tremaining: 108ms\n",
      "7:\tlearn: 0.1038556\ttotal: 285ms\tremaining: 71.2ms\n",
      "8:\tlearn: 0.0836344\ttotal: 327ms\tremaining: 36.3ms\n",
      "9:\tlearn: 0.0696795\ttotal: 360ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:10:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.4209086\ttotal: 334us\tremaining: 3.01ms\n",
      "1:\tlearn: 0.3606859\ttotal: 670us\tremaining: 2.68ms\n",
      "2:\tlearn: 0.2948543\ttotal: 936us\tremaining: 2.18ms\n",
      "3:\tlearn: 0.2738448\ttotal: 1.25ms\tremaining: 1.88ms\n",
      "4:\tlearn: 0.2524115\ttotal: 1.56ms\tremaining: 1.56ms\n",
      "5:\tlearn: 0.2417536\ttotal: 1.82ms\tremaining: 1.21ms\n",
      "6:\tlearn: 0.2144646\ttotal: 2.12ms\tremaining: 909us\n",
      "7:\tlearn: 0.1747334\ttotal: 2.34ms\tremaining: 585us\n",
      "8:\tlearn: 0.1482464\ttotal: 2.57ms\tremaining: 285us\n",
      "9:\tlearn: 0.1383509\ttotal: 2.78ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:10:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.3593249\ttotal: 293us\tremaining: 2.64ms\n",
      "1:\tlearn: 0.2813139\ttotal: 587us\tremaining: 2.35ms\n",
      "2:\tlearn: 0.2052492\ttotal: 837us\tremaining: 1.96ms\n",
      "3:\tlearn: 0.1917485\ttotal: 1.04ms\tremaining: 1.57ms\n",
      "4:\tlearn: 0.1748165\ttotal: 1.26ms\tremaining: 1.26ms\n",
      "5:\tlearn: 0.1577825\ttotal: 1.46ms\tremaining: 971us\n",
      "6:\tlearn: 0.1515769\ttotal: 1.69ms\tremaining: 723us\n",
      "7:\tlearn: 0.1065879\ttotal: 1.92ms\tremaining: 479us\n",
      "8:\tlearn: 0.0974560\ttotal: 2.15ms\tremaining: 239us\n",
      "9:\tlearn: 0.0893896\ttotal: 2.37ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:10:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.3133205\ttotal: 335us\tremaining: 3.02ms\n",
      "1:\tlearn: 0.2464927\ttotal: 680us\tremaining: 2.72ms\n",
      "2:\tlearn: 0.1839729\ttotal: 967us\tremaining: 2.26ms\n",
      "3:\tlearn: 0.1659766\ttotal: 1.2ms\tremaining: 1.8ms\n",
      "4:\tlearn: 0.1525832\ttotal: 1.43ms\tremaining: 1.43ms\n",
      "5:\tlearn: 0.1311105\ttotal: 1.65ms\tremaining: 1.1ms\n",
      "6:\tlearn: 0.1187435\ttotal: 2ms\tremaining: 858us\n",
      "7:\tlearn: 0.0960330\ttotal: 2.21ms\tremaining: 551us\n",
      "8:\tlearn: 0.0835088\ttotal: 2.44ms\tremaining: 271us\n",
      "9:\tlearn: 0.0740621\ttotal: 2.66ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.3840682\ttotal: 321us\tremaining: 2.89ms\n",
      "1:\tlearn: 0.3290891\ttotal: 632us\tremaining: 2.53ms\n",
      "2:\tlearn: 0.2263941\ttotal: 848us\tremaining: 1.98ms\n",
      "3:\tlearn: 0.1834372\ttotal: 1.11ms\tremaining: 1.67ms\n",
      "4:\tlearn: 0.1753963\ttotal: 1.32ms\tremaining: 1.32ms\n",
      "5:\tlearn: 0.1660782\ttotal: 1.53ms\tremaining: 1.02ms\n",
      "6:\tlearn: 0.1506913\ttotal: 1.73ms\tremaining: 743us\n",
      "7:\tlearn: 0.1390193\ttotal: 1.96ms\tremaining: 489us\n",
      "8:\tlearn: 0.1080965\ttotal: 2.17ms\tremaining: 241us\n",
      "9:\tlearn: 0.0863428\ttotal: 2.37ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.3402779\ttotal: 293us\tremaining: 2.64ms\n",
      "1:\tlearn: 0.2480066\ttotal: 581us\tremaining: 2.33ms\n",
      "2:\tlearn: 0.2060514\ttotal: 778us\tremaining: 1.81ms\n",
      "3:\tlearn: 0.1616162\ttotal: 1.04ms\tremaining: 1.56ms\n",
      "4:\tlearn: 0.1540654\ttotal: 1.26ms\tremaining: 1.26ms\n",
      "5:\tlearn: 0.1337491\ttotal: 1.48ms\tremaining: 983us\n",
      "6:\tlearn: 0.1277524\ttotal: 1.68ms\tremaining: 721us\n",
      "7:\tlearn: 0.1191221\ttotal: 1.89ms\tremaining: 472us\n",
      "8:\tlearn: 0.1052497\ttotal: 2.1ms\tremaining: 233us\n",
      "9:\tlearn: 0.0894456\ttotal: 2.31ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.4847863\ttotal: 355us\tremaining: 3.2ms\n",
      "1:\tlearn: 0.4272014\ttotal: 805us\tremaining: 3.22ms\n",
      "2:\tlearn: 0.4148750\ttotal: 1.11ms\tremaining: 2.6ms\n",
      "3:\tlearn: 0.3998437\ttotal: 1.36ms\tremaining: 2.04ms\n",
      "4:\tlearn: 0.3797503\ttotal: 1.64ms\tremaining: 1.64ms\n",
      "5:\tlearn: 0.3237950\ttotal: 1.86ms\tremaining: 1.24ms\n",
      "6:\tlearn: 0.3038337\ttotal: 2.11ms\tremaining: 904us\n",
      "7:\tlearn: 0.2871755\ttotal: 2.34ms\tremaining: 585us\n",
      "8:\tlearn: 0.2835990\ttotal: 2.55ms\tremaining: 283us\n",
      "9:\tlearn: 0.2720704\ttotal: 2.8ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.5932971\ttotal: 449us\tremaining: 4.04ms\n",
      "1:\tlearn: 0.4862540\ttotal: 813us\tremaining: 3.25ms\n",
      "2:\tlearn: 0.4383993\ttotal: 1.06ms\tremaining: 2.47ms\n",
      "3:\tlearn: 0.4265491\ttotal: 1.31ms\tremaining: 1.96ms\n",
      "4:\tlearn: 0.3621434\ttotal: 1.53ms\tremaining: 1.53ms\n",
      "5:\tlearn: 0.3424402\ttotal: 1.78ms\tremaining: 1.19ms\n",
      "6:\tlearn: 0.3187295\ttotal: 2ms\tremaining: 855us\n",
      "7:\tlearn: 0.2972598\ttotal: 2.23ms\tremaining: 556us\n",
      "8:\tlearn: 0.2664004\ttotal: 2.44ms\tremaining: 271us\n",
      "9:\tlearn: 0.2540088\ttotal: 2.67ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.4392199\ttotal: 299us\tremaining: 2.7ms\n",
      "1:\tlearn: 0.3807426\ttotal: 646us\tremaining: 2.59ms\n",
      "2:\tlearn: 0.3077454\ttotal: 930us\tremaining: 2.17ms\n",
      "3:\tlearn: 0.2592390\ttotal: 1.16ms\tremaining: 1.74ms\n",
      "4:\tlearn: 0.2481582\ttotal: 1.5ms\tremaining: 1.5ms\n",
      "5:\tlearn: 0.2263895\ttotal: 1.72ms\tremaining: 1.15ms\n",
      "6:\tlearn: 0.2103155\ttotal: 1.94ms\tremaining: 829us\n",
      "7:\tlearn: 0.1730517\ttotal: 2.14ms\tremaining: 535us\n",
      "8:\tlearn: 0.1653310\ttotal: 2.38ms\tremaining: 264us\n",
      "9:\tlearn: 0.1561582\ttotal: 2.59ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.5401615\ttotal: 343us\tremaining: 3.1ms\n",
      "1:\tlearn: 0.4476627\ttotal: 677us\tremaining: 2.71ms\n",
      "2:\tlearn: 0.4090605\ttotal: 971us\tremaining: 2.27ms\n",
      "3:\tlearn: 0.3831400\ttotal: 1.23ms\tremaining: 1.84ms\n",
      "4:\tlearn: 0.3753138\ttotal: 1.48ms\tremaining: 1.48ms\n",
      "5:\tlearn: 0.3326692\ttotal: 1.74ms\tremaining: 1.16ms\n",
      "6:\tlearn: 0.3116375\ttotal: 1.98ms\tremaining: 846us\n",
      "7:\tlearn: 0.3010649\ttotal: 2.23ms\tremaining: 557us\n",
      "8:\tlearn: 0.2866317\ttotal: 2.47ms\tremaining: 274us\n",
      "9:\tlearn: 0.2642646\ttotal: 2.7ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.4962226\ttotal: 343us\tremaining: 3.09ms\n",
      "1:\tlearn: 0.4022295\ttotal: 684us\tremaining: 2.74ms\n",
      "2:\tlearn: 0.3429144\ttotal: 974us\tremaining: 2.27ms\n",
      "3:\tlearn: 0.3150862\ttotal: 1.23ms\tremaining: 1.85ms\n",
      "4:\tlearn: 0.2733679\ttotal: 1.45ms\tremaining: 1.45ms\n",
      "5:\tlearn: 0.2564844\ttotal: 1.75ms\tremaining: 1.16ms\n",
      "6:\tlearn: 0.2149146\ttotal: 2.03ms\tremaining: 870us\n",
      "7:\tlearn: 0.2013514\ttotal: 2.3ms\tremaining: 575us\n",
      "8:\tlearn: 0.1912803\ttotal: 2.53ms\tremaining: 280us\n",
      "9:\tlearn: 0.1724769\ttotal: 2.74ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.4005966\ttotal: 312us\tremaining: 2.81ms\n",
      "1:\tlearn: 0.3333318\ttotal: 688us\tremaining: 2.75ms\n",
      "2:\tlearn: 0.2654010\ttotal: 958us\tremaining: 2.24ms\n",
      "3:\tlearn: 0.2101211\ttotal: 1.2ms\tremaining: 1.8ms\n",
      "4:\tlearn: 0.1811740\ttotal: 1.44ms\tremaining: 1.44ms\n",
      "5:\tlearn: 0.1610798\ttotal: 1.63ms\tremaining: 1.09ms\n",
      "6:\tlearn: 0.1337428\ttotal: 1.83ms\tremaining: 785us\n",
      "7:\tlearn: 0.1212270\ttotal: 2.03ms\tremaining: 507us\n",
      "8:\tlearn: 0.1058215\ttotal: 2.24ms\tremaining: 248us\n",
      "9:\tlearn: 0.0921531\ttotal: 2.45ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.4237413\ttotal: 26.9ms\tremaining: 242ms\n",
      "1:\tlearn: 0.3182607\ttotal: 27.3ms\tremaining: 109ms\n",
      "2:\tlearn: 0.2682677\ttotal: 27.5ms\tremaining: 64.2ms\n",
      "3:\tlearn: 0.1914193\ttotal: 27.7ms\tremaining: 41.6ms\n",
      "4:\tlearn: 0.1634334\ttotal: 27.9ms\tremaining: 27.9ms\n",
      "5:\tlearn: 0.1289913\ttotal: 28.1ms\tremaining: 18.8ms\n",
      "6:\tlearn: 0.0993761\ttotal: 28.3ms\tremaining: 12.1ms\n",
      "7:\tlearn: 0.0939015\ttotal: 28.5ms\tremaining: 7.13ms\n",
      "8:\tlearn: 0.0885217\ttotal: 28.7ms\tremaining: 3.19ms\n",
      "9:\tlearn: 0.0845921\ttotal: 28.9ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.3935788\ttotal: 292us\tremaining: 2.64ms\n",
      "1:\tlearn: 0.2979603\ttotal: 673us\tremaining: 2.69ms\n",
      "2:\tlearn: 0.2856268\ttotal: 916us\tremaining: 2.14ms\n",
      "3:\tlearn: 0.2021178\ttotal: 1.21ms\tremaining: 1.82ms\n",
      "4:\tlearn: 0.1450915\ttotal: 2.35ms\tremaining: 2.35ms\n",
      "5:\tlearn: 0.1300467\ttotal: 2.88ms\tremaining: 1.92ms\n",
      "6:\tlearn: 0.1088008\ttotal: 3.18ms\tremaining: 1.36ms\n",
      "7:\tlearn: 0.1019505\ttotal: 3.5ms\tremaining: 875us\n",
      "8:\tlearn: 0.0964385\ttotal: 3.76ms\tremaining: 417us\n",
      "9:\tlearn: 0.0891824\ttotal: 3.97ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.2464542\ttotal: 325us\tremaining: 2.93ms\n",
      "1:\tlearn: 0.2197644\ttotal: 688us\tremaining: 2.75ms\n",
      "2:\tlearn: 0.1550091\ttotal: 957us\tremaining: 2.23ms\n",
      "3:\tlearn: 0.1127086\ttotal: 1.19ms\tremaining: 1.78ms\n",
      "4:\tlearn: 0.1121222\ttotal: 1.43ms\tremaining: 1.43ms\n",
      "5:\tlearn: 0.0985961\ttotal: 1.65ms\tremaining: 1.1ms\n",
      "6:\tlearn: 0.0816998\ttotal: 1.87ms\tremaining: 802us\n",
      "7:\tlearn: 0.0734780\ttotal: 2.1ms\tremaining: 524us\n",
      "8:\tlearn: 0.0591953\ttotal: 2.32ms\tremaining: 257us\n",
      "9:\tlearn: 0.0520594\ttotal: 2.53ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.3752992\ttotal: 322us\tremaining: 2.91ms\n",
      "1:\tlearn: 0.3315776\ttotal: 651us\tremaining: 2.6ms\n",
      "2:\tlearn: 0.2848633\ttotal: 919us\tremaining: 2.15ms\n",
      "3:\tlearn: 0.2650628\ttotal: 1.21ms\tremaining: 1.81ms\n",
      "4:\tlearn: 0.2399432\ttotal: 1.44ms\tremaining: 1.44ms\n",
      "5:\tlearn: 0.2240723\ttotal: 1.66ms\tremaining: 1.11ms\n",
      "6:\tlearn: 0.2013782\ttotal: 1.89ms\tremaining: 810us\n",
      "7:\tlearn: 0.1914494\ttotal: 2.12ms\tremaining: 530us\n",
      "8:\tlearn: 0.1661204\ttotal: 2.35ms\tremaining: 261us\n",
      "9:\tlearn: 0.1348531\ttotal: 2.58ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.4698532\ttotal: 317us\tremaining: 2.86ms\n",
      "1:\tlearn: 0.4093370\ttotal: 651us\tremaining: 2.6ms\n",
      "2:\tlearn: 0.3946029\ttotal: 923us\tremaining: 2.15ms\n",
      "3:\tlearn: 0.2415154\ttotal: 1.14ms\tremaining: 1.71ms\n",
      "4:\tlearn: 0.2171714\ttotal: 1.37ms\tremaining: 1.37ms\n",
      "5:\tlearn: 0.2067695\ttotal: 1.59ms\tremaining: 1.06ms\n",
      "6:\tlearn: 0.1736775\ttotal: 1.79ms\tremaining: 769us\n",
      "7:\tlearn: 0.1570599\ttotal: 1.99ms\tremaining: 496us\n",
      "8:\tlearn: 0.1431542\ttotal: 2.19ms\tremaining: 243us\n",
      "9:\tlearn: 0.1324258\ttotal: 2.4ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.5153464\ttotal: 405us\tremaining: 3.65ms\n",
      "1:\tlearn: 0.4651804\ttotal: 680us\tremaining: 2.72ms\n",
      "2:\tlearn: 0.4001457\ttotal: 949us\tremaining: 2.21ms\n",
      "3:\tlearn: 0.3688738\ttotal: 1.17ms\tremaining: 1.75ms\n",
      "4:\tlearn: 0.2611025\ttotal: 1.39ms\tremaining: 1.39ms\n",
      "5:\tlearn: 0.2186993\ttotal: 1.62ms\tremaining: 1.08ms\n",
      "6:\tlearn: 0.1928124\ttotal: 1.85ms\tremaining: 794us\n",
      "7:\tlearn: 0.1743139\ttotal: 2.15ms\tremaining: 536us\n",
      "8:\tlearn: 0.1425418\ttotal: 2.4ms\tremaining: 266us\n",
      "9:\tlearn: 0.1347381\ttotal: 2.6ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.3968626\ttotal: 307us\tremaining: 2.77ms\n",
      "1:\tlearn: 0.2913770\ttotal: 625us\tremaining: 2.5ms\n",
      "2:\tlearn: 0.2461577\ttotal: 883us\tremaining: 2.06ms\n",
      "3:\tlearn: 0.2145545\ttotal: 1.13ms\tremaining: 1.7ms\n",
      "4:\tlearn: 0.1988590\ttotal: 1.36ms\tremaining: 1.36ms\n",
      "5:\tlearn: 0.1733135\ttotal: 1.57ms\tremaining: 1.05ms\n",
      "6:\tlearn: 0.1616581\ttotal: 1.78ms\tremaining: 762us\n",
      "7:\tlearn: 0.1548784\ttotal: 2.01ms\tremaining: 503us\n",
      "8:\tlearn: 0.1423606\ttotal: 2.22ms\tremaining: 246us\n",
      "9:\tlearn: 0.1286170\ttotal: 2.42ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.5291334\ttotal: 345us\tremaining: 3.11ms\n",
      "1:\tlearn: 0.4646265\ttotal: 693us\tremaining: 2.77ms\n",
      "2:\tlearn: 0.3597953\ttotal: 963us\tremaining: 2.25ms\n",
      "3:\tlearn: 0.3300045\ttotal: 1.19ms\tremaining: 1.78ms\n",
      "4:\tlearn: 0.2720470\ttotal: 1.41ms\tremaining: 1.41ms\n",
      "5:\tlearn: 0.2407459\ttotal: 1.61ms\tremaining: 1.07ms\n",
      "6:\tlearn: 0.2356295\ttotal: 1.83ms\tremaining: 784us\n",
      "7:\tlearn: 0.2285680\ttotal: 2.04ms\tremaining: 511us\n",
      "8:\tlearn: 0.2185825\ttotal: 2.25ms\tremaining: 249us\n",
      "9:\tlearn: 0.2039838\ttotal: 2.44ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[00:11:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.5201139\ttotal: 291us\tremaining: 2.62ms\n",
      "1:\tlearn: 0.4654042\ttotal: 635us\tremaining: 2.54ms\n",
      "2:\tlearn: 0.3880476\ttotal: 935us\tremaining: 2.18ms\n",
      "3:\tlearn: 0.3152147\ttotal: 1.18ms\tremaining: 1.77ms\n",
      "4:\tlearn: 0.2826762\ttotal: 1.41ms\tremaining: 1.41ms\n",
      "5:\tlearn: 0.2419670\ttotal: 1.65ms\tremaining: 1.1ms\n",
      "6:\tlearn: 0.2148921\ttotal: 1.87ms\tremaining: 802us\n",
      "7:\tlearn: 0.1944253\ttotal: 2.07ms\tremaining: 518us\n",
      "8:\tlearn: 0.1861416\ttotal: 2.29ms\tremaining: 254us\n",
      "9:\tlearn: 0.1711884\ttotal: 2.61ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "data_1=data_type_change(data1)\n",
    "data_2=data2\n",
    "data_3=data_type_change(data3)\n",
    "data_4=data_type_change(data4)\n",
    "data_5=data_type_change(data5)\n",
    "data_6=data_type_change(data6)\n",
    "accuracy_table_all=pd.DataFrame()\n",
    "for one_data in [data_1,data_2,data_3,data_4,data_5,data_6]:\n",
    "    accuracy_table_in_dataset=pd.DataFrame()\n",
    "    for time in range(0,5) :\n",
    "        accuracy_table_in_dataset=pd.concat([accuracy_table_in_dataset,set_model_accuracy(one_data,False,0.9992)],axis=1)\n",
    "    accuracy_table_all=pd.concat([accuracy_table_all,accuracy_table_in_dataset.mean(axis=1)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3a4c2d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Arcene</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BlastChar</th>\n",
       "      <th>Shopper</th>\n",
       "      <th>SHrutime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.683430</td>\n",
       "      <td>0.672230</td>\n",
       "      <td>0.880649</td>\n",
       "      <td>0.724181</td>\n",
       "      <td>0.818795</td>\n",
       "      <td>0.767719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LM</th>\n",
       "      <td>0.749057</td>\n",
       "      <td>0.749959</td>\n",
       "      <td>0.851996</td>\n",
       "      <td>0.727699</td>\n",
       "      <td>0.833550</td>\n",
       "      <td>0.766372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.785789</td>\n",
       "      <td>0.665389</td>\n",
       "      <td>0.881460</td>\n",
       "      <td>0.742571</td>\n",
       "      <td>0.866743</td>\n",
       "      <td>0.793427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.557799</td>\n",
       "      <td>0.566420</td>\n",
       "      <td>0.802081</td>\n",
       "      <td>0.708080</td>\n",
       "      <td>0.821792</td>\n",
       "      <td>0.796302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.626668</td>\n",
       "      <td>0.880175</td>\n",
       "      <td>0.734477</td>\n",
       "      <td>0.842378</td>\n",
       "      <td>0.796302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>0.751186</td>\n",
       "      <td>0.657315</td>\n",
       "      <td>0.867656</td>\n",
       "      <td>0.711083</td>\n",
       "      <td>0.859511</td>\n",
       "      <td>0.772000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT</th>\n",
       "      <td>0.764763</td>\n",
       "      <td>0.623950</td>\n",
       "      <td>0.872935</td>\n",
       "      <td>0.715516</td>\n",
       "      <td>0.862182</td>\n",
       "      <td>0.782090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM</th>\n",
       "      <td>0.753443</td>\n",
       "      <td>0.644537</td>\n",
       "      <td>0.865264</td>\n",
       "      <td>0.738367</td>\n",
       "      <td>0.814528</td>\n",
       "      <td>0.780161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Income    Arcene      Bank  BlastChar   Shopper  SHrutime\n",
       "KNN   0.683430  0.672230  0.880649   0.724181  0.818795  0.767719\n",
       "LM    0.749057  0.749959  0.851996   0.727699  0.833550  0.766372\n",
       "RF    0.785789  0.665389  0.881460   0.742571  0.866743  0.793427\n",
       "MLP   0.557799  0.566420  0.802081   0.708080  0.821792  0.796302\n",
       "SVM   0.758937  0.626668  0.880175   0.734477  0.842378  0.796302\n",
       "XGB   0.751186  0.657315  0.867656   0.711083  0.859511  0.772000\n",
       "CAT   0.764763  0.623950  0.872935   0.715516  0.862182  0.782090\n",
       "LGBM  0.753443  0.644537  0.865264   0.738367  0.814528  0.780161"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_table_all.columns=[\"Income\",\"Arcene\",\"Bank\",\"BlastChar\",\"Shopper\",\"SHrutime\"]\n",
    "accuracy_table_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cc7e0982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.4159550\ttotal: 266us\tremaining: 2.4ms\n",
      "1:\tlearn: 0.3686011\ttotal: 521us\tremaining: 2.08ms\n",
      "2:\tlearn: 0.3553571\ttotal: 855us\tremaining: 2ms\n",
      "3:\tlearn: 0.2899142\ttotal: 1.09ms\tremaining: 1.64ms\n",
      "4:\tlearn: 0.2330745\ttotal: 1.26ms\tremaining: 1.26ms\n",
      "5:\tlearn: 0.2109643\ttotal: 1.48ms\tremaining: 987us\n",
      "6:\tlearn: 0.1946261\ttotal: 1.66ms\tremaining: 711us\n",
      "7:\tlearn: 0.1492867\ttotal: 1.84ms\tremaining: 460us\n",
      "8:\tlearn: 0.1387435\ttotal: 2.03ms\tremaining: 225us\n",
      "9:\tlearn: 0.1245562\ttotal: 2.21ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.4559778\ttotal: 12.9ms\tremaining: 116ms\n",
      "1:\tlearn: 0.3993390\ttotal: 13.2ms\tremaining: 52.8ms\n",
      "2:\tlearn: 0.3841879\ttotal: 13.4ms\tremaining: 31.2ms\n",
      "3:\tlearn: 0.3721836\ttotal: 13.6ms\tremaining: 20.4ms\n",
      "4:\tlearn: 0.3465589\ttotal: 13.8ms\tremaining: 13.8ms\n",
      "5:\tlearn: 0.3258759\ttotal: 13.9ms\tremaining: 9.29ms\n",
      "6:\tlearn: 0.3217362\ttotal: 14.1ms\tremaining: 6.05ms\n",
      "7:\tlearn: 0.3049146\ttotal: 14.3ms\tremaining: 3.57ms\n",
      "8:\tlearn: 0.2862074\ttotal: 14.5ms\tremaining: 1.61ms\n",
      "9:\tlearn: 0.2656315\ttotal: 14.6ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.4783277\ttotal: 290us\tremaining: 2.61ms\n",
      "1:\tlearn: 0.3781505\ttotal: 577us\tremaining: 2.31ms\n",
      "2:\tlearn: 0.3269927\ttotal: 782us\tremaining: 1.83ms\n",
      "3:\tlearn: 0.3118154\ttotal: 1ms\tremaining: 1.51ms\n",
      "4:\tlearn: 0.2675596\ttotal: 1.21ms\tremaining: 1.21ms\n",
      "5:\tlearn: 0.2610732\ttotal: 1.39ms\tremaining: 926us\n",
      "6:\tlearn: 0.2272579\ttotal: 1.59ms\tremaining: 680us\n",
      "7:\tlearn: 0.2219908\ttotal: 1.76ms\tremaining: 439us\n",
      "8:\tlearn: 0.1955057\ttotal: 1.96ms\tremaining: 217us\n",
      "9:\tlearn: 0.1877184\ttotal: 2.15ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.5857573\ttotal: 294us\tremaining: 2.65ms\n",
      "1:\tlearn: 0.4786014\ttotal: 576us\tremaining: 2.31ms\n",
      "2:\tlearn: 0.4469935\ttotal: 747us\tremaining: 1.75ms\n",
      "3:\tlearn: 0.3808929\ttotal: 908us\tremaining: 1.36ms\n",
      "4:\tlearn: 0.3463193\ttotal: 1.07ms\tremaining: 1.07ms\n",
      "5:\tlearn: 0.3012938\ttotal: 1.23ms\tremaining: 819us\n",
      "6:\tlearn: 0.2605319\ttotal: 1.4ms\tremaining: 598us\n",
      "7:\tlearn: 0.2321757\ttotal: 1.57ms\tremaining: 392us\n",
      "8:\tlearn: 0.2182873\ttotal: 1.78ms\tremaining: 198us\n",
      "9:\tlearn: 0.2064457\ttotal: 1.95ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.4714729\ttotal: 277us\tremaining: 2.5ms\n",
      "1:\tlearn: 0.3604091\ttotal: 551us\tremaining: 2.2ms\n",
      "2:\tlearn: 0.3417000\ttotal: 775us\tremaining: 1.81ms\n",
      "3:\tlearn: 0.3287717\ttotal: 970us\tremaining: 1.46ms\n",
      "4:\tlearn: 0.3157769\ttotal: 1.15ms\tremaining: 1.15ms\n",
      "5:\tlearn: 0.2930031\ttotal: 1.34ms\tremaining: 896us\n",
      "6:\tlearn: 0.2618038\ttotal: 1.54ms\tremaining: 658us\n",
      "7:\tlearn: 0.2519976\ttotal: 1.71ms\tremaining: 427us\n",
      "8:\tlearn: 0.2227558\ttotal: 1.91ms\tremaining: 212us\n",
      "9:\tlearn: 0.2016134\ttotal: 2.09ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.5196870\ttotal: 75.5ms\tremaining: 680ms\n",
      "1:\tlearn: 0.4618445\ttotal: 100ms\tremaining: 402ms\n",
      "2:\tlearn: 0.4287199\ttotal: 125ms\tremaining: 292ms\n",
      "3:\tlearn: 0.4012341\ttotal: 148ms\tremaining: 222ms\n",
      "4:\tlearn: 0.3207960\ttotal: 172ms\tremaining: 172ms\n",
      "5:\tlearn: 0.2571247\ttotal: 195ms\tremaining: 130ms\n",
      "6:\tlearn: 0.2028276\ttotal: 219ms\tremaining: 94ms\n",
      "7:\tlearn: 0.1545209\ttotal: 243ms\tremaining: 60.7ms\n",
      "8:\tlearn: 0.1247204\ttotal: 269ms\tremaining: 29.9ms\n",
      "9:\tlearn: 0.1054017\ttotal: 302ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.5928922\ttotal: 129ms\tremaining: 1.16s\n",
      "1:\tlearn: 0.5716779\ttotal: 155ms\tremaining: 622ms\n",
      "2:\tlearn: 0.4426736\ttotal: 182ms\tremaining: 424ms\n",
      "3:\tlearn: 0.3603463\ttotal: 217ms\tremaining: 326ms\n",
      "4:\tlearn: 0.3209690\ttotal: 243ms\tremaining: 243ms\n",
      "5:\tlearn: 0.2413377\ttotal: 272ms\tremaining: 181ms\n",
      "6:\tlearn: 0.1984471\ttotal: 311ms\tremaining: 133ms\n",
      "7:\tlearn: 0.1663059\ttotal: 338ms\tremaining: 84.5ms\n",
      "8:\tlearn: 0.1408907\ttotal: 389ms\tremaining: 43.2ms\n",
      "9:\tlearn: 0.1173044\ttotal: 420ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.5819403\ttotal: 76.2ms\tremaining: 686ms\n",
      "1:\tlearn: 0.4746072\ttotal: 103ms\tremaining: 413ms\n",
      "2:\tlearn: 0.3866287\ttotal: 139ms\tremaining: 324ms\n",
      "3:\tlearn: 0.3697517\ttotal: 165ms\tremaining: 248ms\n",
      "4:\tlearn: 0.3434167\ttotal: 191ms\tremaining: 191ms\n",
      "5:\tlearn: 0.2789860\ttotal: 219ms\tremaining: 146ms\n",
      "6:\tlearn: 0.2320860\ttotal: 245ms\tremaining: 105ms\n",
      "7:\tlearn: 0.1829597\ttotal: 273ms\tremaining: 68.3ms\n",
      "8:\tlearn: 0.1374952\ttotal: 312ms\tremaining: 34.6ms\n",
      "9:\tlearn: 0.1059029\ttotal: 339ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.6067904\ttotal: 78.1ms\tremaining: 703ms\n",
      "1:\tlearn: 0.4921653\ttotal: 107ms\tremaining: 427ms\n",
      "2:\tlearn: 0.4111409\ttotal: 139ms\tremaining: 325ms\n",
      "3:\tlearn: 0.3745304\ttotal: 168ms\tremaining: 252ms\n",
      "4:\tlearn: 0.3132051\ttotal: 198ms\tremaining: 198ms\n",
      "5:\tlearn: 0.2245769\ttotal: 228ms\tremaining: 152ms\n",
      "6:\tlearn: 0.1677411\ttotal: 259ms\tremaining: 111ms\n",
      "7:\tlearn: 0.1239117\ttotal: 291ms\tremaining: 72.7ms\n",
      "8:\tlearn: 0.1031079\ttotal: 319ms\tremaining: 35.5ms\n",
      "9:\tlearn: 0.0978807\ttotal: 349ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.6094981\ttotal: 55.6ms\tremaining: 501ms\n",
      "1:\tlearn: 0.5397183\ttotal: 94.2ms\tremaining: 377ms\n",
      "2:\tlearn: 0.5265673\ttotal: 186ms\tremaining: 434ms\n",
      "3:\tlearn: 0.4431438\ttotal: 254ms\tremaining: 380ms\n",
      "4:\tlearn: 0.3811656\ttotal: 356ms\tremaining: 356ms\n",
      "5:\tlearn: 0.2922305\ttotal: 388ms\tremaining: 259ms\n",
      "6:\tlearn: 0.2095347\ttotal: 439ms\tremaining: 188ms\n",
      "7:\tlearn: 0.1543061\ttotal: 484ms\tremaining: 121ms\n",
      "8:\tlearn: 0.1152615\ttotal: 517ms\tremaining: 57.4ms\n",
      "9:\tlearn: 0.1059993\ttotal: 593ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.4205922\ttotal: 418us\tremaining: 3.77ms\n",
      "1:\tlearn: 0.3012904\ttotal: 843us\tremaining: 3.38ms\n",
      "2:\tlearn: 0.2093218\ttotal: 1.17ms\tremaining: 2.73ms\n",
      "3:\tlearn: 0.1897729\ttotal: 1.43ms\tremaining: 2.14ms\n",
      "4:\tlearn: 0.1722234\ttotal: 1.69ms\tremaining: 1.69ms\n",
      "5:\tlearn: 0.1579422\ttotal: 1.99ms\tremaining: 1.32ms\n",
      "6:\tlearn: 0.1425026\ttotal: 2.26ms\tremaining: 969us\n",
      "7:\tlearn: 0.1331939\ttotal: 2.54ms\tremaining: 634us\n",
      "8:\tlearn: 0.1236273\ttotal: 2.79ms\tremaining: 310us\n",
      "9:\tlearn: 0.0967216\ttotal: 3.07ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.3752432\ttotal: 373us\tremaining: 3.36ms\n",
      "1:\tlearn: 0.2219360\ttotal: 685us\tremaining: 2.74ms\n",
      "2:\tlearn: 0.1915062\ttotal: 1.18ms\tremaining: 2.75ms\n",
      "3:\tlearn: 0.1614565\ttotal: 2.1ms\tremaining: 3.14ms\n",
      "4:\tlearn: 0.1546673\ttotal: 2.75ms\tremaining: 2.75ms\n",
      "5:\tlearn: 0.1516716\ttotal: 3.23ms\tremaining: 2.15ms\n",
      "6:\tlearn: 0.1304396\ttotal: 3.9ms\tremaining: 1.67ms\n",
      "7:\tlearn: 0.1031848\ttotal: 4.24ms\tremaining: 1.06ms\n",
      "8:\tlearn: 0.0962985\ttotal: 4.58ms\tremaining: 508us\n",
      "9:\tlearn: 0.0815582\ttotal: 4.98ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.4271644\ttotal: 550us\tremaining: 4.95ms\n",
      "1:\tlearn: 0.3367827\ttotal: 1.07ms\tremaining: 4.3ms\n",
      "2:\tlearn: 0.3019658\ttotal: 1.58ms\tremaining: 3.7ms\n",
      "3:\tlearn: 0.2516555\ttotal: 2.01ms\tremaining: 3.02ms\n",
      "4:\tlearn: 0.2440176\ttotal: 2.41ms\tremaining: 2.41ms\n",
      "5:\tlearn: 0.2333762\ttotal: 2.7ms\tremaining: 1.8ms\n",
      "6:\tlearn: 0.2230879\ttotal: 2.97ms\tremaining: 1.27ms\n",
      "7:\tlearn: 0.2170414\ttotal: 3.28ms\tremaining: 820us\n",
      "8:\tlearn: 0.1941530\ttotal: 3.72ms\tremaining: 412us\n",
      "9:\tlearn: 0.1843970\ttotal: 4.02ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.3461675\ttotal: 323us\tremaining: 2.91ms\n",
      "1:\tlearn: 0.3027486\ttotal: 668us\tremaining: 2.67ms\n",
      "2:\tlearn: 0.2339115\ttotal: 1ms\tremaining: 2.33ms\n",
      "3:\tlearn: 0.2291501\ttotal: 1.25ms\tremaining: 1.88ms\n",
      "4:\tlearn: 0.1975730\ttotal: 1.5ms\tremaining: 1.5ms\n",
      "5:\tlearn: 0.1886685\ttotal: 1.76ms\tremaining: 1.18ms\n",
      "6:\tlearn: 0.1802583\ttotal: 1.98ms\tremaining: 848us\n",
      "7:\tlearn: 0.1571869\ttotal: 2.34ms\tremaining: 586us\n",
      "8:\tlearn: 0.1493965\ttotal: 2.58ms\tremaining: 286us\n",
      "9:\tlearn: 0.1409815\ttotal: 2.79ms\tremaining: 0us\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30332/2501512093.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mAUC_table_in_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mAUC_table_in_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAUC_table_in_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mset_model_AUC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mAUC_table_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAUC_table_all\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mAUC_table_in_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30332/142971675.py\u001b[0m in \u001b[0;36mset_model_AUC\u001b[1;34m(data, Supervised_or_not, test_ratio)\u001b[0m\n\u001b[0;32m     37\u001b[0m                   \u001b[0mdepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                   loss_function='MultiClass')\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mCAT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCAT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mauc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCAT\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   4675\u001b[0m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0;32m   4676\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4677\u001b[1;33m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[0m\u001b[0;32m   4678\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2000\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2001\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2002\u001b[1;33m                 \u001b[0mtrain_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"init_model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2003\u001b[0m             )\n\u001b[0;32m   2004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1427\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1428\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1429\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCatBoostError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_1=data_type_change(data1)\n",
    "data_2=data2\n",
    "data_3=data_type_change(data3)\n",
    "data_4=data_type_change(data4)\n",
    "data_5=data_type_change(data5)\n",
    "data_6=data_type_change(data6)\n",
    "AUC_table_all=pd.DataFrame()\n",
    "for one_data in [data_1,data_2,data_3,data_4,data_5,data_6]:\n",
    "    AUC_table_in_dataset=pd.DataFrame()\n",
    "    for time in range(0,5) :\n",
    "        AUC_table_in_dataset=pd.concat([AUC_table_in_dataset,set_model_AUC(one_data,False,0)],axis=1)\n",
    "    AUC_table_all=pd.concat([AUC_table_all,AUC_table_in_dataset.mean(axis=1)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967a43fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_table_all.columns=[\"Income\",\"Arcene\",\"Bank\",\"BlastChar\",\"Shopper\",\"SHrutime\"]\n",
    "AUC_table_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
