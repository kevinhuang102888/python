{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44d1de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94cb3b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyod\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyod.utils.data import evaluate_print\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyod.utils.utility import standardizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ccb8b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "import tensorflow\n",
    "from pyod.models.deep_svdd import DeepSVDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47a37e0",
   "metadata": {},
   "source": [
    "# run table(all methods/all data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3218404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 mnist 個資料處理中....\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 202       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               300       \n",
      "=================================================================\n",
      "Total params: 29,216\n",
      "Trainable params: 29,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "137/137 [==============================] - 1s 3ms/step - loss: 5.8500 - val_loss: 5.5637\n",
      "Epoch 2/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 3.4948 - val_loss: 5.7984\n",
      "Epoch 3/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 2.6806 - val_loss: 6.7295\n",
      "Epoch 4/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 2.2304 - val_loss: 7.7477\n",
      "Epoch 5/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.9417 - val_loss: 8.7706\n",
      "Epoch 6/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.7374 - val_loss: 9.8027\n",
      "Epoch 7/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.5703 - val_loss: 10.9243\n",
      "Epoch 8/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.4475 - val_loss: 11.9217\n",
      "Epoch 9/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.3408 - val_loss: 12.9206\n",
      "Epoch 10/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.2601 - val_loss: 13.9565\n",
      "Epoch 11/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.1873 - val_loss: 14.8881\n",
      "Epoch 12/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.1282 - val_loss: 15.7474\n",
      "Epoch 13/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.0740 - val_loss: 16.8628\n",
      "Epoch 14/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.0322 - val_loss: 17.6367\n",
      "Epoch 15/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 18.4843\n",
      "Epoch 16/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.9646 - val_loss: 19.2616\n",
      "Epoch 17/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.9375 - val_loss: 20.0645\n",
      "Epoch 18/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.9168 - val_loss: 20.7743\n",
      "Epoch 19/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8938 - val_loss: 21.3508\n",
      "Epoch 20/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8760 - val_loss: 22.0405\n",
      "Epoch 21/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8643 - val_loss: 22.5892\n",
      "Epoch 22/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8494 - val_loss: 23.1259\n",
      "Epoch 23/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8414 - val_loss: 23.5958\n",
      "Epoch 24/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8276 - val_loss: 24.0126\n",
      "Epoch 25/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8184 - val_loss: 24.3884\n",
      "Epoch 26/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8097 - val_loss: 24.7145\n",
      "Epoch 27/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8019 - val_loss: 24.9988\n",
      "Epoch 28/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7931 - val_loss: 25.2568\n",
      "Epoch 29/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7886 - val_loss: 25.4781\n",
      "Epoch 30/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7820 - val_loss: 25.6675\n",
      "Epoch 31/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7755 - val_loss: 25.8209\n",
      "Epoch 32/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7717 - val_loss: 25.9613\n",
      "Epoch 33/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7660 - val_loss: 26.0769\n",
      "Epoch 34/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7619 - val_loss: 26.1626\n",
      "Epoch 35/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7588 - val_loss: 26.2488\n",
      "Epoch 36/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7553 - val_loss: 26.3103\n",
      "Epoch 37/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7509 - val_loss: 26.3642\n",
      "Epoch 38/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7485 - val_loss: 26.4072\n",
      "Epoch 39/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7445 - val_loss: 26.4426\n",
      "Epoch 40/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7419 - val_loss: 26.4707\n",
      "Epoch 41/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7391 - val_loss: 26.4937\n",
      "Epoch 42/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7369 - val_loss: 26.5117\n",
      "Epoch 43/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7348 - val_loss: 26.5255\n",
      "Epoch 44/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7326 - val_loss: 26.5385\n",
      "Epoch 45/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7303 - val_loss: 26.5477\n",
      "Epoch 46/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7284 - val_loss: 26.5546\n",
      "Epoch 47/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7265 - val_loss: 26.5600\n",
      "Epoch 48/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7248 - val_loss: 26.5637\n",
      "Epoch 49/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7232 - val_loss: 26.5667\n",
      "Epoch 50/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7218 - val_loss: 26.5688\n",
      "Epoch 51/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7202 - val_loss: 26.5699\n",
      "Epoch 52/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7191 - val_loss: 26.5705\n",
      "Epoch 53/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7179 - val_loss: 26.5709\n",
      "Epoch 54/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7168 - val_loss: 26.5707\n",
      "Epoch 55/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7157 - val_loss: 26.5706\n",
      "Epoch 56/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7148 - val_loss: 26.5702\n",
      "Epoch 57/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7137 - val_loss: 26.5697\n",
      "Epoch 58/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7129 - val_loss: 26.5692\n",
      "Epoch 59/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7121 - val_loss: 26.5686\n",
      "Epoch 60/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7114 - val_loss: 26.5680\n",
      "Epoch 61/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7106 - val_loss: 26.5674\n",
      "Epoch 62/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7100 - val_loss: 26.5669\n",
      "Epoch 63/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7094 - val_loss: 26.5663\n",
      "Epoch 64/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7088 - val_loss: 26.5658\n",
      "Epoch 65/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7083 - val_loss: 26.5653\n",
      "Epoch 66/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7078 - val_loss: 26.5649\n",
      "Epoch 67/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7073 - val_loss: 26.5645\n",
      "Epoch 68/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7069 - val_loss: 26.5641\n",
      "Epoch 69/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7065 - val_loss: 26.5637\n",
      "Epoch 70/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7061 - val_loss: 26.5634\n",
      "Epoch 71/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7058 - val_loss: 26.5631\n",
      "Epoch 72/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7055 - val_loss: 26.5628\n",
      "Epoch 73/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7052 - val_loss: 26.5625\n",
      "Epoch 74/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7049 - val_loss: 26.5622\n",
      "Epoch 75/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7047 - val_loss: 26.5620\n",
      "Epoch 76/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7044 - val_loss: 26.5618\n",
      "Epoch 77/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7042 - val_loss: 26.5616\n",
      "Epoch 78/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7040 - val_loss: 26.5614\n",
      "Epoch 79/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7038 - val_loss: 26.5612\n",
      "Epoch 80/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7036 - val_loss: 26.5610\n",
      "Epoch 81/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7035 - val_loss: 26.5609\n",
      "Epoch 82/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7033 - val_loss: 26.5607\n",
      "Epoch 83/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7032 - val_loss: 26.5606\n",
      "Epoch 84/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7030 - val_loss: 26.5605\n",
      "Epoch 85/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7029 - val_loss: 26.5604\n",
      "Epoch 86/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7028 - val_loss: 26.5603\n",
      "Epoch 87/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7027 - val_loss: 26.5602\n",
      "Epoch 88/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7026 - val_loss: 26.5601\n",
      "Epoch 89/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7025 - val_loss: 26.5600\n",
      "Epoch 90/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7024 - val_loss: 26.5599\n",
      "Epoch 91/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7024 - val_loss: 26.5598\n",
      "Epoch 92/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7023 - val_loss: 26.5598\n",
      "Epoch 93/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7022 - val_loss: 26.5597\n",
      "Epoch 94/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7022 - val_loss: 26.5597\n",
      "Epoch 95/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7021 - val_loss: 26.5596\n",
      "Epoch 96/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7021 - val_loss: 26.5596\n",
      "Epoch 97/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7020 - val_loss: 26.5595\n",
      "Epoch 98/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7020 - val_loss: 26.5595\n",
      "Epoch 99/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7019 - val_loss: 26.5594\n",
      "Epoch 100/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7019 - val_loss: 26.5594\n",
      "Epoch 101/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7019 - val_loss: 26.5594\n",
      "Epoch 102/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7018 - val_loss: 26.5593\n",
      "Epoch 103/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7018 - val_loss: 26.5593\n",
      "Epoch 104/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7018 - val_loss: 26.5593\n",
      "Epoch 105/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7017 - val_loss: 26.5593\n",
      "Epoch 106/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7017 - val_loss: 26.5592\n",
      "Epoch 107/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7017 - val_loss: 26.5592\n",
      "Epoch 108/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7017 - val_loss: 26.5592\n",
      "Epoch 109/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7017 - val_loss: 26.5592\n",
      "Epoch 110/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7016 - val_loss: 26.5592\n",
      "Epoch 111/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7016 - val_loss: 26.5591\n",
      "Epoch 112/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7016 - val_loss: 26.5591\n",
      "Epoch 113/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7016 - val_loss: 26.5591\n",
      "Epoch 114/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7016 - val_loss: 26.5591\n",
      "Epoch 115/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7016 - val_loss: 26.5591\n",
      "Epoch 116/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7015 - val_loss: 26.5591\n",
      "Epoch 117/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7015 - val_loss: 26.5591\n",
      "Epoch 118/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7015 - val_loss: 26.5591\n",
      "Epoch 119/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7015 - val_loss: 26.5590\n",
      "Epoch 120/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7015 - val_loss: 26.5590\n",
      "Epoch 121/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7015 - val_loss: 26.5590\n",
      "Epoch 122/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7015 - val_loss: 26.5590\n",
      "Epoch 123/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7015 - val_loss: 26.5590\n",
      "Epoch 124/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7015 - val_loss: 26.5590\n",
      "Epoch 125/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7015 - val_loss: 26.5590\n",
      "Epoch 126/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7015 - val_loss: 26.5590\n",
      "Epoch 127/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7015 - val_loss: 26.5590\n",
      "Epoch 128/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 26.5590\n",
      "Epoch 129/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 26.5590\n",
      "Epoch 130/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 26.5590\n",
      "Epoch 131/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 26.5590\n",
      "Epoch 132/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 26.5590\n",
      "Epoch 133/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7014 - val_loss: 26.5590\n",
      "Epoch 134/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 26.5590\n",
      "Epoch 135/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 26.5590\n",
      "Epoch 136/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 26.5589\n",
      "Epoch 137/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 26.5589\n",
      "Epoch 138/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 26.5589\n",
      "Epoch 139/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 26.5589\n",
      "Epoch 140/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 26.5589\n",
      "Epoch 141/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 26.5589\n",
      "Epoch 142/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 26.5589\n",
      "Epoch 143/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7014 - val_loss: 26.5589\n",
      "Epoch 144/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 26.5589\n",
      "Epoch 145/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 26.5589\n",
      "Epoch 146/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 26.5589\n",
      "Epoch 147/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 26.5589\n",
      "Epoch 148/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 26.5589\n",
      "Epoch 149/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 26.5589\n",
      "Epoch 150/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 26.5589\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 2000)              202000    \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_1 (TFOpLamb (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_1 (TFOpLambda)   (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_1 (TFOpLa (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_1 (TFOpL ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_1 (AddLoss)         ()                        0         \n",
      "=================================================================\n",
      "Total params: 212,100\n",
      "Trainable params: 212,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 17.2347 - val_loss: 9.4797\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 5.5834 - val_loss: 8.9799\n",
      "Epoch 3/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 4.0862 - val_loss: 10.2057\n",
      "Epoch 4/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 3.5788 - val_loss: 11.5405\n",
      "Epoch 5/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 3.3067 - val_loss: 12.8003\n",
      "Epoch 6/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 3.1327 - val_loss: 13.9157\n",
      "Epoch 7/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 3.0021 - val_loss: 15.0479\n",
      "Epoch 8/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.8980 - val_loss: 16.1174\n",
      "Epoch 9/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.8134 - val_loss: 17.0784\n",
      "Epoch 10/100\n",
      "145/145 [==============================] - 1s 3ms/step - loss: 2.7410 - val_loss: 18.1098\n",
      "Epoch 11/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.6782 - val_loss: 19.2620\n",
      "Epoch 12/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.6273 - val_loss: 20.0722\n",
      "Epoch 13/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.5772 - val_loss: 21.0109\n",
      "Epoch 14/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.5329 - val_loss: 22.2614\n",
      "Epoch 15/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.4949 - val_loss: 22.8858\n",
      "Epoch 16/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.4619 - val_loss: 23.9419\n",
      "Epoch 17/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.4286 - val_loss: 24.9976\n",
      "Epoch 18/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.4039 - val_loss: 25.7704\n",
      "Epoch 19/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.3838 - val_loss: 26.7329\n",
      "Epoch 20/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.3679 - val_loss: 28.0515\n",
      "Epoch 21/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.3499 - val_loss: 28.9196\n",
      "Epoch 22/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.3353 - val_loss: 29.7089\n",
      "Epoch 23/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.3245 - val_loss: 30.1829\n",
      "Epoch 24/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.3137 - val_loss: 31.1814\n",
      "Epoch 25/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.3027 - val_loss: 31.8953\n",
      "Epoch 26/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2933 - val_loss: 33.2522\n",
      "Epoch 27/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2869 - val_loss: 33.7565\n",
      "Epoch 28/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2806 - val_loss: 34.2360\n",
      "Epoch 29/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2720 - val_loss: 35.7215\n",
      "Epoch 30/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2647 - val_loss: 36.3263\n",
      "Epoch 31/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2565 - val_loss: 37.0916\n",
      "Epoch 32/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2511 - val_loss: 37.4392\n",
      "Epoch 33/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2460 - val_loss: 38.5869\n",
      "Epoch 34/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2419 - val_loss: 38.8949\n",
      "Epoch 35/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2392 - val_loss: 39.3186\n",
      "Epoch 36/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2359 - val_loss: 39.5230\n",
      "Epoch 37/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2338 - val_loss: 40.0925\n",
      "Epoch 38/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2322 - val_loss: 40.3845\n",
      "Epoch 39/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2303 - val_loss: 40.4775\n",
      "Epoch 40/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2294 - val_loss: 40.8539\n",
      "Epoch 41/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2288 - val_loss: 40.9655\n",
      "Epoch 42/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2288 - val_loss: 41.0086\n",
      "Epoch 43/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.0494\n",
      "Epoch 44/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.0776\n",
      "Epoch 45/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.0962\n",
      "Epoch 46/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1091\n",
      "Epoch 47/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1189\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1255\n",
      "Epoch 49/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1330\n",
      "Epoch 50/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1375\n",
      "Epoch 51/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1414\n",
      "Epoch 52/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1445\n",
      "Epoch 53/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1472\n",
      "Epoch 54/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1492\n",
      "Epoch 55/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1510\n",
      "Epoch 56/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1529\n",
      "Epoch 57/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1540\n",
      "Epoch 58/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1552\n",
      "Epoch 59/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1560\n",
      "Epoch 60/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1568\n",
      "Epoch 61/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1575\n",
      "Epoch 62/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1579\n",
      "Epoch 63/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1584\n",
      "Epoch 64/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1587\n",
      "Epoch 65/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1589\n",
      "Epoch 66/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2287 - val_loss: 41.1591\n",
      "Epoch 67/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1592\n",
      "Epoch 68/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1593\n",
      "Epoch 69/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1594\n",
      "Epoch 70/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1594\n",
      "Epoch 71/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1594\n",
      "Epoch 72/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 73/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 74/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 75/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 76/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 77/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 78/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 79/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 80/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 81/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 82/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 83/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 84/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 85/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 86/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 87/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 88/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 89/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 90/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 91/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 92/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 93/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 94/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 95/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 96/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 97/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 98/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 99/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Epoch 100/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 41.1595\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 202       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               300       \n",
      "=================================================================\n",
      "Total params: 29,216\n",
      "Trainable params: 29,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "137/137 [==============================] - 2s 5ms/step - loss: 5.2963 - val_loss: 5.4837\n",
      "Epoch 2/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 0s 3ms/step - loss: 2.9941 - val_loss: 6.0236\n",
      "Epoch 3/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 2.2423 - val_loss: 7.0690\n",
      "Epoch 4/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 1.8700 - val_loss: 8.0549\n",
      "Epoch 5/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 1.6452 - val_loss: 9.0433\n",
      "Epoch 6/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.4812 - val_loss: 9.8905\n",
      "Epoch 7/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 1.3553 - val_loss: 10.7334\n",
      "Epoch 8/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 1.2610 - val_loss: 11.5181\n",
      "Epoch 9/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 1.1921 - val_loss: 12.2203\n",
      "Epoch 10/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 1.1245 - val_loss: 13.0827\n",
      "Epoch 11/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.0779 - val_loss: 13.7162\n",
      "Epoch 12/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.0326 - val_loss: 14.3158\n",
      "Epoch 13/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.9972 - val_loss: 14.9553\n",
      "Epoch 14/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.9655 - val_loss: 15.4826\n",
      "Epoch 15/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.9400 - val_loss: 16.1228\n",
      "Epoch 16/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.9099 - val_loss: 16.5741\n",
      "Epoch 17/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.8897 - val_loss: 17.0793\n",
      "Epoch 18/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.8779 - val_loss: 17.6629\n",
      "Epoch 19/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8562 - val_loss: 18.0347\n",
      "Epoch 20/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.8455 - val_loss: 18.5112\n",
      "Epoch 21/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.8289 - val_loss: 18.8675\n",
      "Epoch 22/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.8171 - val_loss: 19.1679\n",
      "Epoch 23/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.8073 - val_loss: 19.5067\n",
      "Epoch 24/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8004 - val_loss: 19.7941\n",
      "Epoch 25/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7900 - val_loss: 20.0163\n",
      "Epoch 26/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7800 - val_loss: 20.2292\n",
      "Epoch 27/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7724 - val_loss: 20.4126\n",
      "Epoch 28/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7673 - val_loss: 20.6039\n",
      "Epoch 29/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7614 - val_loss: 20.7533\n",
      "Epoch 30/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7546 - val_loss: 20.8841\n",
      "Epoch 31/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7485 - val_loss: 20.9839\n",
      "Epoch 32/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7446 - val_loss: 21.0849\n",
      "Epoch 33/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7395 - val_loss: 21.1661\n",
      "Epoch 34/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7350 - val_loss: 21.2318\n",
      "Epoch 35/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7321 - val_loss: 21.2839\n",
      "Epoch 36/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7278 - val_loss: 21.3268\n",
      "Epoch 37/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7241 - val_loss: 21.3692\n",
      "Epoch 38/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7207 - val_loss: 21.4014\n",
      "Epoch 39/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7181 - val_loss: 21.4276\n",
      "Epoch 40/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7146 - val_loss: 21.4460\n",
      "Epoch 41/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7124 - val_loss: 21.4637\n",
      "Epoch 42/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7098 - val_loss: 21.4767\n",
      "Epoch 43/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7074 - val_loss: 21.4863\n",
      "Epoch 44/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7053 - val_loss: 21.4949\n",
      "Epoch 45/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7032 - val_loss: 21.5006\n",
      "Epoch 46/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 21.5049\n",
      "Epoch 47/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6994 - val_loss: 21.5082\n",
      "Epoch 48/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6977 - val_loss: 21.5101\n",
      "Epoch 49/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6963 - val_loss: 21.5116\n",
      "Epoch 50/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6946 - val_loss: 21.5124\n",
      "Epoch 51/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6934 - val_loss: 21.5127\n",
      "Epoch 52/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6921 - val_loss: 21.5126\n",
      "Epoch 53/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6907 - val_loss: 21.5122\n",
      "Epoch 54/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6897 - val_loss: 21.5117\n",
      "Epoch 55/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6886 - val_loss: 21.5111\n",
      "Epoch 56/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6876 - val_loss: 21.5105\n",
      "Epoch 57/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6867 - val_loss: 21.5098\n",
      "Epoch 58/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6859 - val_loss: 21.5091\n",
      "Epoch 59/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6850 - val_loss: 21.5084\n",
      "Epoch 60/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6843 - val_loss: 21.5077\n",
      "Epoch 61/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6836 - val_loss: 21.5071\n",
      "Epoch 62/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6829 - val_loss: 21.5065\n",
      "Epoch 63/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6823 - val_loss: 21.5060\n",
      "Epoch 64/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6818 - val_loss: 21.5054\n",
      "Epoch 65/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6812 - val_loss: 21.5049\n",
      "Epoch 66/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6807 - val_loss: 21.5045\n",
      "Epoch 67/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6803 - val_loss: 21.5040\n",
      "Epoch 68/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6798 - val_loss: 21.5036\n",
      "Epoch 69/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6795 - val_loss: 21.5033\n",
      "Epoch 70/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6791 - val_loss: 21.5029\n",
      "Epoch 71/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6787 - val_loss: 21.5026\n",
      "Epoch 72/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6784 - val_loss: 21.5023\n",
      "Epoch 73/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6781 - val_loss: 21.5020\n",
      "Epoch 74/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6778 - val_loss: 21.5017\n",
      "Epoch 75/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6776 - val_loss: 21.5015\n",
      "Epoch 76/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6773 - val_loss: 21.5012\n",
      "Epoch 77/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6771 - val_loss: 21.5010\n",
      "Epoch 78/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6769 - val_loss: 21.5008\n",
      "Epoch 79/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6767 - val_loss: 21.5006\n",
      "Epoch 80/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6766 - val_loss: 21.5005\n",
      "Epoch 81/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6764 - val_loss: 21.5003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6762 - val_loss: 21.5002\n",
      "Epoch 83/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6761 - val_loss: 21.5000\n",
      "Epoch 84/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6760 - val_loss: 21.4999\n",
      "Epoch 85/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6759 - val_loss: 21.4998\n",
      "Epoch 86/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6757 - val_loss: 21.5019\n",
      "Epoch 87/150\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 0.6757 - val_loss: 21.5613\n",
      "Epoch 88/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6756 - val_loss: 21.5723\n",
      "Epoch 89/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6755 - val_loss: 21.5723\n",
      "Epoch 90/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6754 - val_loss: 21.5722\n",
      "Epoch 91/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6753 - val_loss: 21.5721\n",
      "Epoch 92/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6752 - val_loss: 21.5720\n",
      "Epoch 93/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6752 - val_loss: 21.5720\n",
      "Epoch 94/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6751 - val_loss: 21.5719\n",
      "Epoch 95/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6751 - val_loss: 21.5719\n",
      "Epoch 96/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6750 - val_loss: 21.5718\n",
      "Epoch 97/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6750 - val_loss: 21.5718\n",
      "Epoch 98/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6749 - val_loss: 21.5717\n",
      "Epoch 99/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6749 - val_loss: 21.5717\n",
      "Epoch 100/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6748 - val_loss: 21.5716\n",
      "Epoch 101/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6748 - val_loss: 21.5716\n",
      "Epoch 102/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6748 - val_loss: 21.5716\n",
      "Epoch 103/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6747 - val_loss: 21.5715\n",
      "Epoch 104/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6747 - val_loss: 21.5715\n",
      "Epoch 105/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6747 - val_loss: 21.5715\n",
      "Epoch 106/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6747 - val_loss: 21.5715\n",
      "Epoch 107/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6746 - val_loss: 21.5714\n",
      "Epoch 108/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6746 - val_loss: 21.5714\n",
      "Epoch 109/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6746 - val_loss: 21.5714\n",
      "Epoch 110/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6746 - val_loss: 21.5714\n",
      "Epoch 111/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6746 - val_loss: 21.5714\n",
      "Epoch 112/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6745 - val_loss: 21.5713\n",
      "Epoch 113/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6745 - val_loss: 21.5713\n",
      "Epoch 114/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6745 - val_loss: 21.5713\n",
      "Epoch 115/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6745 - val_loss: 21.5713\n",
      "Epoch 116/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6745 - val_loss: 21.5713\n",
      "Epoch 117/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6745 - val_loss: 21.5713\n",
      "Epoch 118/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6745 - val_loss: 21.5713\n",
      "Epoch 119/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6745 - val_loss: 21.5712\n",
      "Epoch 120/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6744 - val_loss: 21.5712\n",
      "Epoch 121/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6744 - val_loss: 21.5712\n",
      "Epoch 122/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6744 - val_loss: 21.5712\n",
      "Epoch 123/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6744 - val_loss: 21.5712\n",
      "Epoch 124/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6744 - val_loss: 21.5712\n",
      "Epoch 125/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6744 - val_loss: 21.5712\n",
      "Epoch 126/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6744 - val_loss: 21.5712\n",
      "Epoch 127/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6744 - val_loss: 21.5712\n",
      "Epoch 128/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6744 - val_loss: 21.5712\n",
      "Epoch 129/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6744 - val_loss: 21.5712\n",
      "Epoch 130/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6744 - val_loss: 21.5712\n",
      "Epoch 131/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6744 - val_loss: 21.5711\n",
      "Epoch 132/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6744 - val_loss: 21.5711\n",
      "Epoch 133/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6744 - val_loss: 21.5711\n",
      "Epoch 134/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6744 - val_loss: 21.5711\n",
      "Epoch 135/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6744 - val_loss: 21.5711\n",
      "Epoch 136/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6744 - val_loss: 21.5711\n",
      "Epoch 137/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6743 - val_loss: 21.5711\n",
      "Epoch 138/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6743 - val_loss: 21.5711\n",
      "Epoch 139/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6743 - val_loss: 21.5711\n",
      "Epoch 140/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6743 - val_loss: 21.5711\n",
      "Epoch 141/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6743 - val_loss: 21.5711\n",
      "Epoch 142/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6743 - val_loss: 21.5711\n",
      "Epoch 143/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6743 - val_loss: 21.5711\n",
      "Epoch 144/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6743 - val_loss: 21.5711\n",
      "Epoch 145/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6743 - val_loss: 21.5711\n",
      "Epoch 146/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6743 - val_loss: 21.5711\n",
      "Epoch 147/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6743 - val_loss: 21.5711\n",
      "Epoch 148/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6743 - val_loss: 21.5711\n",
      "Epoch 149/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6743 - val_loss: 21.5711\n",
      "Epoch 150/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6743 - val_loss: 21.5711\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 2000)              202000    \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_3 (TFOpLamb (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_3 (TFOpLambda)   (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_3 (TFOpLa (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_3 (TFOpL ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_3 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_3 (AddLoss)         ()                        0         \n",
      "=================================================================\n",
      "Total params: 212,100\n",
      "Trainable params: 212,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 1s 4ms/step - loss: 16.3908 - val_loss: 5.5507\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 5.2525 - val_loss: 3.1508\n",
      "Epoch 3/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 3.8596 - val_loss: 2.6282\n",
      "Epoch 4/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 3.3526 - val_loss: 2.4321\n",
      "Epoch 5/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 3.0902 - val_loss: 2.3384\n",
      "Epoch 6/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.9352 - val_loss: 2.2904\n",
      "Epoch 7/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.8230 - val_loss: 2.2660\n",
      "Epoch 8/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.7324 - val_loss: 2.2512\n",
      "Epoch 9/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.6702 - val_loss: 2.2439\n",
      "Epoch 10/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.6127 - val_loss: 2.2372\n",
      "Epoch 11/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.5659 - val_loss: 2.2340\n",
      "Epoch 12/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.5319 - val_loss: 2.2319\n",
      "Epoch 13/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.4955 - val_loss: 2.2298\n",
      "Epoch 14/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.4669 - val_loss: 2.2291\n",
      "Epoch 15/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.4384 - val_loss: 2.2280\n",
      "Epoch 16/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.4163 - val_loss: 2.2282\n",
      "Epoch 17/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.3989 - val_loss: 2.2277\n",
      "Epoch 18/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.3758 - val_loss: 2.2264\n",
      "Epoch 19/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.3576 - val_loss: 2.2260\n",
      "Epoch 20/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.3451 - val_loss: 2.2260\n",
      "Epoch 21/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.3334 - val_loss: 2.2258\n",
      "Epoch 22/100\n",
      "145/145 [==============================] - 1s 3ms/step - loss: 2.3182 - val_loss: 2.2264\n",
      "Epoch 23/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.3108 - val_loss: 2.2256\n",
      "Epoch 24/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2999 - val_loss: 2.2269\n",
      "Epoch 25/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2902 - val_loss: 2.2265\n",
      "Epoch 26/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2849 - val_loss: 2.2258\n",
      "Epoch 27/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2791 - val_loss: 2.2267\n",
      "Epoch 28/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2685 - val_loss: 2.2254\n",
      "Epoch 29/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2618 - val_loss: 2.2250\n",
      "Epoch 30/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2561 - val_loss: 2.2257\n",
      "Epoch 31/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2547 - val_loss: 2.2251\n",
      "Epoch 32/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2521 - val_loss: 2.2260\n",
      "Epoch 33/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2445 - val_loss: 2.2262\n",
      "Epoch 34/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2408 - val_loss: 2.2253\n",
      "Epoch 35/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2391 - val_loss: 2.2260\n",
      "Epoch 36/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2378 - val_loss: 2.2263\n",
      "Epoch 37/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2374 - val_loss: 2.2268\n",
      "Epoch 38/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2354 - val_loss: 2.2257\n",
      "Epoch 39/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2340 - val_loss: 2.2254\n",
      "Epoch 40/100\n",
      "145/145 [==============================] - 1s 3ms/step - loss: 2.2303 - val_loss: 2.2256\n",
      "Epoch 41/100\n",
      "145/145 [==============================] - 1s 3ms/step - loss: 2.2286 - val_loss: 2.2270\n",
      "Epoch 42/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2272 - val_loss: 2.2244\n",
      "Epoch 43/100\n",
      "145/145 [==============================] - 1s 3ms/step - loss: 2.2264 - val_loss: 2.2241\n",
      "Epoch 44/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2268 - val_loss: 2.2252\n",
      "Epoch 45/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2236 - val_loss: 2.2257\n",
      "Epoch 46/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2228 - val_loss: 2.2245\n",
      "Epoch 47/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2244\n",
      "Epoch 48/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2243\n",
      "Epoch 49/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2243\n",
      "Epoch 50/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2243\n",
      "Epoch 51/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2243\n",
      "Epoch 52/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2243\n",
      "Epoch 53/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 54/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 55/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 56/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 57/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 58/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 59/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 60/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 61/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 62/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 63/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 64/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 65/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 66/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 67/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 68/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 69/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 70/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 71/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 72/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 73/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 74/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 75/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 76/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 77/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 78/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 79/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 80/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 82/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 83/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 84/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 85/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 86/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 87/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 88/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 89/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 90/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 91/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 92/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 93/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 94/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 95/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 96/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 97/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 98/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 99/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Epoch 100/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.2242\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 202       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 100)               300       \n",
      "=================================================================\n",
      "Total params: 29,216\n",
      "Trainable params: 29,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "137/137 [==============================] - 1s 3ms/step - loss: 5.4419 - val_loss: 6.4773\n",
      "Epoch 2/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 2.9918 - val_loss: 8.1125\n",
      "Epoch 3/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 2.1962 - val_loss: 10.0724\n",
      "Epoch 4/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.8272 - val_loss: 12.1882\n",
      "Epoch 5/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.5976 - val_loss: 13.9313\n",
      "Epoch 6/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.4400 - val_loss: 15.4566\n",
      "Epoch 7/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 1.3345 - val_loss: 16.9326\n",
      "Epoch 8/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 1.2451 - val_loss: 18.1151\n",
      "Epoch 9/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 1.1614 - val_loss: 19.2786\n",
      "Epoch 10/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 1.1135 - val_loss: 20.4004\n",
      "Epoch 11/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.0641 - val_loss: 21.4023\n",
      "Epoch 12/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 1.0238 - val_loss: 22.4636\n",
      "Epoch 13/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.9828 - val_loss: 23.4248\n",
      "Epoch 14/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.9575 - val_loss: 24.2331\n",
      "Epoch 15/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.9311 - val_loss: 25.0520\n",
      "Epoch 16/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.9064 - val_loss: 25.7664\n",
      "Epoch 17/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.8873 - val_loss: 26.4422\n",
      "Epoch 18/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8721 - val_loss: 27.0685\n",
      "Epoch 19/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.8557 - val_loss: 27.6468\n",
      "Epoch 20/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8396 - val_loss: 28.1607\n",
      "Epoch 21/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8314 - val_loss: 28.6222\n",
      "Epoch 22/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.8190 - val_loss: 28.9983\n",
      "Epoch 23/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8086 - val_loss: 29.3051\n",
      "Epoch 24/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8014 - val_loss: 29.6600\n",
      "Epoch 25/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7921 - val_loss: 29.9232\n",
      "Epoch 26/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7820 - val_loss: 30.1378\n",
      "Epoch 27/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7780 - val_loss: 30.3235\n",
      "Epoch 28/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7717 - val_loss: 30.4897\n",
      "Epoch 29/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7628 - val_loss: 30.6293\n",
      "Epoch 30/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7571 - val_loss: 30.7510\n",
      "Epoch 31/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7542 - val_loss: 30.8522\n",
      "Epoch 32/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7483 - val_loss: 30.9325\n",
      "Epoch 33/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7432 - val_loss: 31.0044\n",
      "Epoch 34/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7391 - val_loss: 31.0628\n",
      "Epoch 35/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7351 - val_loss: 31.1114\n",
      "Epoch 36/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7319 - val_loss: 31.1532\n",
      "Epoch 37/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7281 - val_loss: 31.1864\n",
      "Epoch 38/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7243 - val_loss: 31.2133\n",
      "Epoch 39/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7221 - val_loss: 31.2364\n",
      "Epoch 40/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7185 - val_loss: 31.2530\n",
      "Epoch 41/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7157 - val_loss: 31.2688\n",
      "Epoch 42/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7132 - val_loss: 31.2810\n",
      "Epoch 43/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7113 - val_loss: 31.2901\n",
      "Epoch 44/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7094 - val_loss: 31.2979\n",
      "Epoch 45/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7069 - val_loss: 31.3031\n",
      "Epoch 46/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7050 - val_loss: 31.3069\n",
      "Epoch 47/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7031 - val_loss: 31.3099\n",
      "Epoch 48/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7014 - val_loss: 31.3114\n",
      "Epoch 49/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6999 - val_loss: 31.3129\n",
      "Epoch 50/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6983 - val_loss: 31.3135\n",
      "Epoch 51/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6971 - val_loss: 31.3136\n",
      "Epoch 52/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6957 - val_loss: 31.3134\n",
      "Epoch 53/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6946 - val_loss: 31.3130\n",
      "Epoch 54/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6934 - val_loss: 31.3125\n",
      "Epoch 55/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6924 - val_loss: 31.3118\n",
      "Epoch 56/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6913 - val_loss: 31.3112\n",
      "Epoch 57/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6905 - val_loss: 31.3105\n",
      "Epoch 58/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6896 - val_loss: 31.3098\n",
      "Epoch 59/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6888 - val_loss: 31.3091\n",
      "Epoch 60/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6880 - val_loss: 31.3084\n",
      "Epoch 61/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6873 - val_loss: 31.3078\n",
      "Epoch 62/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6865 - val_loss: 31.3072\n",
      "Epoch 63/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6860 - val_loss: 31.3067\n",
      "Epoch 64/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6854 - val_loss: 31.3061\n",
      "Epoch 65/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6849 - val_loss: 31.3057\n",
      "Epoch 66/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6844 - val_loss: 31.3052\n",
      "Epoch 67/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6839 - val_loss: 31.3048\n",
      "Epoch 68/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6835 - val_loss: 31.3044\n",
      "Epoch 69/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6831 - val_loss: 31.3040\n",
      "Epoch 70/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6827 - val_loss: 31.3036\n",
      "Epoch 71/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6824 - val_loss: 31.3033\n",
      "Epoch 72/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6820 - val_loss: 31.3030\n",
      "Epoch 73/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6817 - val_loss: 31.3027\n",
      "Epoch 74/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6815 - val_loss: 31.3025\n",
      "Epoch 75/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6812 - val_loss: 31.3022\n",
      "Epoch 76/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6810 - val_loss: 31.3020\n",
      "Epoch 77/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6807 - val_loss: 31.3018\n",
      "Epoch 78/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6805 - val_loss: 31.3016\n",
      "Epoch 79/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6803 - val_loss: 31.3014\n",
      "Epoch 80/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6802 - val_loss: 31.3013\n",
      "Epoch 81/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6800 - val_loss: 31.3011\n",
      "Epoch 82/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6799 - val_loss: 31.3010\n",
      "Epoch 83/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6797 - val_loss: 31.3008\n",
      "Epoch 84/150\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 0.6796 - val_loss: 31.3007\n",
      "Epoch 85/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6795 - val_loss: 31.3006\n",
      "Epoch 86/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6793 - val_loss: 31.3005\n",
      "Epoch 87/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6792 - val_loss: 31.3004\n",
      "Epoch 88/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6791 - val_loss: 31.3003\n",
      "Epoch 89/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6791 - val_loss: 31.3002\n",
      "Epoch 90/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6790 - val_loss: 31.3001\n",
      "Epoch 91/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6789 - val_loss: 31.3001\n",
      "Epoch 92/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6788 - val_loss: 31.3000\n",
      "Epoch 93/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6788 - val_loss: 31.2999\n",
      "Epoch 94/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6787 - val_loss: 31.2999\n",
      "Epoch 95/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6787 - val_loss: 31.2998\n",
      "Epoch 96/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6786 - val_loss: 31.2998\n",
      "Epoch 97/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6786 - val_loss: 31.2997\n",
      "Epoch 98/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6785 - val_loss: 31.2997\n",
      "Epoch 99/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6785 - val_loss: 31.2996\n",
      "Epoch 100/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6784 - val_loss: 31.2996\n",
      "Epoch 101/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6784 - val_loss: 31.2996\n",
      "Epoch 102/150\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.6784 - val_loss: 31.2995\n",
      "Epoch 103/150\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.6783 - val_loss: 31.2995\n",
      "Epoch 104/150\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.6783 - val_loss: 31.2995\n",
      "Epoch 105/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6783 - val_loss: 31.2994\n",
      "Epoch 106/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6782 - val_loss: 31.2994\n",
      "Epoch 107/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6782 - val_loss: 31.2994\n",
      "Epoch 108/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6782 - val_loss: 31.2994\n",
      "Epoch 109/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6782 - val_loss: 31.2994\n",
      "Epoch 110/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6782 - val_loss: 31.2993\n",
      "Epoch 111/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6781 - val_loss: 31.2993\n",
      "Epoch 112/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6781 - val_loss: 31.2993\n",
      "Epoch 113/150\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 0.6781 - val_loss: 31.2993\n",
      "Epoch 114/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6781 - val_loss: 31.2993\n",
      "Epoch 115/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6781 - val_loss: 31.2993\n",
      "Epoch 116/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6781 - val_loss: 31.2993\n",
      "Epoch 117/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6781 - val_loss: 31.2992\n",
      "Epoch 118/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6780 - val_loss: 31.2992\n",
      "Epoch 119/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6780 - val_loss: 31.2992\n",
      "Epoch 120/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6780 - val_loss: 31.2992\n",
      "Epoch 121/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6780 - val_loss: 31.2992\n",
      "Epoch 122/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6780 - val_loss: 31.2992\n",
      "Epoch 123/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6780 - val_loss: 31.2992\n",
      "Epoch 124/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6780 - val_loss: 31.2992\n",
      "Epoch 125/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6780 - val_loss: 31.2992\n",
      "Epoch 126/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6780 - val_loss: 31.2992\n",
      "Epoch 127/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6780 - val_loss: 31.2992\n",
      "Epoch 128/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6780 - val_loss: 31.2992\n",
      "Epoch 129/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6780 - val_loss: 31.2992\n",
      "Epoch 130/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6780 - val_loss: 31.2992\n",
      "Epoch 131/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6780 - val_loss: 31.2991\n",
      "Epoch 132/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6780 - val_loss: 31.2991\n",
      "Epoch 133/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6779 - val_loss: 31.2991\n",
      "Epoch 134/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6779 - val_loss: 31.2991\n",
      "Epoch 135/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6779 - val_loss: 31.2991\n",
      "Epoch 136/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6779 - val_loss: 31.2991\n",
      "Epoch 137/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6779 - val_loss: 31.2991\n",
      "Epoch 138/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6779 - val_loss: 31.2991\n",
      "Epoch 139/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6779 - val_loss: 31.2991\n",
      "Epoch 140/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6779 - val_loss: 31.2991\n",
      "Epoch 141/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6779 - val_loss: 31.2991\n",
      "Epoch 142/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6779 - val_loss: 31.2991\n",
      "Epoch 143/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6779 - val_loss: 31.2991\n",
      "Epoch 144/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6779 - val_loss: 31.2991\n",
      "Epoch 145/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6779 - val_loss: 31.2991\n",
      "Epoch 146/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6779 - val_loss: 31.2991\n",
      "Epoch 147/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6779 - val_loss: 31.2991\n",
      "Epoch 148/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6779 - val_loss: 31.2991\n",
      "Epoch 149/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6779 - val_loss: 31.2991\n",
      "Epoch 150/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6779 - val_loss: 31.2991\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 2000)              202000    \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_5 (TFOpLamb (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_5 (TFOpLambda)   (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_5 (TFOpLa (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_5 (TFOpL ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_5 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_5 (AddLoss)         ()                        0         \n",
      "=================================================================\n",
      "Total params: 212,100\n",
      "Trainable params: 212,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 17.6217 - val_loss: 6.6604\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 5.2607 - val_loss: 3.5594\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 3.5501 - val_loss: 2.9485\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 3.1250 - val_loss: 2.6936\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.9275 - val_loss: 2.5656\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.8019 - val_loss: 2.4818\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.7121 - val_loss: 2.4224\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.6419 - val_loss: 2.3689\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.5937 - val_loss: 2.3273\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.5364 - val_loss: 2.3014\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.4984 - val_loss: 2.2713\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.4640 - val_loss: 2.2596\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.4332 - val_loss: 2.2533\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.4125 - val_loss: 2.2460\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.3896 - val_loss: 2.2352\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 2.3650 - val_loss: 2.2354\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.3483 - val_loss: 2.2318\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.3341 - val_loss: 2.2323\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.3214 - val_loss: 2.2323\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.3082 - val_loss: 2.2321\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2979 - val_loss: 2.2310\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2888 - val_loss: 2.2300\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2812 - val_loss: 2.2307\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2737 - val_loss: 2.2295\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2675 - val_loss: 2.2303\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2617 - val_loss: 2.2292\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2549 - val_loss: 2.2300\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2484 - val_loss: 2.2292\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2405 - val_loss: 2.2286\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2369 - val_loss: 2.2288\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2308 - val_loss: 2.2278\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2267 - val_loss: 2.2272\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2267 - val_loss: 2.2276\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2240 - val_loss: 2.2269\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2235 - val_loss: 2.2268\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2268\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 57/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 92/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 93/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 94/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 95/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 96/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 97/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 98/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 99/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Epoch 100/100\n",
      "144/144 [==============================] - 0s 2ms/step - loss: 2.2234 - val_loss: 2.2267\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 2)                 202       \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 100)               300       \n",
      "=================================================================\n",
      "Total params: 29,216\n",
      "Trainable params: 29,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 1s 4ms/step - loss: 5.1666 - val_loss: 3.3289\n",
      "Epoch 2/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 2.8509 - val_loss: 2.1540\n",
      "Epoch 3/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 2.1124 - val_loss: 1.6908\n",
      "Epoch 4/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 1.7715 - val_loss: 1.4433\n",
      "Epoch 5/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 1.5584 - val_loss: 1.2774\n",
      "Epoch 6/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.4088 - val_loss: 1.1648\n",
      "Epoch 7/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 1.2926 - val_loss: 1.0836\n",
      "Epoch 8/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 1.2126 - val_loss: 1.0195\n",
      "Epoch 9/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.1434 - val_loss: 0.9716\n",
      "Epoch 10/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 1.0911 - val_loss: 0.9335\n",
      "Epoch 11/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 1.0397 - val_loss: 0.9031\n",
      "Epoch 12/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.9971 - val_loss: 0.8783\n",
      "Epoch 13/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.9663 - val_loss: 0.8578\n",
      "Epoch 14/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.9391 - val_loss: 0.8384\n",
      "Epoch 15/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.9154 - val_loss: 0.8229\n",
      "Epoch 16/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.8915 - val_loss: 0.8096\n",
      "Epoch 17/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.8687 - val_loss: 0.7977\n",
      "Epoch 18/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.8552 - val_loss: 0.7866\n",
      "Epoch 19/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8374 - val_loss: 0.7770\n",
      "Epoch 20/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.8257 - val_loss: 0.7680\n",
      "Epoch 21/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.8128 - val_loss: 0.7599\n",
      "Epoch 22/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8016 - val_loss: 0.7524\n",
      "Epoch 23/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7928 - val_loss: 0.7455\n",
      "Epoch 24/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7854 - val_loss: 0.7390\n",
      "Epoch 25/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7757 - val_loss: 0.7330\n",
      "Epoch 26/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7673 - val_loss: 0.7276\n",
      "Epoch 27/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7585 - val_loss: 0.7224\n",
      "Epoch 28/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7547 - val_loss: 0.7176\n",
      "Epoch 29/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7486 - val_loss: 0.7130\n",
      "Epoch 30/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7409 - val_loss: 0.7089\n",
      "Epoch 31/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7360 - val_loss: 0.7049\n",
      "Epoch 32/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7319 - val_loss: 0.7013\n",
      "Epoch 33/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7264 - val_loss: 0.6979\n",
      "Epoch 34/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7228 - val_loss: 0.6946\n",
      "Epoch 35/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7197 - val_loss: 0.6915\n",
      "Epoch 36/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7148 - val_loss: 0.6886\n",
      "Epoch 37/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7120 - val_loss: 0.6859\n",
      "Epoch 38/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7085 - val_loss: 0.6834\n",
      "Epoch 39/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7057 - val_loss: 0.6809\n",
      "Epoch 40/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7026 - val_loss: 0.6786\n",
      "Epoch 41/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7002 - val_loss: 0.6765\n",
      "Epoch 42/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6976 - val_loss: 0.6745\n",
      "Epoch 43/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6951 - val_loss: 0.6726\n",
      "Epoch 44/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6931 - val_loss: 0.6708\n",
      "Epoch 45/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6911 - val_loss: 0.6691\n",
      "Epoch 46/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6890 - val_loss: 0.6675\n",
      "Epoch 47/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6870 - val_loss: 0.6660\n",
      "Epoch 48/150\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.6852 - val_loss: 0.6646\n",
      "Epoch 49/150\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 0.6839 - val_loss: 0.6633\n",
      "Epoch 50/150\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.6825 - val_loss: 0.6620\n",
      "Epoch 51/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6810 - val_loss: 0.6608\n",
      "Epoch 52/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6797 - val_loss: 0.6597\n",
      "Epoch 53/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6785 - val_loss: 0.6587\n",
      "Epoch 54/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6772 - val_loss: 0.6577\n",
      "Epoch 55/150\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.6763 - val_loss: 0.6568\n",
      "Epoch 56/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6754 - val_loss: 0.6558\n",
      "Epoch 57/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6744 - val_loss: 0.6550\n",
      "Epoch 58/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6735 - val_loss: 0.6542\n",
      "Epoch 59/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6727 - val_loss: 0.6535\n",
      "Epoch 60/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6720 - val_loss: 0.6528\n",
      "Epoch 61/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6712 - val_loss: 0.6522\n",
      "Epoch 62/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6707 - val_loss: 0.6516\n",
      "Epoch 63/150\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.6700 - val_loss: 0.6510\n",
      "Epoch 64/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6694 - val_loss: 0.6505\n",
      "Epoch 65/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6689 - val_loss: 0.6500\n",
      "Epoch 66/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6684 - val_loss: 0.6495\n",
      "Epoch 67/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6679 - val_loss: 0.6491\n",
      "Epoch 68/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6675 - val_loss: 0.6486\n",
      "Epoch 69/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6671 - val_loss: 0.6483\n",
      "Epoch 70/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6667 - val_loss: 0.6479\n",
      "Epoch 71/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6664 - val_loss: 0.6476\n",
      "Epoch 72/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6661 - val_loss: 0.6473\n",
      "Epoch 73/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6658 - val_loss: 0.6470\n",
      "Epoch 74/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6655 - val_loss: 0.6467\n",
      "Epoch 75/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6652 - val_loss: 0.6464\n",
      "Epoch 76/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6650 - val_loss: 0.6462\n",
      "Epoch 77/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6648 - val_loss: 0.6460\n",
      "Epoch 78/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6646 - val_loss: 0.6458\n",
      "Epoch 79/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6644 - val_loss: 0.6456\n",
      "Epoch 80/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6642 - val_loss: 0.6454\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6640 - val_loss: 0.6453\n",
      "Epoch 82/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6639 - val_loss: 0.6451\n",
      "Epoch 83/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6638 - val_loss: 0.6450\n",
      "Epoch 84/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6636 - val_loss: 0.6448\n",
      "Epoch 85/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6635 - val_loss: 0.6447\n",
      "Epoch 86/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6634 - val_loss: 0.6446\n",
      "Epoch 87/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6633 - val_loss: 0.6445\n",
      "Epoch 88/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6632 - val_loss: 0.6444\n",
      "Epoch 89/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6631 - val_loss: 0.6443\n",
      "Epoch 90/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6630 - val_loss: 0.6442\n",
      "Epoch 91/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6630 - val_loss: 0.6441\n",
      "Epoch 92/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6629 - val_loss: 0.6441\n",
      "Epoch 93/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6628 - val_loss: 0.6440\n",
      "Epoch 94/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6628 - val_loss: 0.6439\n",
      "Epoch 95/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6627 - val_loss: 0.6439\n",
      "Epoch 96/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6627 - val_loss: 0.6438\n",
      "Epoch 97/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6626 - val_loss: 0.6438\n",
      "Epoch 98/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6626 - val_loss: 0.6437\n",
      "Epoch 99/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6625 - val_loss: 0.6437\n",
      "Epoch 100/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6625 - val_loss: 0.6436\n",
      "Epoch 101/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6624 - val_loss: 0.6436\n",
      "Epoch 102/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6624 - val_loss: 0.6436\n",
      "Epoch 103/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6624 - val_loss: 0.6435\n",
      "Epoch 104/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6624 - val_loss: 0.6435\n",
      "Epoch 105/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6623 - val_loss: 0.6435\n",
      "Epoch 106/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6623 - val_loss: 0.6434\n",
      "Epoch 107/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6623 - val_loss: 0.6434\n",
      "Epoch 108/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6623 - val_loss: 0.6434\n",
      "Epoch 109/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6622 - val_loss: 0.6434\n",
      "Epoch 110/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6622 - val_loss: 0.6434\n",
      "Epoch 111/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6622 - val_loss: 0.6433\n",
      "Epoch 112/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6622 - val_loss: 0.6433\n",
      "Epoch 113/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6622 - val_loss: 0.6433\n",
      "Epoch 114/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6622 - val_loss: 0.6433\n",
      "Epoch 115/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6621 - val_loss: 0.6433\n",
      "Epoch 116/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6621 - val_loss: 0.6433\n",
      "Epoch 117/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6621 - val_loss: 0.6432\n",
      "Epoch 118/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6621 - val_loss: 0.6432\n",
      "Epoch 119/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6621 - val_loss: 0.6432\n",
      "Epoch 120/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6621 - val_loss: 0.6432\n",
      "Epoch 121/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6621 - val_loss: 0.6432\n",
      "Epoch 122/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6621 - val_loss: 0.6432\n",
      "Epoch 123/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6621 - val_loss: 0.6432\n",
      "Epoch 124/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6621 - val_loss: 0.6432\n",
      "Epoch 125/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6621 - val_loss: 0.6432\n",
      "Epoch 126/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6620 - val_loss: 0.6431\n",
      "Epoch 127/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6620 - val_loss: 0.6431\n",
      "Epoch 128/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6620 - val_loss: 0.6431\n",
      "Epoch 129/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6620 - val_loss: 0.6431\n",
      "Epoch 130/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6620 - val_loss: 0.6431\n",
      "Epoch 131/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6620 - val_loss: 0.6431\n",
      "Epoch 132/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6620 - val_loss: 0.6431\n",
      "Epoch 133/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6620 - val_loss: 0.6431\n",
      "Epoch 134/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6620 - val_loss: 0.6431\n",
      "Epoch 135/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6620 - val_loss: 0.6431\n",
      "Epoch 136/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6620 - val_loss: 0.6431\n",
      "Epoch 137/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6620 - val_loss: 0.6431\n",
      "Epoch 138/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6620 - val_loss: 0.6431\n",
      "Epoch 139/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6620 - val_loss: 0.6431\n",
      "Epoch 140/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6620 - val_loss: 0.6431\n",
      "Epoch 141/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6620 - val_loss: 0.6431\n",
      "Epoch 142/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6620 - val_loss: 0.6431\n",
      "Epoch 143/150\n",
      "137/137 [==============================] - 0s 4ms/step - loss: 0.6620 - val_loss: 0.6431\n",
      "Epoch 144/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6620 - val_loss: 0.6431\n",
      "Epoch 145/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6620 - val_loss: 0.6431\n",
      "Epoch 146/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6620 - val_loss: 0.6430\n",
      "Epoch 147/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6620 - val_loss: 0.6430\n",
      "Epoch 148/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6620 - val_loss: 0.6430\n",
      "Epoch 149/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6620 - val_loss: 0.6430\n",
      "Epoch 150/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6620 - val_loss: 0.6430\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 2000)              202000    \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_7 (TFOpLamb (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_7 (TFOpLambda)   (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_7 (TFOpLa (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_7 (TFOpL ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_7 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_7 (AddLoss)         ()                        0         \n",
      "=================================================================\n",
      "Total params: 212,100\n",
      "Trainable params: 212,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 1s 4ms/step - loss: 14.5651 - val_loss: 15.3194\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 4.3994 - val_loss: 14.8296\n",
      "Epoch 3/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 3.3047 - val_loss: 13.8848\n",
      "Epoch 4/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.9379 - val_loss: 14.8232\n",
      "Epoch 5/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.7523 - val_loss: 15.6727\n",
      "Epoch 6/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.6403 - val_loss: 15.7491\n",
      "Epoch 7/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.5716 - val_loss: 16.3783\n",
      "Epoch 8/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.5167 - val_loss: 18.7199\n",
      "Epoch 9/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.4699 - val_loss: 18.4926\n",
      "Epoch 10/100\n",
      "145/145 [==============================] - ETA: 0s - loss: 2.437 - 0s 3ms/step - loss: 2.4275 - val_loss: 19.3626\n",
      "Epoch 11/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.4043 - val_loss: 19.4111\n",
      "Epoch 12/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.3747 - val_loss: 20.2866\n",
      "Epoch 13/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.3521 - val_loss: 20.9855\n",
      "Epoch 14/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.3330 - val_loss: 27.0383\n",
      "Epoch 15/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.3272 - val_loss: 31.1289\n",
      "Epoch 16/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.3293 - val_loss: 23.8589\n",
      "Epoch 17/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2957 - val_loss: 23.5054\n",
      "Epoch 18/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2841 - val_loss: 23.4922\n",
      "Epoch 19/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2765 - val_loss: 26.6445\n",
      "Epoch 20/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2713 - val_loss: 30.0986\n",
      "Epoch 21/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2680 - val_loss: 24.9977\n",
      "Epoch 22/100\n",
      "145/145 [==============================] - 1s 3ms/step - loss: 2.2527 - val_loss: 24.8755\n",
      "Epoch 23/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2468 - val_loss: 26.1019\n",
      "Epoch 24/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2446 - val_loss: 30.2726\n",
      "Epoch 25/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 2.2441 - val_loss: 35.2131\n",
      "Epoch 26/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 2.2495 - val_loss: 35.1938\n",
      "Epoch 27/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2389 - val_loss: 30.9626\n",
      "Epoch 28/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2329 - val_loss: 29.1512\n",
      "Epoch 29/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2307 - val_loss: 30.2147\n",
      "Epoch 30/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2289 - val_loss: 31.9761\n",
      "Epoch 31/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2274 - val_loss: 37.4854\n",
      "Epoch 32/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2278 - val_loss: 36.5370\n",
      "Epoch 33/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2252 - val_loss: 35.8201\n",
      "Epoch 34/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 2.2230 - val_loss: 32.4818\n",
      "Epoch 35/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 2.2188 - val_loss: 30.8565\n",
      "Epoch 36/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2177 - val_loss: 30.7832\n",
      "Epoch 37/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2172 - val_loss: 31.1228\n",
      "Epoch 38/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2162 - val_loss: 31.2897\n",
      "Epoch 39/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2153 - val_loss: 31.3548\n",
      "Epoch 40/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2151 - val_loss: 31.4025\n",
      "Epoch 41/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2151 - val_loss: 31.4432\n",
      "Epoch 42/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2150 - val_loss: 31.4772\n",
      "Epoch 43/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2150 - val_loss: 31.5043\n",
      "Epoch 44/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2150 - val_loss: 31.5280\n",
      "Epoch 45/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2150 - val_loss: 31.5443\n",
      "Epoch 46/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2150 - val_loss: 31.5631\n",
      "Epoch 47/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2150 - val_loss: 31.5789\n",
      "Epoch 48/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2150 - val_loss: 31.5918\n",
      "Epoch 49/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2150 - val_loss: 31.6027\n",
      "Epoch 50/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2150 - val_loss: 31.6115\n",
      "Epoch 51/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2150 - val_loss: 31.6189\n",
      "Epoch 52/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2150 - val_loss: 31.6240\n",
      "Epoch 53/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2150 - val_loss: 31.6293\n",
      "Epoch 54/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2150 - val_loss: 31.6341\n",
      "Epoch 55/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2150 - val_loss: 31.6373\n",
      "Epoch 56/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6401\n",
      "Epoch 57/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6422\n",
      "Epoch 58/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6439\n",
      "Epoch 59/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6454\n",
      "Epoch 60/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6465\n",
      "Epoch 61/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6474\n",
      "Epoch 62/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2150 - val_loss: 31.6482\n",
      "Epoch 63/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6488\n",
      "Epoch 64/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6491\n",
      "Epoch 65/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6495\n",
      "Epoch 66/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6499\n",
      "Epoch 67/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6502\n",
      "Epoch 68/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6503\n",
      "Epoch 69/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6504\n",
      "Epoch 70/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6505\n",
      "Epoch 71/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6505\n",
      "Epoch 72/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6506\n",
      "Epoch 73/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6506\n",
      "Epoch 74/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6506\n",
      "Epoch 75/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6506\n",
      "Epoch 76/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6506\n",
      "Epoch 77/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6507\n",
      "Epoch 78/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6507\n",
      "Epoch 79/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6507\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6507\n",
      "Epoch 81/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6508\n",
      "Epoch 82/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6508\n",
      "Epoch 83/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6509\n",
      "Epoch 84/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6509\n",
      "Epoch 85/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6509\n",
      "Epoch 86/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6509\n",
      "Epoch 87/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6509\n",
      "Epoch 88/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6509\n",
      "Epoch 89/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6509\n",
      "Epoch 90/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6509\n",
      "Epoch 91/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6509\n",
      "Epoch 92/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6509\n",
      "Epoch 93/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6509\n",
      "Epoch 94/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6509\n",
      "Epoch 95/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6509\n",
      "Epoch 96/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6509\n",
      "Epoch 97/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.2150 - val_loss: 31.6509\n",
      "Epoch 98/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6509\n",
      "Epoch 99/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6509\n",
      "Epoch 100/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2150 - val_loss: 31.6509\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 2)                 202       \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 100)               300       \n",
      "=================================================================\n",
      "Total params: 29,216\n",
      "Trainable params: 29,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "137/137 [==============================] - 1s 3ms/step - loss: 5.8055 - val_loss: 5.4477\n",
      "Epoch 2/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 3.4445 - val_loss: 5.8237\n",
      "Epoch 3/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 2.6328 - val_loss: 6.8449\n",
      "Epoch 4/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 2.1996 - val_loss: 8.0090\n",
      "Epoch 5/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.9217 - val_loss: 9.1407\n",
      "Epoch 6/150\n",
      "137/137 [==============================] - ETA: 0s - loss: 1.576 - 0s 2ms/step - loss: 1.7112 - val_loss: 10.1395\n",
      "Epoch 7/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.5571 - val_loss: 11.4470\n",
      "Epoch 8/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.4276 - val_loss: 12.5004\n",
      "Epoch 9/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.3234 - val_loss: 13.6828\n",
      "Epoch 10/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.2487 - val_loss: 14.8191\n",
      "Epoch 11/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.1860 - val_loss: 15.9163\n",
      "Epoch 12/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.1172 - val_loss: 17.0610\n",
      "Epoch 13/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.0692 - val_loss: 17.9973\n",
      "Epoch 14/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1.0262 - val_loss: 19.0870\n",
      "Epoch 15/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.9937 - val_loss: 19.9133\n",
      "Epoch 16/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.9603 - val_loss: 20.8620\n",
      "Epoch 17/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.9310 - val_loss: 21.6501\n",
      "Epoch 18/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.9106 - val_loss: 22.5165\n",
      "Epoch 19/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8909 - val_loss: 23.2818\n",
      "Epoch 20/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8711 - val_loss: 23.9290\n",
      "Epoch 21/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8568 - val_loss: 24.5334\n",
      "Epoch 22/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8412 - val_loss: 25.1267\n",
      "Epoch 23/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8302 - val_loss: 25.5555\n",
      "Epoch 24/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8219 - val_loss: 26.0449\n",
      "Epoch 25/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8133 - val_loss: 26.4874\n",
      "Epoch 26/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.8035 - val_loss: 26.8513\n",
      "Epoch 27/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7950 - val_loss: 27.1386\n",
      "Epoch 28/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7894 - val_loss: 27.4370\n",
      "Epoch 29/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7816 - val_loss: 27.6636\n",
      "Epoch 30/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7781 - val_loss: 27.8495\n",
      "Epoch 31/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7721 - val_loss: 28.0305\n",
      "Epoch 32/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7661 - val_loss: 28.1691\n",
      "Epoch 33/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7612 - val_loss: 28.2898\n",
      "Epoch 34/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7575 - val_loss: 28.3899\n",
      "Epoch 35/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7534 - val_loss: 28.4720\n",
      "Epoch 36/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7492 - val_loss: 28.5383\n",
      "Epoch 37/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7458 - val_loss: 28.5912\n",
      "Epoch 38/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7425 - val_loss: 28.6330\n",
      "Epoch 39/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7398 - val_loss: 28.6678\n",
      "Epoch 40/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7370 - val_loss: 28.6963\n",
      "Epoch 41/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7339 - val_loss: 28.7194\n",
      "Epoch 42/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7317 - val_loss: 28.7368\n",
      "Epoch 43/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7295 - val_loss: 28.7502\n",
      "Epoch 44/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7270 - val_loss: 28.7609\n",
      "Epoch 45/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7251 - val_loss: 28.7693\n",
      "Epoch 46/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7233 - val_loss: 28.7760\n",
      "Epoch 47/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7210 - val_loss: 28.7805\n",
      "Epoch 48/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7194 - val_loss: 28.7839\n",
      "Epoch 49/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7181 - val_loss: 28.7864\n",
      "Epoch 50/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7166 - val_loss: 28.7878\n",
      "Epoch 51/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7152 - val_loss: 28.7886\n",
      "Epoch 52/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7138 - val_loss: 28.7891\n",
      "Epoch 53/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7126 - val_loss: 28.7891\n",
      "Epoch 54/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7114 - val_loss: 28.7889\n",
      "Epoch 55/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7104 - val_loss: 28.7884\n",
      "Epoch 56/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7094 - val_loss: 28.7878\n",
      "Epoch 57/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7086 - val_loss: 28.7872\n",
      "Epoch 58/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7078 - val_loss: 28.7866\n",
      "Epoch 59/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7068 - val_loss: 28.7859\n",
      "Epoch 60/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7061 - val_loss: 28.7852\n",
      "Epoch 61/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7054 - val_loss: 28.7846\n",
      "Epoch 62/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7047 - val_loss: 28.7840\n",
      "Epoch 63/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7041 - val_loss: 28.7835\n",
      "Epoch 64/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7036 - val_loss: 28.7829\n",
      "Epoch 65/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7030 - val_loss: 28.7825\n",
      "Epoch 66/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.7025 - val_loss: 28.7820\n",
      "Epoch 67/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7020 - val_loss: 28.7816\n",
      "Epoch 68/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7016 - val_loss: 28.7812\n",
      "Epoch 69/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7012 - val_loss: 28.7808\n",
      "Epoch 70/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7008 - val_loss: 28.7805\n",
      "Epoch 71/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7005 - val_loss: 28.7801\n",
      "Epoch 72/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.7001 - val_loss: 28.7798\n",
      "Epoch 73/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6999 - val_loss: 28.7796\n",
      "Epoch 74/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6996 - val_loss: 28.7793\n",
      "Epoch 75/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6993 - val_loss: 28.7791\n",
      "Epoch 76/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6991 - val_loss: 28.7788\n",
      "Epoch 77/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6989 - val_loss: 28.7786\n",
      "Epoch 78/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6987 - val_loss: 28.7784\n",
      "Epoch 79/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6985 - val_loss: 28.7783\n",
      "Epoch 80/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6983 - val_loss: 28.7781\n",
      "Epoch 81/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6981 - val_loss: 28.7779\n",
      "Epoch 82/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6980 - val_loss: 28.7778\n",
      "Epoch 83/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6978 - val_loss: 28.7777\n",
      "Epoch 84/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6977 - val_loss: 28.7775\n",
      "Epoch 85/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6976 - val_loss: 28.7774\n",
      "Epoch 86/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6975 - val_loss: 28.7773\n",
      "Epoch 87/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6974 - val_loss: 28.7772\n",
      "Epoch 88/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6973 - val_loss: 28.7771\n",
      "Epoch 89/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6972 - val_loss: 28.7770\n",
      "Epoch 90/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6971 - val_loss: 28.7770\n",
      "Epoch 91/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6970 - val_loss: 28.7769\n",
      "Epoch 92/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6970 - val_loss: 28.7768\n",
      "Epoch 93/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6969 - val_loss: 28.7768\n",
      "Epoch 94/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6968 - val_loss: 28.7767\n",
      "Epoch 95/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6968 - val_loss: 28.7767\n",
      "Epoch 96/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6967 - val_loss: 28.7766\n",
      "Epoch 97/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6967 - val_loss: 28.7766\n",
      "Epoch 98/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6966 - val_loss: 28.7765\n",
      "Epoch 99/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6966 - val_loss: 28.7765\n",
      "Epoch 100/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6966 - val_loss: 28.7765\n",
      "Epoch 101/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6965 - val_loss: 28.7764\n",
      "Epoch 102/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6965 - val_loss: 28.7764\n",
      "Epoch 103/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6965 - val_loss: 28.7764\n",
      "Epoch 104/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6964 - val_loss: 28.7763\n",
      "Epoch 105/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6964 - val_loss: 28.7763\n",
      "Epoch 106/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6964 - val_loss: 28.7763\n",
      "Epoch 107/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6963 - val_loss: 28.7763\n",
      "Epoch 108/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6963 - val_loss: 28.7762\n",
      "Epoch 109/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6963 - val_loss: 28.7762\n",
      "Epoch 110/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6963 - val_loss: 28.7762\n",
      "Epoch 111/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6963 - val_loss: 28.7762\n",
      "Epoch 112/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6963 - val_loss: 28.7762\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6962 - val_loss: 28.7762\n",
      "Epoch 114/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6962 - val_loss: 28.7761\n",
      "Epoch 115/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6962 - val_loss: 28.7761\n",
      "Epoch 116/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6962 - val_loss: 28.7761\n",
      "Epoch 117/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6962 - val_loss: 28.7761\n",
      "Epoch 118/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6962 - val_loss: 28.7761\n",
      "Epoch 119/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6962 - val_loss: 28.7761\n",
      "Epoch 120/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6962 - val_loss: 28.7761\n",
      "Epoch 121/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6961 - val_loss: 28.7761\n",
      "Epoch 122/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6961 - val_loss: 28.7761\n",
      "Epoch 123/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6961 - val_loss: 28.7761\n",
      "Epoch 124/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6961 - val_loss: 28.7760\n",
      "Epoch 125/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6961 - val_loss: 28.7760\n",
      "Epoch 126/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6961 - val_loss: 28.7760\n",
      "Epoch 127/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6961 - val_loss: 28.7760\n",
      "Epoch 128/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6961 - val_loss: 28.7760\n",
      "Epoch 129/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6961 - val_loss: 28.7760\n",
      "Epoch 130/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6961 - val_loss: 28.7760\n",
      "Epoch 131/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6961 - val_loss: 28.7760\n",
      "Epoch 132/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6961 - val_loss: 28.7760\n",
      "Epoch 133/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6961 - val_loss: 28.7760\n",
      "Epoch 134/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6961 - val_loss: 28.7760\n",
      "Epoch 135/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6961 - val_loss: 28.7760\n",
      "Epoch 136/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6961 - val_loss: 28.7760\n",
      "Epoch 137/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6961 - val_loss: 28.7760\n",
      "Epoch 138/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6961 - val_loss: 28.7760\n",
      "Epoch 139/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6960 - val_loss: 28.7760\n",
      "Epoch 140/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6960 - val_loss: 28.7760\n",
      "Epoch 141/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6960 - val_loss: 28.7760\n",
      "Epoch 142/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6960 - val_loss: 28.7760\n",
      "Epoch 143/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6960 - val_loss: 28.7760\n",
      "Epoch 144/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6960 - val_loss: 28.7760\n",
      "Epoch 145/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6960 - val_loss: 28.7760\n",
      "Epoch 146/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6960 - val_loss: 28.7760\n",
      "Epoch 147/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6960 - val_loss: 28.7760\n",
      "Epoch 148/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6960 - val_loss: 28.7760\n",
      "Epoch 149/150\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 0.6960 - val_loss: 28.7760\n",
      "Epoch 150/150\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 0.6960 - val_loss: 28.7760\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 2000)              202000    \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_9 (TFOpLamb (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_9 (TFOpLambda)   (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_9 (TFOpLa (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_9 (TFOpL ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_9 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_9 (AddLoss)         ()                        0         \n",
      "=================================================================\n",
      "Total params: 212,100\n",
      "Trainable params: 212,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 18.6636 - val_loss: 6.3853\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 5.3935 - val_loss: 3.0849\n",
      "Epoch 3/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 3.8161 - val_loss: 2.5471\n",
      "Epoch 4/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 3.3581 - val_loss: 2.3714\n",
      "Epoch 5/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 3.1345 - val_loss: 2.3074\n",
      "Epoch 6/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.9916 - val_loss: 2.2728\n",
      "Epoch 7/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.8890 - val_loss: 2.2559\n",
      "Epoch 8/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.8079 - val_loss: 2.2484\n",
      "Epoch 9/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.7421 - val_loss: 2.2416\n",
      "Epoch 10/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.6839 - val_loss: 2.2395\n",
      "Epoch 11/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.6297 - val_loss: 2.2357\n",
      "Epoch 12/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.5845 - val_loss: 2.2350\n",
      "Epoch 13/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.5434 - val_loss: 2.2352\n",
      "Epoch 14/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.5057 - val_loss: 2.2329\n",
      "Epoch 15/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.4766 - val_loss: 2.2341\n",
      "Epoch 16/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.4507 - val_loss: 2.2328\n",
      "Epoch 17/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.4231 - val_loss: 2.2318\n",
      "Epoch 18/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.3989 - val_loss: 2.2327\n",
      "Epoch 19/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.3813 - val_loss: 2.2313\n",
      "Epoch 20/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.3616 - val_loss: 2.2314\n",
      "Epoch 21/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.3468 - val_loss: 2.2314\n",
      "Epoch 22/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.3318 - val_loss: 2.2321\n",
      "Epoch 23/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.3208 - val_loss: 2.2319\n",
      "Epoch 24/100\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 2.3095 - val_loss: 2.2332\n",
      "Epoch 25/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2999 - val_loss: 2.2334\n",
      "Epoch 26/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2904 - val_loss: 2.2319\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2821 - val_loss: 2.2329\n",
      "Epoch 28/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2739 - val_loss: 2.2322\n",
      "Epoch 29/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2686 - val_loss: 2.2322\n",
      "Epoch 30/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2612 - val_loss: 2.2345\n",
      "Epoch 31/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2545 - val_loss: 2.2319\n",
      "Epoch 32/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2464 - val_loss: 2.2326\n",
      "Epoch 33/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2420 - val_loss: 2.2305\n",
      "Epoch 34/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2388 - val_loss: 2.2307\n",
      "Epoch 35/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2370 - val_loss: 2.2307\n",
      "Epoch 36/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2345 - val_loss: 2.2303\n",
      "Epoch 37/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2334 - val_loss: 2.2313\n",
      "Epoch 38/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2305 - val_loss: 2.2299\n",
      "Epoch 39/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2278 - val_loss: 2.2296\n",
      "Epoch 40/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2276 - val_loss: 2.2294\n",
      "Epoch 41/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2264 - val_loss: 2.2296\n",
      "Epoch 42/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 43/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 44/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 45/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 46/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 47/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 48/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 49/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 50/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 51/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 52/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 53/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 54/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 55/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 56/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 57/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 58/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 59/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 60/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 61/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 62/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 63/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 64/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 65/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 66/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 67/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 68/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 69/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 70/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 71/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 72/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 73/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 74/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 75/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 76/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 77/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 78/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 79/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 80/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 81/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 82/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 83/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 84/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 85/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 86/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 87/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 88/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 89/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 90/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 91/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 92/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 93/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 94/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 95/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 96/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 97/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 98/100\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 99/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "Epoch 100/100\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 2.2262 - val_loss: 2.2294\n",
      "第 musk 個資料處理中....\n",
      "\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 166)               27722     \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 166)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 166)               27722     \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 166)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 2)                 334       \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 166)               498       \n",
      "=================================================================\n",
      "Total params: 64,790\n",
      "Trainable params: 64,790\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 1s 5ms/step - loss: 8.7361 - val_loss: 6.0554\n",
      "Epoch 2/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 5.0903 - val_loss: 4.1401\n",
      "Epoch 3/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 3.7958 - val_loss: 3.2366\n",
      "Epoch 4/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 3.1642 - val_loss: 2.7448\n",
      "Epoch 5/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.7701 - val_loss: 2.4445\n",
      "Epoch 6/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.5304 - val_loss: 2.2352\n",
      "Epoch 7/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.3564 - val_loss: 2.0861\n",
      "Epoch 8/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.2169 - val_loss: 1.9696\n",
      "Epoch 9/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.1126 - val_loss: 1.8776\n",
      "Epoch 10/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.0481 - val_loss: 1.7997\n",
      "Epoch 11/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.9584 - val_loss: 1.7359\n",
      "Epoch 12/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.9031 - val_loss: 1.6825\n",
      "Epoch 13/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.8485 - val_loss: 1.6356\n",
      "Epoch 14/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.8093 - val_loss: 1.5927\n",
      "Epoch 15/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.7504 - val_loss: 1.5558\n",
      "Epoch 16/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.7208 - val_loss: 1.5245\n",
      "Epoch 17/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.6675 - val_loss: 1.4937\n",
      "Epoch 18/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.6563 - val_loss: 1.4677\n",
      "Epoch 19/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.6023 - val_loss: 1.4423\n",
      "Epoch 20/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.5793 - val_loss: 1.4208\n",
      "Epoch 21/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.5691 - val_loss: 1.4002\n",
      "Epoch 22/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.5341 - val_loss: 1.3816\n",
      "Epoch 23/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.5132 - val_loss: 1.3644\n",
      "Epoch 24/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.5091 - val_loss: 1.3475\n",
      "Epoch 25/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.4869 - val_loss: 1.3314\n",
      "Epoch 26/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.4647 - val_loss: 1.3174\n",
      "Epoch 27/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.4437 - val_loss: 1.3040\n",
      "Epoch 28/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.4289 - val_loss: 1.2914\n",
      "Epoch 29/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.4230 - val_loss: 1.2798\n",
      "Epoch 30/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3924 - val_loss: 1.2688\n",
      "Epoch 31/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3760 - val_loss: 1.2578\n",
      "Epoch 32/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.3685 - val_loss: 1.2477\n",
      "Epoch 33/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3566 - val_loss: 1.2382\n",
      "Epoch 34/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3484 - val_loss: 1.2293\n",
      "Epoch 35/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3351 - val_loss: 1.2208\n",
      "Epoch 36/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3180 - val_loss: 1.2132\n",
      "Epoch 37/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3193 - val_loss: 1.2052\n",
      "Epoch 38/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3106 - val_loss: 1.1977\n",
      "Epoch 39/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2939 - val_loss: 1.1902\n",
      "Epoch 40/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2772 - val_loss: 1.1835\n",
      "Epoch 41/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2771 - val_loss: 1.1773\n",
      "Epoch 42/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2672 - val_loss: 1.1710\n",
      "Epoch 43/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2635 - val_loss: 1.1649\n",
      "Epoch 44/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2533 - val_loss: 1.1589\n",
      "Epoch 45/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2324 - val_loss: 1.1537\n",
      "Epoch 46/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2355 - val_loss: 1.1485\n",
      "Epoch 47/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2263 - val_loss: 1.1434\n",
      "Epoch 48/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2179 - val_loss: 1.1387\n",
      "Epoch 49/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2166 - val_loss: 1.1340\n",
      "Epoch 50/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2154 - val_loss: 1.1294\n",
      "Epoch 51/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1947 - val_loss: 1.1251\n",
      "Epoch 52/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1951 - val_loss: 1.1210\n",
      "Epoch 53/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1884 - val_loss: 1.1170\n",
      "Epoch 54/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1848 - val_loss: 1.1131\n",
      "Epoch 55/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1809 - val_loss: 1.1094\n",
      "Epoch 56/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1727 - val_loss: 1.1058\n",
      "Epoch 57/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1670 - val_loss: 1.1024\n",
      "Epoch 58/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1614 - val_loss: 1.0989\n",
      "Epoch 59/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1584 - val_loss: 1.0956\n",
      "Epoch 60/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1518 - val_loss: 1.0925\n",
      "Epoch 61/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1511 - val_loss: 1.0893\n",
      "Epoch 62/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1448 - val_loss: 1.0863\n",
      "Epoch 63/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1435 - val_loss: 1.0835\n",
      "Epoch 64/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1363 - val_loss: 1.0806\n",
      "Epoch 65/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1352 - val_loss: 1.0778\n",
      "Epoch 66/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1306 - val_loss: 1.0751\n",
      "Epoch 67/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1294 - val_loss: 1.0724\n",
      "Epoch 68/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1193 - val_loss: 1.0699\n",
      "Epoch 69/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1229 - val_loss: 1.0674\n",
      "Epoch 70/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1160 - val_loss: 1.0651\n",
      "Epoch 71/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1166 - val_loss: 1.0626\n",
      "Epoch 72/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1115 - val_loss: 1.0603\n",
      "Epoch 73/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1067 - val_loss: 1.0581\n",
      "Epoch 74/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1039 - val_loss: 1.0559\n",
      "Epoch 75/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1038 - val_loss: 1.0538\n",
      "Epoch 76/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1008 - val_loss: 1.0517\n",
      "Epoch 77/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0985 - val_loss: 1.0497\n",
      "Epoch 78/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0939 - val_loss: 1.0477\n",
      "Epoch 79/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0926 - val_loss: 1.0458\n",
      "Epoch 80/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0906 - val_loss: 1.0439\n",
      "Epoch 81/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0860 - val_loss: 1.0421\n",
      "Epoch 82/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0857 - val_loss: 1.0404\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0818 - val_loss: 1.0386\n",
      "Epoch 84/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0800 - val_loss: 1.0369\n",
      "Epoch 85/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0767 - val_loss: 1.0353\n",
      "Epoch 86/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0743 - val_loss: 1.0337\n",
      "Epoch 87/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0729 - val_loss: 1.0322\n",
      "Epoch 88/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0720 - val_loss: 1.0307\n",
      "Epoch 89/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0694 - val_loss: 1.0292\n",
      "Epoch 90/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0673 - val_loss: 1.0278\n",
      "Epoch 91/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0670 - val_loss: 1.0264\n",
      "Epoch 92/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0646 - val_loss: 1.0250\n",
      "Epoch 93/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0620 - val_loss: 1.0236\n",
      "Epoch 94/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0608 - val_loss: 1.0223\n",
      "Epoch 95/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0593 - val_loss: 1.0211\n",
      "Epoch 96/150\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0589 - val_loss: 1.0198\n",
      "Epoch 97/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0560 - val_loss: 1.0186\n",
      "Epoch 98/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0548 - val_loss: 1.0174\n",
      "Epoch 99/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0531 - val_loss: 1.0162\n",
      "Epoch 100/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0520 - val_loss: 1.0151\n",
      "Epoch 101/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0502 - val_loss: 1.0140\n",
      "Epoch 102/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0492 - val_loss: 1.0129\n",
      "Epoch 103/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0475 - val_loss: 1.0119\n",
      "Epoch 104/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0462 - val_loss: 1.0109\n",
      "Epoch 105/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0454 - val_loss: 1.0099\n",
      "Epoch 106/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0436 - val_loss: 1.0089\n",
      "Epoch 107/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0426 - val_loss: 1.0080\n",
      "Epoch 108/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0413 - val_loss: 1.0070\n",
      "Epoch 109/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0400 - val_loss: 1.0061\n",
      "Epoch 110/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0395 - val_loss: 1.0053\n",
      "Epoch 111/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0384 - val_loss: 1.0044\n",
      "Epoch 112/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0372 - val_loss: 1.0036\n",
      "Epoch 113/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0361 - val_loss: 1.0028\n",
      "Epoch 114/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0354 - val_loss: 1.0020\n",
      "Epoch 115/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0339 - val_loss: 1.0012\n",
      "Epoch 116/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0332 - val_loss: 1.0005\n",
      "Epoch 117/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0328 - val_loss: 0.9997\n",
      "Epoch 118/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0318 - val_loss: 0.9990\n",
      "Epoch 119/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0313 - val_loss: 0.9983\n",
      "Epoch 120/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0299 - val_loss: 0.9976\n",
      "Epoch 121/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0292 - val_loss: 0.9969\n",
      "Epoch 122/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0284 - val_loss: 0.9963\n",
      "Epoch 123/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0279 - val_loss: 0.9956\n",
      "Epoch 124/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0269 - val_loss: 0.9950\n",
      "Epoch 125/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0264 - val_loss: 0.9944\n",
      "Epoch 126/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0256 - val_loss: 0.9938\n",
      "Epoch 127/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0251 - val_loss: 0.9932\n",
      "Epoch 128/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0242 - val_loss: 0.9927\n",
      "Epoch 129/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0237 - val_loss: 0.9921\n",
      "Epoch 130/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0232 - val_loss: 0.9916\n",
      "Epoch 131/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0223 - val_loss: 0.9911\n",
      "Epoch 132/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0218 - val_loss: 0.9906\n",
      "Epoch 133/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0214 - val_loss: 0.9901\n",
      "Epoch 134/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0206 - val_loss: 0.9896\n",
      "Epoch 135/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0202 - val_loss: 0.9891\n",
      "Epoch 136/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0197 - val_loss: 0.9887\n",
      "Epoch 137/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0190 - val_loss: 0.9882\n",
      "Epoch 138/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0186 - val_loss: 0.9878\n",
      "Epoch 139/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0183 - val_loss: 0.9873\n",
      "Epoch 140/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0178 - val_loss: 0.9869\n",
      "Epoch 141/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0173 - val_loss: 0.9865\n",
      "Epoch 142/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0169 - val_loss: 0.9862\n",
      "Epoch 143/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0167 - val_loss: 0.9858\n",
      "Epoch 144/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0161 - val_loss: 0.9854\n",
      "Epoch 145/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0156 - val_loss: 0.9850\n",
      "Epoch 146/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0154 - val_loss: 0.9847\n",
      "Epoch 147/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0149 - val_loss: 0.9843\n",
      "Epoch 148/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0147 - val_loss: 0.9840\n",
      "Epoch 149/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0144 - val_loss: 0.9837\n",
      "Epoch 150/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0138 - val_loss: 0.9833\n",
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 166)]             0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 166)               27722     \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 3320)              554440    \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_11 (TFOpLam (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_11 (TFOpLambda)  (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_11 (TFOpL (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_11 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_11 (TFO ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_11 (AddLoss)        ()                        0         \n",
      "=================================================================\n",
      "Total params: 582,162\n",
      "Trainable params: 582,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 8ms/step - loss: 30.6498 - val_loss: 15.8385\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 11.8712 - val_loss: 9.3720\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 8.2240 - val_loss: 7.5822\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 6.9184 - val_loss: 6.6259\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 6.3047 - val_loss: 6.1294\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.9859 - val_loss: 5.9768\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.8086 - val_loss: 5.8582\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 5.6797 - val_loss: 5.6663\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 5.5716 - val_loss: 5.5558\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 5.4989 - val_loss: 5.5485\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 5.4603 - val_loss: 5.4905\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.4066 - val_loss: 5.4031\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.3442 - val_loss: 5.3722\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.3289 - val_loss: 5.3519\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.2968 - val_loss: 5.3026\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.2686 - val_loss: 5.2966\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.2576 - val_loss: 5.2720\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.2383 - val_loss: 5.2545\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.2168 - val_loss: 5.2362\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1946 - val_loss: 5.2251\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1857 - val_loss: 5.2042\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1781 - val_loss: 5.2004\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1716 - val_loss: 5.1904\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1648 - val_loss: 5.1805\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1602 - val_loss: 5.1767\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1558 - val_loss: 5.1720\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1517 - val_loss: 5.1654\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1485 - val_loss: 5.1610\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1458 - val_loss: 5.1617\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1438 - val_loss: 5.1542\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1417 - val_loss: 5.1519\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1400 - val_loss: 5.1498\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1386 - val_loss: 5.1485\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1373 - val_loss: 5.1460\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1364 - val_loss: 5.1443\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.1354 - val_loss: 5.1439\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1346 - val_loss: 5.1430\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1339 - val_loss: 5.1419\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1333 - val_loss: 5.1400\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1327 - val_loss: 5.1400\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1322 - val_loss: 5.1392\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1318 - val_loss: 5.1384\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1315 - val_loss: 5.1371\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1311 - val_loss: 5.1367\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1308 - val_loss: 5.1362\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1306 - val_loss: 5.1361\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1303 - val_loss: 5.1349\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1301 - val_loss: 5.1352\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1300 - val_loss: 5.1346\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1298 - val_loss: 5.1341\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1297 - val_loss: 5.1340\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1295 - val_loss: 5.1341\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1294 - val_loss: 5.1334\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1293 - val_loss: 5.1332\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1292 - val_loss: 5.1331\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1292 - val_loss: 5.1330\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1291 - val_loss: 5.1327\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1290 - val_loss: 5.1324\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1290 - val_loss: 5.1323\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1289 - val_loss: 5.1321\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1289 - val_loss: 5.1321\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1288 - val_loss: 5.1319\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1288 - val_loss: 5.1318\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1288 - val_loss: 5.1318\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1287 - val_loss: 5.1317\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1287 - val_loss: 5.1315\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1287 - val_loss: 5.1314\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1286 - val_loss: 5.1314\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1286 - val_loss: 5.1313\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1286 - val_loss: 5.1312\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1286 - val_loss: 5.1312\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1286 - val_loss: 5.1311\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1286 - val_loss: 5.1310\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1286 - val_loss: 5.1310\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1285 - val_loss: 5.1310\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1285 - val_loss: 5.1309\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1285 - val_loss: 5.1308\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1285 - val_loss: 5.1308\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1285 - val_loss: 5.1307\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1285 - val_loss: 5.1307\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.1285 - val_loss: 5.1306\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1285 - val_loss: 5.1306\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1285 - val_loss: 5.1306\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1285 - val_loss: 5.1305\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1285 - val_loss: 5.1305\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1285 - val_loss: 5.1305\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1285 - val_loss: 5.1305\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1285 - val_loss: 5.1305\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1285 - val_loss: 5.1305\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1285 - val_loss: 5.1305\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1285 - val_loss: 5.1304\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1285 - val_loss: 5.1304\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1285 - val_loss: 5.1304\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1285 - val_loss: 5.1304\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1285 - val_loss: 5.1304\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1285 - val_loss: 5.1304\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1285 - val_loss: 5.1304\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1285 - val_loss: 5.1304\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1285 - val_loss: 5.1303\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1285 - val_loss: 5.1303\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_66 (Dense)             (None, 166)               27722     \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 166)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 166)               27722     \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 166)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 2)                 334       \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 166)               498       \n",
      "=================================================================\n",
      "Total params: 64,790\n",
      "Trainable params: 64,790\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "59/59 [==============================] - 1s 6ms/step - loss: 8.6942 - val_loss: 6.0628\n",
      "Epoch 2/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 5.0539 - val_loss: 4.1717\n",
      "Epoch 3/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 3.7718 - val_loss: 3.2658\n",
      "Epoch 4/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 3.1554 - val_loss: 2.7783\n",
      "Epoch 5/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.7553 - val_loss: 2.4808\n",
      "Epoch 6/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 2.5086 - val_loss: 2.2739\n",
      "Epoch 7/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 2.3595 - val_loss: 2.1209\n",
      "Epoch 8/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 2.2321 - val_loss: 2.0053\n",
      "Epoch 9/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.1406 - val_loss: 1.9132\n",
      "Epoch 10/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.0408 - val_loss: 1.8385\n",
      "Epoch 11/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.9460 - val_loss: 1.7751\n",
      "Epoch 12/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.9097 - val_loss: 1.7219\n",
      "Epoch 13/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.8615 - val_loss: 1.6713\n",
      "Epoch 14/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.8044 - val_loss: 1.6304\n",
      "Epoch 15/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.7327 - val_loss: 1.5938\n",
      "Epoch 16/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.7032 - val_loss: 1.5619\n",
      "Epoch 17/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.6753 - val_loss: 1.5315\n",
      "Epoch 18/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.6643 - val_loss: 1.5045\n",
      "Epoch 19/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.6064 - val_loss: 1.4806\n",
      "Epoch 20/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.5866 - val_loss: 1.4585\n",
      "Epoch 21/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.5544 - val_loss: 1.4379\n",
      "Epoch 22/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.5476 - val_loss: 1.4186\n",
      "Epoch 23/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.5198 - val_loss: 1.4014\n",
      "Epoch 24/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.5053 - val_loss: 1.3852\n",
      "Epoch 25/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.4621 - val_loss: 1.3691\n",
      "Epoch 26/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.4486 - val_loss: 1.3559\n",
      "Epoch 27/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.4513 - val_loss: 1.3415\n",
      "Epoch 28/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.4296 - val_loss: 1.3290\n",
      "Epoch 29/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.4097 - val_loss: 1.3183\n",
      "Epoch 30/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3886 - val_loss: 1.3064\n",
      "Epoch 31/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3852 - val_loss: 1.2957\n",
      "Epoch 32/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3616 - val_loss: 1.2861\n",
      "Epoch 33/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3525 - val_loss: 1.2760\n",
      "Epoch 34/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3360 - val_loss: 1.2672\n",
      "Epoch 35/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3332 - val_loss: 1.2586\n",
      "Epoch 36/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3323 - val_loss: 1.2504\n",
      "Epoch 37/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3083 - val_loss: 1.2433\n",
      "Epoch 38/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3003 - val_loss: 1.2351\n",
      "Epoch 39/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2913 - val_loss: 1.2283\n",
      "Epoch 40/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2790 - val_loss: 1.2213\n",
      "Epoch 41/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2678 - val_loss: 1.2148\n",
      "Epoch 42/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2646 - val_loss: 1.2086\n",
      "Epoch 43/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2570 - val_loss: 1.2026\n",
      "Epoch 44/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2432 - val_loss: 1.1969\n",
      "Epoch 45/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2389 - val_loss: 1.1916\n",
      "Epoch 46/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2238 - val_loss: 1.1866\n",
      "Epoch 47/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2254 - val_loss: 1.1815\n",
      "Epoch 48/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2156 - val_loss: 1.1766\n",
      "Epoch 49/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2071 - val_loss: 1.1718\n",
      "Epoch 50/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2064 - val_loss: 1.1674\n",
      "Epoch 51/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2028 - val_loss: 1.1629\n",
      "Epoch 52/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1922 - val_loss: 1.1588\n",
      "Epoch 53/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1884 - val_loss: 1.1547\n",
      "Epoch 54/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1859 - val_loss: 1.1507\n",
      "Epoch 55/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1731 - val_loss: 1.1470\n",
      "Epoch 56/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1699 - val_loss: 1.1434\n",
      "Epoch 57/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1652 - val_loss: 1.1399\n",
      "Epoch 58/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1566 - val_loss: 1.1366\n",
      "Epoch 59/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1555 - val_loss: 1.1333\n",
      "Epoch 60/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1531 - val_loss: 1.1301\n",
      "Epoch 61/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1466 - val_loss: 1.1269\n",
      "Epoch 62/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1426 - val_loss: 1.1239\n",
      "Epoch 63/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1411 - val_loss: 1.1209\n",
      "Epoch 64/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1338 - val_loss: 1.1181\n",
      "Epoch 65/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1292 - val_loss: 1.1154\n",
      "Epoch 66/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1279 - val_loss: 1.1127\n",
      "Epoch 67/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1226 - val_loss: 1.1101\n",
      "Epoch 68/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1210 - val_loss: 1.1075\n",
      "Epoch 69/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1163 - val_loss: 1.1050\n",
      "Epoch 70/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1135 - val_loss: 1.1026\n",
      "Epoch 71/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1096 - val_loss: 1.1002\n",
      "Epoch 72/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1073 - val_loss: 1.0980\n",
      "Epoch 73/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1013 - val_loss: 1.0958\n",
      "Epoch 74/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1004 - val_loss: 1.0936\n",
      "Epoch 75/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0985 - val_loss: 1.0915\n",
      "Epoch 76/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0943 - val_loss: 1.0895\n",
      "Epoch 77/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0914 - val_loss: 1.0875\n",
      "Epoch 78/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0877 - val_loss: 1.0856\n",
      "Epoch 79/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0887 - val_loss: 1.0837\n",
      "Epoch 80/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0835 - val_loss: 1.0818\n",
      "Epoch 81/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0841 - val_loss: 1.0801\n",
      "Epoch 82/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0789 - val_loss: 1.0783\n",
      "Epoch 83/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0766 - val_loss: 1.0766\n",
      "Epoch 84/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0752 - val_loss: 1.0750\n",
      "Epoch 85/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0735 - val_loss: 1.0734\n",
      "Epoch 86/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0710 - val_loss: 1.0718\n",
      "Epoch 87/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0680 - val_loss: 1.0702\n",
      "Epoch 88/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0659 - val_loss: 1.0688\n",
      "Epoch 89/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0652 - val_loss: 1.0673\n",
      "Epoch 90/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0636 - val_loss: 1.0659\n",
      "Epoch 91/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0620 - val_loss: 1.0645\n",
      "Epoch 92/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0600 - val_loss: 1.0631\n",
      "Epoch 93/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0583 - val_loss: 1.0618\n",
      "Epoch 94/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0552 - val_loss: 1.0605\n",
      "Epoch 95/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0553 - val_loss: 1.0592\n",
      "Epoch 96/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0521 - val_loss: 1.0580\n",
      "Epoch 97/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0512 - val_loss: 1.0568\n",
      "Epoch 98/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0497 - val_loss: 1.0557\n",
      "Epoch 99/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0482 - val_loss: 1.0546\n",
      "Epoch 100/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0463 - val_loss: 1.0535\n",
      "Epoch 101/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0464 - val_loss: 1.0524\n",
      "Epoch 102/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0445 - val_loss: 1.0513\n",
      "Epoch 103/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0437 - val_loss: 1.0503\n",
      "Epoch 104/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0421 - val_loss: 1.0492\n",
      "Epoch 105/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0404 - val_loss: 1.0483\n",
      "Epoch 106/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0393 - val_loss: 1.0473\n",
      "Epoch 107/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0373 - val_loss: 1.0464\n",
      "Epoch 108/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0370 - val_loss: 1.0455\n",
      "Epoch 109/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0349 - val_loss: 1.0446\n",
      "Epoch 110/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0338 - val_loss: 1.0438\n",
      "Epoch 111/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0343 - val_loss: 1.0429\n",
      "Epoch 112/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0326 - val_loss: 1.0421\n",
      "Epoch 113/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0318 - val_loss: 1.0413\n",
      "Epoch 114/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0308 - val_loss: 1.0405\n",
      "Epoch 115/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0298 - val_loss: 1.0398\n",
      "Epoch 116/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0290 - val_loss: 1.0390\n",
      "Epoch 117/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0283 - val_loss: 1.0383\n",
      "Epoch 118/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0273 - val_loss: 1.0376\n",
      "Epoch 119/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0265 - val_loss: 1.0369\n",
      "Epoch 120/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0259 - val_loss: 1.0362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0248 - val_loss: 1.0355\n",
      "Epoch 122/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0238 - val_loss: 1.0349\n",
      "Epoch 123/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0232 - val_loss: 1.0342\n",
      "Epoch 124/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0226 - val_loss: 1.0336\n",
      "Epoch 125/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0218 - val_loss: 1.0330\n",
      "Epoch 126/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0214 - val_loss: 1.0324\n",
      "Epoch 127/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0205 - val_loss: 1.0319\n",
      "Epoch 128/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0197 - val_loss: 1.0313\n",
      "Epoch 129/150\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0194 - val_loss: 1.0308\n",
      "Epoch 130/150\n",
      "59/59 [==============================] - 0s 7ms/step - loss: 1.0188 - val_loss: 1.0303\n",
      "Epoch 131/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0181 - val_loss: 1.0297\n",
      "Epoch 132/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0172 - val_loss: 1.0292\n",
      "Epoch 133/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0171 - val_loss: 1.0288\n",
      "Epoch 134/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0166 - val_loss: 1.0283\n",
      "Epoch 135/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0158 - val_loss: 1.0278\n",
      "Epoch 136/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0154 - val_loss: 1.0274\n",
      "Epoch 137/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0148 - val_loss: 1.0269\n",
      "Epoch 138/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0141 - val_loss: 1.0265\n",
      "Epoch 139/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0140 - val_loss: 1.0261\n",
      "Epoch 140/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0134 - val_loss: 1.0257\n",
      "Epoch 141/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0131 - val_loss: 1.0253\n",
      "Epoch 142/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0126 - val_loss: 1.0249\n",
      "Epoch 143/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0122 - val_loss: 1.0245\n",
      "Epoch 144/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0117 - val_loss: 1.0241\n",
      "Epoch 145/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0112 - val_loss: 1.0238\n",
      "Epoch 146/150\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0111 - val_loss: 1.0234\n",
      "Epoch 147/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0105 - val_loss: 1.0231\n",
      "Epoch 148/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0103 - val_loss: 1.0228\n",
      "Epoch 149/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0098 - val_loss: 1.0224\n",
      "Epoch 150/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0094 - val_loss: 1.0221\n",
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 166)]             0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 166)               27722     \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 3320)              554440    \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_13 (TFOpLam (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_13 (TFOpLambda)  (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_13 (TFOpL (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_13 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_13 (TFO ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_13 (AddLoss)        ()                        0         \n",
      "=================================================================\n",
      "Total params: 582,162\n",
      "Trainable params: 582,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 30.6156 - val_loss: 16.1986\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 12.0762 - val_loss: 9.7460\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 8.5052 - val_loss: 7.9555\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 7.1441 - val_loss: 6.9642\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 6.4405 - val_loss: 6.4134\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 6.1084 - val_loss: 6.1301\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.9188 - val_loss: 6.0749\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.7974 - val_loss: 5.8051\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 5.6379 - val_loss: 5.6378\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 5.5195 - val_loss: 5.6281\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 5.4932 - val_loss: 5.5845\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.4397 - val_loss: 5.4733\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 5.3740 - val_loss: 5.4177\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 5.3314 - val_loss: 5.3711\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.2931 - val_loss: 5.3516\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.2650 - val_loss: 5.3032\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.2451 - val_loss: 5.3012\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.2336 - val_loss: 5.2821\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 5.2141 - val_loss: 5.2464\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 5.2036 - val_loss: 5.2530\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 5.1930 - val_loss: 5.2250\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 5.1786 - val_loss: 5.2180\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 5.1729 - val_loss: 5.2020\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 5.1669 - val_loss: 5.2040\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 5.1614 - val_loss: 5.1895\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1565 - val_loss: 5.1915\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1536 - val_loss: 5.1784\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.1503 - val_loss: 5.1739\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.1475 - val_loss: 5.1717\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1452 - val_loss: 5.1692\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.1432 - val_loss: 5.1618\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1414 - val_loss: 5.1591\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1399 - val_loss: 5.1569\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1388 - val_loss: 5.1555\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1375 - val_loss: 5.1544\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1366 - val_loss: 5.1511\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1359 - val_loss: 5.1492\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1351 - val_loss: 5.1481\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.1344 - val_loss: 5.1472\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1339 - val_loss: 5.1460\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1335 - val_loss: 5.1455\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1331 - val_loss: 5.1443\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1327 - val_loss: 5.1431\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1324 - val_loss: 5.1427\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1321 - val_loss: 5.1420\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1319 - val_loss: 5.1407\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.1316 - val_loss: 5.1405\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.1314 - val_loss: 5.1399\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1313 - val_loss: 5.1392\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1311 - val_loss: 5.1389\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1310 - val_loss: 5.1385\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1309 - val_loss: 5.1378\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1307 - val_loss: 5.1379\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1306 - val_loss: 5.1372\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1306 - val_loss: 5.1369\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1305 - val_loss: 5.1370\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1304 - val_loss: 5.1362\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1303 - val_loss: 5.1364\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1303 - val_loss: 5.1359\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1302 - val_loss: 5.1357\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1302 - val_loss: 5.1356\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1302 - val_loss: 5.1354\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1301 - val_loss: 5.1352\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1301 - val_loss: 5.1351\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1301 - val_loss: 5.1348\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1300 - val_loss: 5.1347\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1300 - val_loss: 5.1345\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1300 - val_loss: 5.1345\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1300 - val_loss: 5.1344\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1299 - val_loss: 5.1343\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1299 - val_loss: 5.1342\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1299 - val_loss: 5.1342\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1299 - val_loss: 5.1341\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 5.1299 - val_loss: 5.1340\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.1299 - val_loss: 5.1339\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1299 - val_loss: 5.1339\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1299 - val_loss: 5.1337\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1299 - val_loss: 5.1337\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1299 - val_loss: 5.1336\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1298 - val_loss: 5.1337\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1298 - val_loss: 5.1336\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1298 - val_loss: 5.1336\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1298 - val_loss: 5.1334\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1298 - val_loss: 5.1335\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1298 - val_loss: 5.1334\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1298 - val_loss: 5.1333\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1298 - val_loss: 5.1334\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1298 - val_loss: 5.1333\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.1298 - val_loss: 5.1333\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1298 - val_loss: 5.1333\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1298 - val_loss: 5.1332\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1298 - val_loss: 5.1332\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1298 - val_loss: 5.1331\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1298 - val_loss: 5.1331\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1298 - val_loss: 5.1331\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1298 - val_loss: 5.1331\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1298 - val_loss: 5.1331\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1298 - val_loss: 5.1331\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.1298 - val_loss: 5.1331\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1298 - val_loss: 5.1330\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_77 (Dense)             (None, 166)               27722     \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 166)               0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 166)               27722     \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 166)               0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 2)                 334       \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 166)               498       \n",
      "=================================================================\n",
      "Total params: 64,790\n",
      "Trainable params: 64,790\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 1s 5ms/step - loss: 8.7055 - val_loss: 6.0875\n",
      "Epoch 2/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 5.0959 - val_loss: 4.2030\n",
      "Epoch 3/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 3.8176 - val_loss: 3.2717\n",
      "Epoch 4/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 3.1504 - val_loss: 2.7752\n",
      "Epoch 5/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.7688 - val_loss: 2.4745\n",
      "Epoch 6/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.5317 - val_loss: 2.2646\n",
      "Epoch 7/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.3657 - val_loss: 2.1109\n",
      "Epoch 8/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.2376 - val_loss: 1.9902\n",
      "Epoch 9/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.1376 - val_loss: 1.8983\n",
      "Epoch 10/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.0218 - val_loss: 1.8211\n",
      "Epoch 11/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.9554 - val_loss: 1.7580\n",
      "Epoch 12/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.9109 - val_loss: 1.7040\n",
      "Epoch 13/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.8725 - val_loss: 1.6544\n",
      "Epoch 14/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.7697 - val_loss: 1.6154\n",
      "Epoch 15/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.7572 - val_loss: 1.5782\n",
      "Epoch 16/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.7132 - val_loss: 1.5441\n",
      "Epoch 17/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.6770 - val_loss: 1.5144\n",
      "Epoch 18/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.6551 - val_loss: 1.4872\n",
      "Epoch 19/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.6142 - val_loss: 1.4646\n",
      "Epoch 20/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.5910 - val_loss: 1.4413\n",
      "Epoch 21/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.5611 - val_loss: 1.4203\n",
      "Epoch 22/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.5461 - val_loss: 1.4021\n",
      "Epoch 23/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.5087 - val_loss: 1.3838\n",
      "Epoch 24/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.5008 - val_loss: 1.3669\n",
      "Epoch 25/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.4580 - val_loss: 1.3522\n",
      "Epoch 26/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.4766 - val_loss: 1.3384\n",
      "Epoch 27/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.4305 - val_loss: 1.3241\n",
      "Epoch 28/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.4278 - val_loss: 1.3119\n",
      "Epoch 29/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.4150 - val_loss: 1.3015\n",
      "Epoch 30/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3913 - val_loss: 1.2886\n",
      "Epoch 31/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3960 - val_loss: 1.2786\n",
      "Epoch 32/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3663 - val_loss: 1.2682\n",
      "Epoch 33/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3537 - val_loss: 1.2586\n",
      "Epoch 34/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3346 - val_loss: 1.2497\n",
      "Epoch 35/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3291 - val_loss: 1.2419\n",
      "Epoch 36/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3344 - val_loss: 1.2328\n",
      "Epoch 37/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3111 - val_loss: 1.2255\n",
      "Epoch 38/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2964 - val_loss: 1.2180\n",
      "Epoch 39/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.2929 - val_loss: 1.2107\n",
      "Epoch 40/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.2804 - val_loss: 1.2043\n",
      "Epoch 41/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.2690 - val_loss: 1.1977\n",
      "Epoch 42/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2634 - val_loss: 1.1914\n",
      "Epoch 43/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2561 - val_loss: 1.1857\n",
      "Epoch 44/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2431 - val_loss: 1.1798\n",
      "Epoch 45/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2378 - val_loss: 1.1745\n",
      "Epoch 46/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2339 - val_loss: 1.1694\n",
      "Epoch 47/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2244 - val_loss: 1.1642\n",
      "Epoch 48/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.2193 - val_loss: 1.1593\n",
      "Epoch 49/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.2081 - val_loss: 1.1547\n",
      "Epoch 50/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.2087 - val_loss: 1.1501\n",
      "Epoch 51/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2044 - val_loss: 1.1456\n",
      "Epoch 52/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2048 - val_loss: 1.1413\n",
      "Epoch 53/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1879 - val_loss: 1.1373\n",
      "Epoch 54/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1779 - val_loss: 1.1335\n",
      "Epoch 55/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1811 - val_loss: 1.1297\n",
      "Epoch 56/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1755 - val_loss: 1.1260\n",
      "Epoch 57/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1655 - val_loss: 1.1225\n",
      "Epoch 58/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1630 - val_loss: 1.1191\n",
      "Epoch 59/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1549 - val_loss: 1.1158\n",
      "Epoch 60/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1552 - val_loss: 1.1126\n",
      "Epoch 61/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1474 - val_loss: 1.1095\n",
      "Epoch 62/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1461 - val_loss: 1.1065\n",
      "Epoch 63/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1436 - val_loss: 1.1035\n",
      "Epoch 64/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1418 - val_loss: 1.1005\n",
      "Epoch 65/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1294 - val_loss: 1.0978\n",
      "Epoch 66/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1314 - val_loss: 1.0950\n",
      "Epoch 67/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1252 - val_loss: 1.0924\n",
      "Epoch 68/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1226 - val_loss: 1.0899\n",
      "Epoch 69/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1185 - val_loss: 1.0874\n",
      "Epoch 70/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1156 - val_loss: 1.0850\n",
      "Epoch 71/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1098 - val_loss: 1.0827\n",
      "Epoch 72/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1087 - val_loss: 1.0805\n",
      "Epoch 73/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1052 - val_loss: 1.0782\n",
      "Epoch 74/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1026 - val_loss: 1.0761\n",
      "Epoch 75/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0986 - val_loss: 1.0740\n",
      "Epoch 76/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0989 - val_loss: 1.0719\n",
      "Epoch 77/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0950 - val_loss: 1.0699\n",
      "Epoch 78/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0915 - val_loss: 1.0680\n",
      "Epoch 79/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0877 - val_loss: 1.0661\n",
      "Epoch 80/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0888 - val_loss: 1.0643\n",
      "Epoch 81/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0874 - val_loss: 1.0624\n",
      "Epoch 82/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0832 - val_loss: 1.0605\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0809 - val_loss: 1.0588\n",
      "Epoch 84/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0762 - val_loss: 1.0572\n",
      "Epoch 85/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0759 - val_loss: 1.0556\n",
      "Epoch 86/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0722 - val_loss: 1.0540\n",
      "Epoch 87/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0721 - val_loss: 1.0525\n",
      "Epoch 88/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0704 - val_loss: 1.0509\n",
      "Epoch 89/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0658 - val_loss: 1.0495\n",
      "Epoch 90/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0661 - val_loss: 1.0480\n",
      "Epoch 91/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0629 - val_loss: 1.0467\n",
      "Epoch 92/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0615 - val_loss: 1.0453\n",
      "Epoch 93/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0597 - val_loss: 1.0440\n",
      "Epoch 94/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0587 - val_loss: 1.0427\n",
      "Epoch 95/150\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0563 - val_loss: 1.0414\n",
      "Epoch 96/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0557 - val_loss: 1.0402\n",
      "Epoch 97/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0535 - val_loss: 1.0390\n",
      "Epoch 98/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0513 - val_loss: 1.0379\n",
      "Epoch 99/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0507 - val_loss: 1.0367\n",
      "Epoch 100/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0486 - val_loss: 1.0356\n",
      "Epoch 101/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0479 - val_loss: 1.0346\n",
      "Epoch 102/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0459 - val_loss: 1.0335\n",
      "Epoch 103/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0459 - val_loss: 1.0325\n",
      "Epoch 104/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0445 - val_loss: 1.0314\n",
      "Epoch 105/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0425 - val_loss: 1.0304\n",
      "Epoch 106/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0407 - val_loss: 1.0295\n",
      "Epoch 107/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0406 - val_loss: 1.0286\n",
      "Epoch 108/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0394 - val_loss: 1.0276\n",
      "Epoch 109/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0379 - val_loss: 1.0268\n",
      "Epoch 110/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0369 - val_loss: 1.0259\n",
      "Epoch 111/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0356 - val_loss: 1.0250\n",
      "Epoch 112/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0343 - val_loss: 1.0242\n",
      "Epoch 113/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0342 - val_loss: 1.0234\n",
      "Epoch 114/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0340 - val_loss: 1.0226\n",
      "Epoch 115/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0324 - val_loss: 1.0218\n",
      "Epoch 116/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0309 - val_loss: 1.0211\n",
      "Epoch 117/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0303 - val_loss: 1.0204\n",
      "Epoch 118/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0295 - val_loss: 1.0196\n",
      "Epoch 119/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0288 - val_loss: 1.0189\n",
      "Epoch 120/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0279 - val_loss: 1.0182\n",
      "Epoch 121/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0265 - val_loss: 1.0176\n",
      "Epoch 122/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0260 - val_loss: 1.0169\n",
      "Epoch 123/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0251 - val_loss: 1.0163\n",
      "Epoch 124/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0242 - val_loss: 1.0157\n",
      "Epoch 125/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0242 - val_loss: 1.0151\n",
      "Epoch 126/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.0145\n",
      "Epoch 127/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0225 - val_loss: 1.0140\n",
      "Epoch 128/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0223 - val_loss: 1.0134\n",
      "Epoch 129/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0213 - val_loss: 1.0129\n",
      "Epoch 130/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0209 - val_loss: 1.0123\n",
      "Epoch 131/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0203 - val_loss: 1.0118\n",
      "Epoch 132/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0196 - val_loss: 1.0113\n",
      "Epoch 133/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0192 - val_loss: 1.0108\n",
      "Epoch 134/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0185 - val_loss: 1.0103\n",
      "Epoch 135/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0182 - val_loss: 1.0099\n",
      "Epoch 136/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0174 - val_loss: 1.0094\n",
      "Epoch 137/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0169 - val_loss: 1.0090\n",
      "Epoch 138/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0166 - val_loss: 1.0085\n",
      "Epoch 139/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0158 - val_loss: 1.0081\n",
      "Epoch 140/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0156 - val_loss: 1.0077\n",
      "Epoch 141/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0151 - val_loss: 1.0073\n",
      "Epoch 142/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0147 - val_loss: 1.0069\n",
      "Epoch 143/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0143 - val_loss: 1.0065\n",
      "Epoch 144/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0139 - val_loss: 1.0062\n",
      "Epoch 145/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0134 - val_loss: 1.0058\n",
      "Epoch 146/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0131 - val_loss: 1.0054\n",
      "Epoch 147/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0126 - val_loss: 1.0051\n",
      "Epoch 148/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0123 - val_loss: 1.0048\n",
      "Epoch 149/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0120 - val_loss: 1.0044\n",
      "Epoch 150/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0116 - val_loss: 1.0041\n",
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 166)]             0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 166)               27722     \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 3320)              554440    \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_15 (TFOpLam (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_15 (TFOpLambda)  (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_15 (TFOpL (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_15 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_15 (TFO ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_15 (AddLoss)        ()                        0         \n",
      "=================================================================\n",
      "Total params: 582,162\n",
      "Trainable params: 582,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 10ms/step - loss: 29.4793 - val_loss: 15.0730\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 11.4308 - val_loss: 9.2312\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 8.2346 - val_loss: 7.4120\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 6.9595 - val_loss: 6.6882\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 6.3901 - val_loss: 6.2685\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 6.0487 - val_loss: 6.0557\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.9635 - val_loss: 6.0761\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.7658 - val_loss: 5.7392\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.6490 - val_loss: 5.6424\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.5342 - val_loss: 5.5311\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.4490 - val_loss: 5.4690\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.4033 - val_loss: 5.4481\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.3554 - val_loss: 5.3736\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.3404 - val_loss: 5.3410\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.2933 - val_loss: 5.3223\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.2628 - val_loss: 5.2847\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.2449 - val_loss: 5.3034\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.2452 - val_loss: 5.2881\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.2224 - val_loss: 5.2379\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.2107 - val_loss: 5.2238\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 5.1912 - val_loss: 5.2026\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1803 - val_loss: 5.1927\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1738 - val_loss: 5.1871\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 5.1681 - val_loss: 5.1838\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 5.1639 - val_loss: 5.1770\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 5.1609 - val_loss: 5.1770\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 5.1573 - val_loss: 5.1714\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1543 - val_loss: 5.1662\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1523 - val_loss: 5.1644\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 5.1502 - val_loss: 5.1616\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 5.1486 - val_loss: 5.1605\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 5.1471 - val_loss: 5.1575\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 5.1458 - val_loss: 5.1566\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 5.1448 - val_loss: 5.1546\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 5.1437 - val_loss: 5.1527\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 5.1429 - val_loss: 5.1519\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 5.1421 - val_loss: 5.1504\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 5.1414 - val_loss: 5.1491\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 5.1409 - val_loss: 5.1480\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1404 - val_loss: 5.1474\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1399 - val_loss: 5.1465\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1396 - val_loss: 5.1462\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1393 - val_loss: 5.1457\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1390 - val_loss: 5.1448\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1387 - val_loss: 5.1447\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1385 - val_loss: 5.1439\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1383 - val_loss: 5.1436\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1381 - val_loss: 5.1432\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1379 - val_loss: 5.1429\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1378 - val_loss: 5.1424\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1377 - val_loss: 5.1423\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1375 - val_loss: 5.1419\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1374 - val_loss: 5.1419\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1373 - val_loss: 5.1414\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1373 - val_loss: 5.1414\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1372 - val_loss: 5.1410\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1371 - val_loss: 5.1409\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1371 - val_loss: 5.1408\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 5.1370 - val_loss: 5.1406\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 5.1370 - val_loss: 5.1404\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1369 - val_loss: 5.1403\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1369 - val_loss: 5.1404\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1368 - val_loss: 5.1400\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1368 - val_loss: 5.1400\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1368 - val_loss: 5.1401\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1368 - val_loss: 5.1398\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1367 - val_loss: 5.1398\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1367 - val_loss: 5.1396\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1367 - val_loss: 5.1397\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1367 - val_loss: 5.1395\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1367 - val_loss: 5.1394\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 5.1366 - val_loss: 5.1393\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 5.1366 - val_loss: 5.1393\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 5.1366 - val_loss: 5.1392\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1366 - val_loss: 5.1392\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1366 - val_loss: 5.1391\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1366 - val_loss: 5.1392\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 5.1366 - val_loss: 5.1391\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 5.1366 - val_loss: 5.1390\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1366 - val_loss: 5.1389\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1366 - val_loss: 5.1389\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 5.1366 - val_loss: 5.1389\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1366 - val_loss: 5.1388\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1366 - val_loss: 5.1388\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1366 - val_loss: 5.1387\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 5.1365 - val_loss: 5.1388\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1365 - val_loss: 5.1388\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1365 - val_loss: 5.1387\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 5.1365 - val_loss: 5.1387\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 5.1365 - val_loss: 5.1386\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1365 - val_loss: 5.1386\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1365 - val_loss: 5.1386\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1365 - val_loss: 5.1386\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1365 - val_loss: 5.1386\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1365 - val_loss: 5.1386\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 5.1365 - val_loss: 5.1386\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1365 - val_loss: 5.1386\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1365 - val_loss: 5.1385\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1365 - val_loss: 5.1385\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1365 - val_loss: 5.1385\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_88 (Dense)             (None, 166)               27722     \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 166)               0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 166)               27722     \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 166)               0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 2)                 334       \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 166)               498       \n",
      "=================================================================\n",
      "Total params: 64,790\n",
      "Trainable params: 64,790\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "59/59 [==============================] - 1s 8ms/step - loss: 8.7178 - val_loss: 6.0143\n",
      "Epoch 2/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 5.0579 - val_loss: 4.1580\n",
      "Epoch 3/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 3.7928 - val_loss: 3.2676\n",
      "Epoch 4/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 3.1617 - val_loss: 2.7910\n",
      "Epoch 5/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.7828 - val_loss: 2.4834\n",
      "Epoch 6/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.5423 - val_loss: 2.2786\n",
      "Epoch 7/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.3615 - val_loss: 2.1246\n",
      "Epoch 8/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.2226 - val_loss: 2.0117\n",
      "Epoch 9/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.1205 - val_loss: 1.9201\n",
      "Epoch 10/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.0338 - val_loss: 1.8397\n",
      "Epoch 11/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.9768 - val_loss: 1.7784\n",
      "Epoch 12/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.8936 - val_loss: 1.7213\n",
      "Epoch 13/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.8562 - val_loss: 1.6729\n",
      "Epoch 14/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.8152 - val_loss: 1.6299\n",
      "Epoch 15/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.7646 - val_loss: 1.5948\n",
      "Epoch 16/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.6948 - val_loss: 1.5603\n",
      "Epoch 17/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.6773 - val_loss: 1.5297\n",
      "Epoch 18/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.6477 - val_loss: 1.5024\n",
      "Epoch 19/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.6294 - val_loss: 1.4779\n",
      "Epoch 20/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.5655 - val_loss: 1.4571\n",
      "Epoch 21/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.5794 - val_loss: 1.4358\n",
      "Epoch 22/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.5377 - val_loss: 1.4165\n",
      "Epoch 23/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.5153 - val_loss: 1.3982\n",
      "Epoch 24/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.4874 - val_loss: 1.3824\n",
      "Epoch 25/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.4647 - val_loss: 1.3674\n",
      "Epoch 26/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.4613 - val_loss: 1.3519\n",
      "Epoch 27/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.4380 - val_loss: 1.3389\n",
      "Epoch 28/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.4398 - val_loss: 1.3255\n",
      "Epoch 29/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.4014 - val_loss: 1.3138\n",
      "Epoch 30/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.3973 - val_loss: 1.3023\n",
      "Epoch 31/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.3777 - val_loss: 1.2922\n",
      "Epoch 32/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3718 - val_loss: 1.2821\n",
      "Epoch 33/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3547 - val_loss: 1.2720\n",
      "Epoch 34/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3427 - val_loss: 1.2634\n",
      "Epoch 35/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3341 - val_loss: 1.2543\n",
      "Epoch 36/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3282 - val_loss: 1.2465\n",
      "Epoch 37/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3184 - val_loss: 1.2382\n",
      "Epoch 38/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2927 - val_loss: 1.2306\n",
      "Epoch 39/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2856 - val_loss: 1.2238\n",
      "Epoch 40/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2807 - val_loss: 1.2169\n",
      "Epoch 41/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.2726 - val_loss: 1.2105\n",
      "Epoch 42/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2525 - val_loss: 1.2043\n",
      "Epoch 43/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2496 - val_loss: 1.1990\n",
      "Epoch 44/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.2489 - val_loss: 1.1928\n",
      "Epoch 45/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2434 - val_loss: 1.1875\n",
      "Epoch 46/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2302 - val_loss: 1.1820\n",
      "Epoch 47/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2225 - val_loss: 1.1770\n",
      "Epoch 48/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2253 - val_loss: 1.1719\n",
      "Epoch 49/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2058 - val_loss: 1.1671\n",
      "Epoch 50/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2123 - val_loss: 1.1624\n",
      "Epoch 51/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1983 - val_loss: 1.1580\n",
      "Epoch 52/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1852 - val_loss: 1.1540\n",
      "Epoch 53/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1899 - val_loss: 1.1499\n",
      "Epoch 54/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1791 - val_loss: 1.1461\n",
      "Epoch 55/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1789 - val_loss: 1.1423\n",
      "Epoch 56/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1691 - val_loss: 1.1386\n",
      "Epoch 57/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1652 - val_loss: 1.1351\n",
      "Epoch 58/150\n",
      "59/59 [==============================] - ETA: 0s - loss: 1.157 - 0s 3ms/step - loss: 1.1581 - val_loss: 1.1317\n",
      "Epoch 59/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1568 - val_loss: 1.1284\n",
      "Epoch 60/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1534 - val_loss: 1.1251\n",
      "Epoch 61/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1461 - val_loss: 1.1220\n",
      "Epoch 62/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1411 - val_loss: 1.1190\n",
      "Epoch 63/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1395 - val_loss: 1.1161\n",
      "Epoch 64/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.1389 - val_loss: 1.1131\n",
      "Epoch 65/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1279 - val_loss: 1.1104\n",
      "Epoch 66/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1283 - val_loss: 1.1076\n",
      "Epoch 67/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1255 - val_loss: 1.1049\n",
      "Epoch 68/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1202 - val_loss: 1.1024\n",
      "Epoch 69/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.1147 - val_loss: 1.0999\n",
      "Epoch 70/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.1108 - val_loss: 1.0976\n",
      "Epoch 71/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1112 - val_loss: 1.0952\n",
      "Epoch 72/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1052 - val_loss: 1.0929\n",
      "Epoch 73/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1063 - val_loss: 1.0906\n",
      "Epoch 74/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1024 - val_loss: 1.0885\n",
      "Epoch 75/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0983 - val_loss: 1.0863\n",
      "Epoch 76/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0954 - val_loss: 1.0843\n",
      "Epoch 77/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0913 - val_loss: 1.0823\n",
      "Epoch 78/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0919 - val_loss: 1.0803\n",
      "Epoch 79/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0853 - val_loss: 1.0785\n",
      "Epoch 80/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0849 - val_loss: 1.0766\n",
      "Epoch 81/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0868 - val_loss: 1.0747\n",
      "Epoch 82/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0807 - val_loss: 1.0730\n",
      "Epoch 83/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0812 - val_loss: 1.0711\n",
      "Epoch 84/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0738 - val_loss: 1.0695\n",
      "Epoch 85/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0732 - val_loss: 1.0679\n",
      "Epoch 86/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0720 - val_loss: 1.0663\n",
      "Epoch 87/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0695 - val_loss: 1.0648\n",
      "Epoch 88/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0672 - val_loss: 1.0632\n",
      "Epoch 89/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0662 - val_loss: 1.0617\n",
      "Epoch 90/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0640 - val_loss: 1.0603\n",
      "Epoch 91/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0616 - val_loss: 1.0589\n",
      "Epoch 92/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0602 - val_loss: 1.0575\n",
      "Epoch 93/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0590 - val_loss: 1.0562\n",
      "Epoch 94/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0582 - val_loss: 1.0549\n",
      "Epoch 95/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0559 - val_loss: 1.0536\n",
      "Epoch 96/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0538 - val_loss: 1.0523\n",
      "Epoch 97/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0523 - val_loss: 1.0511\n",
      "Epoch 98/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0511 - val_loss: 1.0499\n",
      "Epoch 99/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0497 - val_loss: 1.0488\n",
      "Epoch 100/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0480 - val_loss: 1.0477\n",
      "Epoch 101/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0479 - val_loss: 1.0465\n",
      "Epoch 102/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0461 - val_loss: 1.0454\n",
      "Epoch 103/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0444 - val_loss: 1.0444\n",
      "Epoch 104/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0428 - val_loss: 1.0433\n",
      "Epoch 105/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0412 - val_loss: 1.0423\n",
      "Epoch 106/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0397 - val_loss: 1.0414\n",
      "Epoch 107/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0390 - val_loss: 1.0404\n",
      "Epoch 108/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0375 - val_loss: 1.0395\n",
      "Epoch 109/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0362 - val_loss: 1.0386\n",
      "Epoch 110/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0357 - val_loss: 1.0377\n",
      "Epoch 111/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0344 - val_loss: 1.0369\n",
      "Epoch 112/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0332 - val_loss: 1.0361\n",
      "Epoch 113/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0327 - val_loss: 1.0352\n",
      "Epoch 114/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0314 - val_loss: 1.0345\n",
      "Epoch 115/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0306 - val_loss: 1.0337\n",
      "Epoch 116/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0296 - val_loss: 1.0329\n",
      "Epoch 117/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0289 - val_loss: 1.0322\n",
      "Epoch 118/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0280 - val_loss: 1.0315\n",
      "Epoch 119/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0269 - val_loss: 1.0308\n",
      "Epoch 120/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0258 - val_loss: 1.0301\n",
      "Epoch 121/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0255 - val_loss: 1.0294\n",
      "Epoch 122/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0247 - val_loss: 1.0288\n",
      "Epoch 123/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0239 - val_loss: 1.0282\n",
      "Epoch 124/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0232 - val_loss: 1.0275\n",
      "Epoch 125/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0228 - val_loss: 1.0269\n",
      "Epoch 126/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0219 - val_loss: 1.0263\n",
      "Epoch 127/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0212 - val_loss: 1.0258\n",
      "Epoch 128/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0207 - val_loss: 1.0252\n",
      "Epoch 129/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0198 - val_loss: 1.0247\n",
      "Epoch 130/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0194 - val_loss: 1.0241\n",
      "Epoch 131/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0188 - val_loss: 1.0236\n",
      "Epoch 132/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0181 - val_loss: 1.0231\n",
      "Epoch 133/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0175 - val_loss: 1.0226\n",
      "Epoch 134/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0172 - val_loss: 1.0221\n",
      "Epoch 135/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0167 - val_loss: 1.0216\n",
      "Epoch 136/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0160 - val_loss: 1.0212\n",
      "Epoch 137/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0156 - val_loss: 1.0207\n",
      "Epoch 138/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0151 - val_loss: 1.0203\n",
      "Epoch 139/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0146 - val_loss: 1.0199\n",
      "Epoch 140/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0142 - val_loss: 1.0195\n",
      "Epoch 141/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0135 - val_loss: 1.0191\n",
      "Epoch 142/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0132 - val_loss: 1.0187\n",
      "Epoch 143/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0129 - val_loss: 1.0183\n",
      "Epoch 144/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0124 - val_loss: 1.0179\n",
      "Epoch 145/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0120 - val_loss: 1.0175\n",
      "Epoch 146/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0115 - val_loss: 1.0172\n",
      "Epoch 147/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0113 - val_loss: 1.0169\n",
      "Epoch 148/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0109 - val_loss: 1.0165\n",
      "Epoch 149/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0107 - val_loss: 1.0162\n",
      "Epoch 150/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0102 - val_loss: 1.0159\n",
      "Model: \"model_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        [(None, 166)]             0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 166)               27722     \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 3320)              554440    \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_17 (TFOpLam (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_17 (TFOpLambda)  (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_17 (TFOpL (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_17 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_17 (TFO ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_17 (AddLoss)        ()                        0         \n",
      "=================================================================\n",
      "Total params: 582,162\n",
      "Trainable params: 582,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 30.7946 - val_loss: 15.9086\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 12.3409 - val_loss: 9.7306\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 8.6645 - val_loss: 7.8637\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 7.3187 - val_loss: 7.8950\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 6.8568 - val_loss: 6.4940\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 6.1483 - val_loss: 6.2282\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 6.0137 - val_loss: 5.9495\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.7409 - val_loss: 5.7247\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.5949 - val_loss: 5.6095\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.5904 - val_loss: 5.5556\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.4845 - val_loss: 5.4957\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 5.4128 - val_loss: 5.4420\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 5.3711 - val_loss: 5.4113\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 5.3266 - val_loss: 5.3672\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.3054 - val_loss: 5.3243\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.3016 - val_loss: 5.3271\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 5.3022 - val_loss: 5.2936\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 5.2563 - val_loss: 5.2734\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 5.2265 - val_loss: 5.2436\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 5.2054 - val_loss: 5.2223\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 5.1879 - val_loss: 5.2016\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 5.1797 - val_loss: 5.2057\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 5.1735 - val_loss: 5.1967\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1786 - val_loss: 5.1864\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1659 - val_loss: 5.1862\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 5.1724 - val_loss: 5.1740\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 5.1515 - val_loss: 5.1613\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 5.1417 - val_loss: 5.1588\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 5.1404 - val_loss: 5.1544\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 5.1360 - val_loss: 5.1512\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 5.1349 - val_loss: 5.1486\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 5.1336 - val_loss: 5.1443\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 5.1324 - val_loss: 5.1457\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1302 - val_loss: 5.1428\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 5.1287 - val_loss: 5.1412\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1277 - val_loss: 5.1395\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 5.1269 - val_loss: 5.1385\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 5.1261 - val_loss: 5.1371\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 5.1256 - val_loss: 5.1360\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1249 - val_loss: 5.1349\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1245 - val_loss: 5.1337\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1242 - val_loss: 5.1344\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1238 - val_loss: 5.1326\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 5.1234 - val_loss: 5.1322\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 5.1231 - val_loss: 5.1316\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 5.1229 - val_loss: 5.1317\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 5.1227 - val_loss: 5.1305\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 5.1224 - val_loss: 5.1304\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 5.1222 - val_loss: 5.1298\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 5.1221 - val_loss: 5.1290\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 5.1219 - val_loss: 5.1291\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 5.1218 - val_loss: 5.1286\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 5.1217 - val_loss: 5.1283\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 5.1216 - val_loss: 5.1285\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 5.1215 - val_loss: 5.1277\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 5.1214 - val_loss: 5.1280\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 5.1213 - val_loss: 5.1274\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1213 - val_loss: 5.1275\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 5.1212 - val_loss: 5.1274\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 5.1212 - val_loss: 5.1272\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 5.1211 - val_loss: 5.1269\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 5.1211 - val_loss: 5.1269\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1211 - val_loss: 5.1265\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 5.1210 - val_loss: 5.1267\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1210 - val_loss: 5.1264\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1209 - val_loss: 5.1264\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1209 - val_loss: 5.1260\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1209 - val_loss: 5.1258\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1208 - val_loss: 5.1258\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 5.1208 - val_loss: 5.1256\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1208 - val_loss: 5.1256\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1208 - val_loss: 5.1257\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1208 - val_loss: 5.1257\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 5.1208 - val_loss: 5.1254\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1207 - val_loss: 5.1254\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1207 - val_loss: 5.1252\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 5.1208 - val_loss: 5.1250\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 5.1207 - val_loss: 5.1251\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 5.1207 - val_loss: 5.1250\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1207 - val_loss: 5.1250\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1207 - val_loss: 5.1249\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 5.1207 - val_loss: 5.1250\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1207 - val_loss: 5.1250\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1207 - val_loss: 5.1249\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1207 - val_loss: 5.1249\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1207 - val_loss: 5.1249\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 5.1207 - val_loss: 5.1249\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 5.1207 - val_loss: 5.1249\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 5.1207 - val_loss: 5.1248\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 5.1207 - val_loss: 5.1248\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 5.1207 - val_loss: 5.1248\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 5.1207 - val_loss: 5.1248\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 5.1207 - val_loss: 5.1248\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 5.1207 - val_loss: 5.1247\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 5.1207 - val_loss: 5.1248\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 5.1207 - val_loss: 5.1247\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 5.1207 - val_loss: 5.1247\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 5.1207 - val_loss: 5.1247\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 5.1207 - val_loss: 5.1247\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 5.1207 - val_loss: 5.1246\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_99 (Dense)             (None, 166)               27722     \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 166)               0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 166)               27722     \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 166)               0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 2)                 334       \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 166)               498       \n",
      "=================================================================\n",
      "Total params: 64,790\n",
      "Trainable params: 64,790\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 1s 5ms/step - loss: 8.6921 - val_loss: 6.1373\n",
      "Epoch 2/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 5.0625 - val_loss: 4.2137\n",
      "Epoch 3/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 3.7803 - val_loss: 3.3159\n",
      "Epoch 4/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 3.1279 - val_loss: 2.8274\n",
      "Epoch 5/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 2.7774 - val_loss: 2.5197\n",
      "Epoch 6/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 2.5599 - val_loss: 2.3068\n",
      "Epoch 7/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 2.3596 - val_loss: 2.1549\n",
      "Epoch 8/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 2.1928 - val_loss: 2.0411\n",
      "Epoch 9/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 2.1352 - val_loss: 1.9488\n",
      "Epoch 10/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 2.0371 - val_loss: 1.8716\n",
      "Epoch 11/150\n",
      "59/59 [==============================] - ETA: 0s - loss: 1.958 - 0s 2ms/step - loss: 1.9525 - val_loss: 1.8076\n",
      "Epoch 12/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.8836 - val_loss: 1.7546\n",
      "Epoch 13/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.8474 - val_loss: 1.7037\n",
      "Epoch 14/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.7973 - val_loss: 1.6644\n",
      "Epoch 15/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.7511 - val_loss: 1.6281\n",
      "Epoch 16/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.7017 - val_loss: 1.5946\n",
      "Epoch 17/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.6713 - val_loss: 1.5634\n",
      "Epoch 18/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.6434 - val_loss: 1.5365\n",
      "Epoch 19/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.6194 - val_loss: 1.5120\n",
      "Epoch 20/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.5831 - val_loss: 1.4905\n",
      "Epoch 21/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.5610 - val_loss: 1.4684\n",
      "Epoch 22/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.5339 - val_loss: 1.4509\n",
      "Epoch 23/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.5133 - val_loss: 1.4318\n",
      "Epoch 24/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.4907 - val_loss: 1.4153\n",
      "Epoch 25/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.4569 - val_loss: 1.4004\n",
      "Epoch 26/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.4470 - val_loss: 1.3863\n",
      "Epoch 27/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.4431 - val_loss: 1.3726\n",
      "Epoch 28/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.4186 - val_loss: 1.3602\n",
      "Epoch 29/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.4190 - val_loss: 1.3484\n",
      "Epoch 30/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.3815 - val_loss: 1.3376\n",
      "Epoch 31/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.3800 - val_loss: 1.3267\n",
      "Epoch 32/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.3638 - val_loss: 1.3162\n",
      "Epoch 33/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.3507 - val_loss: 1.3065\n",
      "Epoch 34/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3369 - val_loss: 1.2979\n",
      "Epoch 35/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3297 - val_loss: 1.2897\n",
      "Epoch 36/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3053 - val_loss: 1.2811\n",
      "Epoch 37/150\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3014 - val_loss: 1.2736\n",
      "Epoch 38/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.3009 - val_loss: 1.2656\n",
      "Epoch 39/150\n",
      "59/59 [==============================] - ETA: 0s - loss: 1.286 - 0s 3ms/step - loss: 1.2841 - val_loss: 1.2587\n",
      "Epoch 40/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.2830 - val_loss: 1.2525\n",
      "Epoch 41/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.2636 - val_loss: 1.2454\n",
      "Epoch 42/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.2604 - val_loss: 1.2392\n",
      "Epoch 43/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2438 - val_loss: 1.2332\n",
      "Epoch 44/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2547 - val_loss: 1.2276\n",
      "Epoch 45/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2340 - val_loss: 1.2223\n",
      "Epoch 46/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.2258 - val_loss: 1.2163\n",
      "Epoch 47/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.2201 - val_loss: 1.2115\n",
      "Epoch 48/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.2121 - val_loss: 1.2069\n",
      "Epoch 49/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.2032 - val_loss: 1.2018\n",
      "Epoch 50/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.1962 - val_loss: 1.1973\n",
      "Epoch 51/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1908 - val_loss: 1.1931\n",
      "Epoch 52/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1871 - val_loss: 1.1888\n",
      "Epoch 53/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1884 - val_loss: 1.1847\n",
      "Epoch 54/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1793 - val_loss: 1.1807\n",
      "Epoch 55/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1683 - val_loss: 1.1770\n",
      "Epoch 56/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.1687 - val_loss: 1.1733\n",
      "Epoch 57/150\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1630 - val_loss: 1.1698\n",
      "Epoch 58/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1550 - val_loss: 1.1664\n",
      "Epoch 59/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1474 - val_loss: 1.1631\n",
      "Epoch 60/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1486 - val_loss: 1.1600\n",
      "Epoch 61/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1441 - val_loss: 1.1568\n",
      "Epoch 62/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1372 - val_loss: 1.1539\n",
      "Epoch 63/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1375 - val_loss: 1.1508\n",
      "Epoch 64/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1313 - val_loss: 1.1479\n",
      "Epoch 65/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1263 - val_loss: 1.1452\n",
      "Epoch 66/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.1252 - val_loss: 1.1425\n",
      "Epoch 67/150\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1200 - val_loss: 1.1398\n",
      "Epoch 68/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1185 - val_loss: 1.1372\n",
      "Epoch 69/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.1150 - val_loss: 1.1347\n",
      "Epoch 70/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1075 - val_loss: 1.1323\n",
      "Epoch 71/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1069 - val_loss: 1.1299\n",
      "Epoch 72/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.1075 - val_loss: 1.1275\n",
      "Epoch 73/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0990 - val_loss: 1.1253\n",
      "Epoch 74/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0987 - val_loss: 1.1232\n",
      "Epoch 75/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0949 - val_loss: 1.1210\n",
      "Epoch 76/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0922 - val_loss: 1.1189\n",
      "Epoch 77/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0862 - val_loss: 1.1170\n",
      "Epoch 78/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0892 - val_loss: 1.1150\n",
      "Epoch 79/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0821 - val_loss: 1.1131\n",
      "Epoch 80/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0828 - val_loss: 1.1112\n",
      "Epoch 81/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0820 - val_loss: 1.1094\n",
      "Epoch 82/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0761 - val_loss: 1.1076\n",
      "Epoch 83/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0742 - val_loss: 1.1059\n",
      "Epoch 84/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0711 - val_loss: 1.1042\n",
      "Epoch 85/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0695 - val_loss: 1.1026\n",
      "Epoch 86/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0672 - val_loss: 1.1010\n",
      "Epoch 87/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0643 - val_loss: 1.0995\n",
      "Epoch 88/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0627 - val_loss: 1.0980\n",
      "Epoch 89/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0623 - val_loss: 1.0966\n",
      "Epoch 90/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0599 - val_loss: 1.0951\n",
      "Epoch 91/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0590 - val_loss: 1.0937\n",
      "Epoch 92/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0577 - val_loss: 1.0923\n",
      "Epoch 93/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0569 - val_loss: 1.0910\n",
      "Epoch 94/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0534 - val_loss: 1.0896\n",
      "Epoch 95/150\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0519 - val_loss: 1.0883\n",
      "Epoch 96/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0493 - val_loss: 1.0871\n",
      "Epoch 97/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0489 - val_loss: 1.0859\n",
      "Epoch 98/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0470 - val_loss: 1.0847\n",
      "Epoch 99/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0466 - val_loss: 1.0835\n",
      "Epoch 100/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0435 - val_loss: 1.0824\n",
      "Epoch 101/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0417 - val_loss: 1.0813\n",
      "Epoch 102/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0405 - val_loss: 1.0803\n",
      "Epoch 103/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0396 - val_loss: 1.0793\n",
      "Epoch 104/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0389 - val_loss: 1.0782\n",
      "Epoch 105/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0365 - val_loss: 1.0772\n",
      "Epoch 106/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0362 - val_loss: 1.0763\n",
      "Epoch 107/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0349 - val_loss: 1.0753\n",
      "Epoch 108/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0339 - val_loss: 1.0744\n",
      "Epoch 109/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0330 - val_loss: 1.0735\n",
      "Epoch 110/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0322 - val_loss: 1.0726\n",
      "Epoch 111/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0302 - val_loss: 1.0718\n",
      "Epoch 112/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0296 - val_loss: 1.0709\n",
      "Epoch 113/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0291 - val_loss: 1.0701\n",
      "Epoch 114/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0278 - val_loss: 1.0693\n",
      "Epoch 115/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0262 - val_loss: 1.0685\n",
      "Epoch 116/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0262 - val_loss: 1.0678\n",
      "Epoch 117/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0243 - val_loss: 1.0671\n",
      "Epoch 118/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0237 - val_loss: 1.0663\n",
      "Epoch 119/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0235 - val_loss: 1.0656\n",
      "Epoch 120/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0222 - val_loss: 1.0650\n",
      "Epoch 121/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0216 - val_loss: 1.0643\n",
      "Epoch 122/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0208 - val_loss: 1.0636\n",
      "Epoch 123/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0201 - val_loss: 1.0630\n",
      "Epoch 124/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0194 - val_loss: 1.0624\n",
      "Epoch 125/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0188 - val_loss: 1.0618\n",
      "Epoch 126/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0186 - val_loss: 1.0612\n",
      "Epoch 127/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0171 - val_loss: 1.0606\n",
      "Epoch 128/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0168 - val_loss: 1.0600\n",
      "Epoch 129/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0162 - val_loss: 1.0595\n",
      "Epoch 130/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0153 - val_loss: 1.0589\n",
      "Epoch 131/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0152 - val_loss: 1.0584\n",
      "Epoch 132/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0144 - val_loss: 1.0579\n",
      "Epoch 133/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0139 - val_loss: 1.0574\n",
      "Epoch 134/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0134 - val_loss: 1.0569\n",
      "Epoch 135/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0128 - val_loss: 1.0564\n",
      "Epoch 136/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0123 - val_loss: 1.0560\n",
      "Epoch 137/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0117 - val_loss: 1.0555\n",
      "Epoch 138/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0114 - val_loss: 1.0551\n",
      "Epoch 139/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0109 - val_loss: 1.0546\n",
      "Epoch 140/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0103 - val_loss: 1.0542\n",
      "Epoch 141/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0097 - val_loss: 1.0538\n",
      "Epoch 142/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0095 - val_loss: 1.0534\n",
      "Epoch 143/150\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.0091 - val_loss: 1.0530\n",
      "Epoch 144/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0086 - val_loss: 1.0526\n",
      "Epoch 145/150\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0082 - val_loss: 1.0523\n",
      "Epoch 146/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0078 - val_loss: 1.0519\n",
      "Epoch 147/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0074 - val_loss: 1.0516\n",
      "Epoch 148/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0072 - val_loss: 1.0512\n",
      "Epoch 149/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0067 - val_loss: 1.0509\n",
      "Epoch 150/150\n",
      "59/59 [==============================] - 0s 2ms/step - loss: 1.0064 - val_loss: 1.0506\n",
      "Model: \"model_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        [(None, 166)]             0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 166)               27722     \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 3320)              554440    \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_19 (TFOpLam (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_19 (TFOpLambda)  (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_19 (TFOpL (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_19 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_19 (TFO ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_19 (AddLoss)        ()                        0         \n",
      "=================================================================\n",
      "Total params: 582,162\n",
      "Trainable params: 582,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 8ms/step - loss: 30.6702 - val_loss: 15.9004\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 11.9846 - val_loss: 9.6318\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 8.3294 - val_loss: 7.5117\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 6.9919 - val_loss: 6.6725\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 6.3935 - val_loss: 6.2555\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 6.0427 - val_loss: 5.9612\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.8324 - val_loss: 5.7793\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.6845 - val_loss: 5.6596\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.6229 - val_loss: 5.6493\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.5204 - val_loss: 5.5694\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.4582 - val_loss: 5.4798\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.4811 - val_loss: 5.4623\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.3798 - val_loss: 5.3940\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.3192 - val_loss: 5.3227\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.2794 - val_loss: 5.3066\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.2525 - val_loss: 5.2657\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.2299 - val_loss: 5.2500\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.2183 - val_loss: 5.2318\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.2078 - val_loss: 5.2206\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1972 - val_loss: 5.2100\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 5.1888 - val_loss: 5.1995\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1811 - val_loss: 5.1825\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1678 - val_loss: 5.1800\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.1627 - val_loss: 5.1730\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1583 - val_loss: 5.1707\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1537 - val_loss: 5.1656\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1499 - val_loss: 5.1615\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1472 - val_loss: 5.1584\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1446 - val_loss: 5.1547\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1424 - val_loss: 5.1527\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1407 - val_loss: 5.1509\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1391 - val_loss: 5.1476\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1377 - val_loss: 5.1462\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1367 - val_loss: 5.1437\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1356 - val_loss: 5.1430\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1348 - val_loss: 5.1414\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1340 - val_loss: 5.1402\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1333 - val_loss: 5.1393\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1328 - val_loss: 5.1385\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1323 - val_loss: 5.1375\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1318 - val_loss: 5.1363\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1314 - val_loss: 5.1362\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1311 - val_loss: 5.1351\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1307 - val_loss: 5.1349\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1304 - val_loss: 5.1342\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1302 - val_loss: 5.1338\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1300 - val_loss: 5.1335\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1298 - val_loss: 5.1332\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1296 - val_loss: 5.1329\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1295 - val_loss: 5.1324\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1293 - val_loss: 5.1322\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1292 - val_loss: 5.1320\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1291 - val_loss: 5.1318\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1290 - val_loss: 5.1315\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.1289 - val_loss: 5.1314\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1289 - val_loss: 5.1313\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1288 - val_loss: 5.1310\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1287 - val_loss: 5.1309\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1287 - val_loss: 5.1309\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1286 - val_loss: 5.1307\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1286 - val_loss: 5.1306\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1286 - val_loss: 5.1305\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1285 - val_loss: 5.1304\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1285 - val_loss: 5.1304\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1285 - val_loss: 5.1302\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1284 - val_loss: 5.1303\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1284 - val_loss: 5.1302\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1284 - val_loss: 5.1300\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1284 - val_loss: 5.1301\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1284 - val_loss: 5.1300\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1283 - val_loss: 5.1298\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.1283 - val_loss: 5.1298\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1283 - val_loss: 5.1299\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1283 - val_loss: 5.1297\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1283 - val_loss: 5.1297\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1283 - val_loss: 5.1297\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1283 - val_loss: 5.1297\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 5.1283 - val_loss: 5.1296\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1283 - val_loss: 5.1296\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1283 - val_loss: 5.1296\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.1283 - val_loss: 5.1295\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.1283 - val_loss: 5.1295\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1282 - val_loss: 5.1295\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1282 - val_loss: 5.1295\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1282 - val_loss: 5.1294\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1282 - val_loss: 5.1294\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1282 - val_loss: 5.1294\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1282 - val_loss: 5.1294\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1282 - val_loss: 5.1294\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1282 - val_loss: 5.1294\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1282 - val_loss: 5.1294\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1282 - val_loss: 5.1294\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 5.1282 - val_loss: 5.1294\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1282 - val_loss: 5.1294\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1282 - val_loss: 5.1294\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1282 - val_loss: 5.1293\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1282 - val_loss: 5.1293\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 5.1282 - val_loss: 5.1293\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1282 - val_loss: 5.1293\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 5.1282 - val_loss: 5.1293\n",
      "第 optdigit 個資料處理中....\n",
      "\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_110 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 64)                192       \n",
      "=================================================================\n",
      "Total params: 17,156\n",
      "Trainable params: 17,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "101/101 [==============================] - 1s 3ms/step - loss: 4.8013 - val_loss: 3.0494\n",
      "Epoch 2/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 3.0373 - val_loss: 2.1979\n",
      "Epoch 3/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 2.3762 - val_loss: 1.7936\n",
      "Epoch 4/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 2.0180 - val_loss: 1.5763\n",
      "Epoch 5/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.8041 - val_loss: 1.4470\n",
      "Epoch 6/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.6651 - val_loss: 1.3600\n",
      "Epoch 7/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.5632 - val_loss: 1.2952\n",
      "Epoch 8/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.4940 - val_loss: 1.2471\n",
      "Epoch 9/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.4246 - val_loss: 1.2080\n",
      "Epoch 10/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.3789 - val_loss: 1.1777\n",
      "Epoch 11/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.3364 - val_loss: 1.1511\n",
      "Epoch 12/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2972 - val_loss: 1.1294\n",
      "Epoch 13/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2731 - val_loss: 1.1098\n",
      "Epoch 14/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2506 - val_loss: 1.0933\n",
      "Epoch 15/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2328 - val_loss: 1.0785\n",
      "Epoch 16/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2083 - val_loss: 1.0648\n",
      "Epoch 17/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1964 - val_loss: 1.0530\n",
      "Epoch 18/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.1784 - val_loss: 1.0425\n",
      "Epoch 19/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1680 - val_loss: 1.0328\n",
      "Epoch 20/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.1513 - val_loss: 1.0240\n",
      "Epoch 21/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.1455 - val_loss: 1.0157\n",
      "Epoch 22/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.1346 - val_loss: 1.0082\n",
      "Epoch 23/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.1238 - val_loss: 1.0015\n",
      "Epoch 24/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.1172 - val_loss: 0.9951\n",
      "Epoch 25/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.1068 - val_loss: 0.9893\n",
      "Epoch 26/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1014 - val_loss: 0.9838\n",
      "Epoch 27/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0944 - val_loss: 0.9786\n",
      "Epoch 28/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0876 - val_loss: 0.9738\n",
      "Epoch 29/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0814 - val_loss: 0.9693\n",
      "Epoch 30/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0762 - val_loss: 0.9651\n",
      "Epoch 31/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0712 - val_loss: 0.9611\n",
      "Epoch 32/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0671 - val_loss: 0.9573\n",
      "Epoch 33/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0611 - val_loss: 0.9538\n",
      "Epoch 34/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0592 - val_loss: 0.9504\n",
      "Epoch 35/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0523 - val_loss: 0.9472\n",
      "Epoch 36/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0506 - val_loss: 0.9442\n",
      "Epoch 37/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0469 - val_loss: 0.9413\n",
      "Epoch 38/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0435 - val_loss: 0.9386\n",
      "Epoch 39/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0397 - val_loss: 0.9360\n",
      "Epoch 40/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0378 - val_loss: 0.9335\n",
      "Epoch 41/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0331 - val_loss: 0.9312\n",
      "Epoch 42/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0320 - val_loss: 0.9289\n",
      "Epoch 43/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0278 - val_loss: 0.9269\n",
      "Epoch 44/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0265 - val_loss: 0.9248\n",
      "Epoch 45/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0231 - val_loss: 0.9229\n",
      "Epoch 46/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0216 - val_loss: 0.9211\n",
      "Epoch 47/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0187 - val_loss: 0.9194\n",
      "Epoch 48/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0171 - val_loss: 0.9177\n",
      "Epoch 49/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0152 - val_loss: 0.9162\n",
      "Epoch 50/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0130 - val_loss: 0.9147\n",
      "Epoch 51/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0120 - val_loss: 0.9132\n",
      "Epoch 52/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0100 - val_loss: 0.9118\n",
      "Epoch 53/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0079 - val_loss: 0.9105\n",
      "Epoch 54/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0066 - val_loss: 0.9093\n",
      "Epoch 55/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0054 - val_loss: 0.9081\n",
      "Epoch 56/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0040 - val_loss: 0.9070\n",
      "Epoch 57/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0029 - val_loss: 0.9058\n",
      "Epoch 58/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0017 - val_loss: 0.9048\n",
      "Epoch 59/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0007 - val_loss: 0.9038\n",
      "Epoch 60/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9028\n",
      "Epoch 61/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 0.9019\n",
      "Epoch 62/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9972 - val_loss: 0.9010\n",
      "Epoch 63/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9963 - val_loss: 0.9002\n",
      "Epoch 64/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9953 - val_loss: 0.8994\n",
      "Epoch 65/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9944 - val_loss: 0.8987\n",
      "Epoch 66/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9938 - val_loss: 0.8980\n",
      "Epoch 67/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 0.8973\n",
      "Epoch 68/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9923 - val_loss: 0.8966\n",
      "Epoch 69/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9915 - val_loss: 0.8960\n",
      "Epoch 70/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9908 - val_loss: 0.8954\n",
      "Epoch 71/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9901 - val_loss: 0.8948\n",
      "Epoch 72/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9895 - val_loss: 0.8942\n",
      "Epoch 73/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9889 - val_loss: 0.8937\n",
      "Epoch 74/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9885 - val_loss: 0.8932\n",
      "Epoch 75/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9879 - val_loss: 0.8928\n",
      "Epoch 76/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9874 - val_loss: 0.8923\n",
      "Epoch 77/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9869 - val_loss: 0.8919\n",
      "Epoch 78/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9865 - val_loss: 0.8915\n",
      "Epoch 79/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9861 - val_loss: 0.8911\n",
      "Epoch 80/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9857 - val_loss: 0.8907\n",
      "Epoch 81/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9852 - val_loss: 0.8904\n",
      "Epoch 82/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9849 - val_loss: 0.8900\n",
      "Epoch 83/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9846 - val_loss: 0.8897\n",
      "Epoch 84/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9842 - val_loss: 0.8894\n",
      "Epoch 85/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9839 - val_loss: 0.8891\n",
      "Epoch 86/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9836 - val_loss: 0.8889\n",
      "Epoch 87/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9833 - val_loss: 0.8886\n",
      "Epoch 88/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9831 - val_loss: 0.8884\n",
      "Epoch 89/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9828 - val_loss: 0.8881\n",
      "Epoch 90/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9826 - val_loss: 0.8879\n",
      "Epoch 91/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9824 - val_loss: 0.8877\n",
      "Epoch 92/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9821 - val_loss: 0.8875\n",
      "Epoch 93/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9820 - val_loss: 0.8873\n",
      "Epoch 94/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9818 - val_loss: 0.8871\n",
      "Epoch 95/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9816 - val_loss: 0.8870\n",
      "Epoch 96/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9814 - val_loss: 0.8868\n",
      "Epoch 97/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9812 - val_loss: 0.8866\n",
      "Epoch 98/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9811 - val_loss: 0.8865\n",
      "Epoch 99/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9809 - val_loss: 0.8864\n",
      "Epoch 100/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9808 - val_loss: 0.8862\n",
      "Epoch 101/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9807 - val_loss: 0.8861\n",
      "Epoch 102/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9805 - val_loss: 0.8860\n",
      "Epoch 103/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9804 - val_loss: 0.8859\n",
      "Epoch 104/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9803 - val_loss: 0.8858\n",
      "Epoch 105/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9802 - val_loss: 0.8857\n",
      "Epoch 106/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9801 - val_loss: 0.8856\n",
      "Epoch 107/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9800 - val_loss: 0.8855\n",
      "Epoch 108/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9799 - val_loss: 0.8854\n",
      "Epoch 109/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9799 - val_loss: 0.8854\n",
      "Epoch 110/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9798 - val_loss: 0.8853\n",
      "Epoch 111/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9797 - val_loss: 0.8852\n",
      "Epoch 112/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9796 - val_loss: 0.8851\n",
      "Epoch 113/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9796 - val_loss: 0.8851\n",
      "Epoch 114/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9795 - val_loss: 0.8850\n",
      "Epoch 115/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9794 - val_loss: 0.8850\n",
      "Epoch 116/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9794 - val_loss: 0.8849\n",
      "Epoch 117/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9793 - val_loss: 0.8849\n",
      "Epoch 118/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9793 - val_loss: 0.8848\n",
      "Epoch 119/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9792 - val_loss: 0.8848\n",
      "Epoch 120/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9792 - val_loss: 0.8847\n",
      "Epoch 121/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9791 - val_loss: 0.8847\n",
      "Epoch 122/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9791 - val_loss: 0.8847\n",
      "Epoch 123/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9791 - val_loss: 0.8846\n",
      "Epoch 124/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9790 - val_loss: 0.8846\n",
      "Epoch 125/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9790 - val_loss: 0.8846\n",
      "Epoch 126/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9790 - val_loss: 0.8845\n",
      "Epoch 127/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9789 - val_loss: 0.8845\n",
      "Epoch 128/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9789 - val_loss: 0.8845\n",
      "Epoch 129/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9789 - val_loss: 0.8844\n",
      "Epoch 130/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9788 - val_loss: 0.8844\n",
      "Epoch 131/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9788 - val_loss: 0.8844\n",
      "Epoch 132/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9788 - val_loss: 0.8844\n",
      "Epoch 133/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9788 - val_loss: 0.8843\n",
      "Epoch 134/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9787 - val_loss: 0.8843\n",
      "Epoch 135/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9787 - val_loss: 0.8843\n",
      "Epoch 136/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9787 - val_loss: 0.8843\n",
      "Epoch 137/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9787 - val_loss: 0.8843\n",
      "Epoch 138/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9787 - val_loss: 0.8843\n",
      "Epoch 139/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9787 - val_loss: 0.8842\n",
      "Epoch 140/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9786 - val_loss: 0.8842\n",
      "Epoch 141/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9786 - val_loss: 0.8842\n",
      "Epoch 142/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9786 - val_loss: 0.8842\n",
      "Epoch 143/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9786 - val_loss: 0.8842\n",
      "Epoch 144/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9786 - val_loss: 0.8842\n",
      "Epoch 145/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9786 - val_loss: 0.8842\n",
      "Epoch 146/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9786 - val_loss: 0.8841\n",
      "Epoch 147/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9785 - val_loss: 0.8841\n",
      "Epoch 148/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9785 - val_loss: 0.8841\n",
      "Epoch 149/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9785 - val_loss: 0.8841\n",
      "Epoch 150/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9785 - val_loss: 0.8841\n",
      "Model: \"model_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 1280)              83200     \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_21 (TFOpLam (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_21 (TFOpLambda)  (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_21 (TFOpL (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_21 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_21 (TFO ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_21 (AddLoss)        ()                        0         \n",
      "=================================================================\n",
      "Total params: 87,360\n",
      "Trainable params: 87,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 13.8597 - val_loss: 10.2816\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 5.3471 - val_loss: 5.3932\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 3.0787 - val_loss: 4.1031\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 2.4639 - val_loss: 3.5754\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 2.1889 - val_loss: 3.1726\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 2.0411 - val_loss: 2.9084\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.9430 - val_loss: 2.7235\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.8808 - val_loss: 2.5451\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.8315 - val_loss: 2.3970\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.7957 - val_loss: 2.3000\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.7681 - val_loss: 2.1861\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.7441 - val_loss: 2.1047\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.7269 - val_loss: 2.0214\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.7103 - val_loss: 1.9615\n",
      "Epoch 15/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.7013 - val_loss: 1.9022\n",
      "Epoch 16/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6848 - val_loss: 1.8593\n",
      "Epoch 17/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6781 - val_loss: 1.8197\n",
      "Epoch 18/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6666 - val_loss: 1.7832\n",
      "Epoch 19/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6698 - val_loss: 1.7524\n",
      "Epoch 20/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6577 - val_loss: 1.7232\n",
      "Epoch 21/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6479 - val_loss: 1.7013\n",
      "Epoch 22/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6431 - val_loss: 1.6879\n",
      "Epoch 23/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6379 - val_loss: 1.6761\n",
      "Epoch 24/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6353 - val_loss: 1.6659\n",
      "Epoch 25/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6327 - val_loss: 1.6593\n",
      "Epoch 26/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6303 - val_loss: 1.6538\n",
      "Epoch 27/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6284 - val_loss: 1.6504\n",
      "Epoch 28/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6267 - val_loss: 1.6455\n",
      "Epoch 29/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6252 - val_loss: 1.6439\n",
      "Epoch 30/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6239 - val_loss: 1.6412\n",
      "Epoch 31/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6231 - val_loss: 1.6404\n",
      "Epoch 32/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6226 - val_loss: 1.6375\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6209 - val_loss: 1.6358\n",
      "Epoch 34/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6201 - val_loss: 1.6340\n",
      "Epoch 35/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6198 - val_loss: 1.6329\n",
      "Epoch 36/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6192 - val_loss: 1.6316\n",
      "Epoch 37/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6313\n",
      "Epoch 38/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6183 - val_loss: 1.6297\n",
      "Epoch 39/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6182 - val_loss: 1.6299\n",
      "Epoch 40/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6181 - val_loss: 1.6281\n",
      "Epoch 41/100\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.618 - 0s 2ms/step - loss: 1.6180 - val_loss: 1.6272\n",
      "Epoch 42/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6179 - val_loss: 1.6267\n",
      "Epoch 43/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6178 - val_loss: 1.6266\n",
      "Epoch 44/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6178 - val_loss: 1.6263\n",
      "Epoch 45/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6178 - val_loss: 1.6262\n",
      "Epoch 46/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6261\n",
      "Epoch 47/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6259\n",
      "Epoch 48/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6259\n",
      "Epoch 49/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 50/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6259\n",
      "Epoch 51/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6259\n",
      "Epoch 52/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6259\n",
      "Epoch 53/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6259\n",
      "Epoch 54/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6259\n",
      "Epoch 55/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6259\n",
      "Epoch 56/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6259\n",
      "Epoch 57/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 58/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 59/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 60/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 61/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 62/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 63/100\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.617 - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 64/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 65/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 66/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 67/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 68/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 69/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 70/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 71/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 72/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 73/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 74/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 75/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 76/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 77/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 78/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 79/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 80/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 81/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 82/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 83/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 84/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 85/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 86/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 87/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 88/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 89/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 90/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 91/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 92/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 93/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 94/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 95/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 96/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 97/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 98/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 99/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Epoch 100/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6258\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_121 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 64)                192       \n",
      "=================================================================\n",
      "Total params: 17,156\n",
      "Trainable params: 17,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 1s 3ms/step - loss: 4.7401 - val_loss: 3.2817\n",
      "Epoch 2/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 2.9947 - val_loss: 2.3801\n",
      "Epoch 3/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 2.3295 - val_loss: 1.9499\n",
      "Epoch 4/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.9797 - val_loss: 1.7074\n",
      "Epoch 5/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.7803 - val_loss: 1.5612\n",
      "Epoch 6/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.6379 - val_loss: 1.4501\n",
      "Epoch 7/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.5379 - val_loss: 1.3742\n",
      "Epoch 8/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.4658 - val_loss: 1.3168\n",
      "Epoch 9/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.4089 - val_loss: 1.2718\n",
      "Epoch 10/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.3661 - val_loss: 1.2333\n",
      "Epoch 11/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.3223 - val_loss: 1.2034\n",
      "Epoch 12/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2953 - val_loss: 1.1768\n",
      "Epoch 13/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2701 - val_loss: 1.1552\n",
      "Epoch 14/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2429 - val_loss: 1.1364\n",
      "Epoch 15/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2237 - val_loss: 1.1194\n",
      "Epoch 16/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2005 - val_loss: 1.1049\n",
      "Epoch 17/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1902 - val_loss: 1.0916\n",
      "Epoch 18/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1749 - val_loss: 1.0804\n",
      "Epoch 19/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1592 - val_loss: 1.0701\n",
      "Epoch 20/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1468 - val_loss: 1.0601\n",
      "Epoch 21/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1370 - val_loss: 1.0516\n",
      "Epoch 22/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1300 - val_loss: 1.0437\n",
      "Epoch 23/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1208 - val_loss: 1.0364\n",
      "Epoch 24/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1138 - val_loss: 1.0296\n",
      "Epoch 25/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1082 - val_loss: 1.0233\n",
      "Epoch 26/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0969 - val_loss: 1.0176\n",
      "Epoch 27/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0921 - val_loss: 1.0122\n",
      "Epoch 28/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0835 - val_loss: 1.0073\n",
      "Epoch 29/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0789 - val_loss: 1.0026\n",
      "Epoch 30/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0736 - val_loss: 0.9982\n",
      "Epoch 31/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0696 - val_loss: 0.9940\n",
      "Epoch 32/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0631 - val_loss: 0.9901\n",
      "Epoch 33/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0573 - val_loss: 0.9866\n",
      "Epoch 34/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0532 - val_loss: 0.9832\n",
      "Epoch 35/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0507 - val_loss: 0.9799\n",
      "Epoch 36/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0457 - val_loss: 0.9769\n",
      "Epoch 37/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0426 - val_loss: 0.9740\n",
      "Epoch 38/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0391 - val_loss: 0.9713\n",
      "Epoch 39/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0359 - val_loss: 0.9687\n",
      "Epoch 40/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0333 - val_loss: 0.9662\n",
      "Epoch 41/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0310 - val_loss: 0.9639\n",
      "Epoch 42/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0281 - val_loss: 0.9616\n",
      "Epoch 43/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0253 - val_loss: 0.9595\n",
      "Epoch 44/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0225 - val_loss: 0.9574\n",
      "Epoch 45/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0195 - val_loss: 0.9555\n",
      "Epoch 46/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0180 - val_loss: 0.9537\n",
      "Epoch 47/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0159 - val_loss: 0.9520\n",
      "Epoch 48/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0141 - val_loss: 0.9503\n",
      "Epoch 49/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0114 - val_loss: 0.9487\n",
      "Epoch 50/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0098 - val_loss: 0.9472\n",
      "Epoch 51/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0084 - val_loss: 0.9458\n",
      "Epoch 52/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0064 - val_loss: 0.9444\n",
      "Epoch 53/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0047 - val_loss: 0.9431\n",
      "Epoch 54/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0034 - val_loss: 0.9418\n",
      "Epoch 55/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0024 - val_loss: 0.9406\n",
      "Epoch 56/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0005 - val_loss: 0.9395\n",
      "Epoch 57/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9384\n",
      "Epoch 58/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9981 - val_loss: 0.9373\n",
      "Epoch 59/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9968 - val_loss: 0.9363\n",
      "Epoch 60/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9958 - val_loss: 0.9354\n",
      "Epoch 61/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9948 - val_loss: 0.9345\n",
      "Epoch 62/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9937 - val_loss: 0.9336\n",
      "Epoch 63/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 0.9328\n",
      "Epoch 64/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9920 - val_loss: 0.9320\n",
      "Epoch 65/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 0.9312\n",
      "Epoch 66/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9901 - val_loss: 0.9305\n",
      "Epoch 67/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9893 - val_loss: 0.9298\n",
      "Epoch 68/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9887 - val_loss: 0.9292\n",
      "Epoch 69/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9879 - val_loss: 0.9286\n",
      "Epoch 70/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9873 - val_loss: 0.9280\n",
      "Epoch 71/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9866 - val_loss: 0.9274\n",
      "Epoch 72/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9861 - val_loss: 0.9268\n",
      "Epoch 73/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9855 - val_loss: 0.9263\n",
      "Epoch 74/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9849 - val_loss: 0.9258\n",
      "Epoch 75/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9844 - val_loss: 0.9254\n",
      "Epoch 76/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9839 - val_loss: 0.9249\n",
      "Epoch 77/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9834 - val_loss: 0.9245\n",
      "Epoch 78/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9830 - val_loss: 0.9241\n",
      "Epoch 79/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9825 - val_loss: 0.9237\n",
      "Epoch 80/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9821 - val_loss: 0.9233\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9817 - val_loss: 0.9230\n",
      "Epoch 82/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9814 - val_loss: 0.9226\n",
      "Epoch 83/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9811 - val_loss: 0.9223\n",
      "Epoch 84/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9807 - val_loss: 0.9220\n",
      "Epoch 85/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9804 - val_loss: 0.9217\n",
      "Epoch 86/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9801 - val_loss: 0.9215\n",
      "Epoch 87/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9798 - val_loss: 0.9212\n",
      "Epoch 88/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9796 - val_loss: 0.9210\n",
      "Epoch 89/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9793 - val_loss: 0.9207\n",
      "Epoch 90/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9791 - val_loss: 0.9205\n",
      "Epoch 91/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9789 - val_loss: 0.9203\n",
      "Epoch 92/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9786 - val_loss: 0.9201\n",
      "Epoch 93/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9784 - val_loss: 0.9199\n",
      "Epoch 94/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9783 - val_loss: 0.9197\n",
      "Epoch 95/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9780 - val_loss: 0.9196\n",
      "Epoch 96/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9779 - val_loss: 0.9194\n",
      "Epoch 97/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9777 - val_loss: 0.9193\n",
      "Epoch 98/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9776 - val_loss: 0.9191\n",
      "Epoch 99/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9774 - val_loss: 0.9190\n",
      "Epoch 100/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9773 - val_loss: 0.9189\n",
      "Epoch 101/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9772 - val_loss: 0.9187\n",
      "Epoch 102/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9770 - val_loss: 0.9186\n",
      "Epoch 103/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9769 - val_loss: 0.9185\n",
      "Epoch 104/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9768 - val_loss: 0.9184\n",
      "Epoch 105/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9767 - val_loss: 0.9183\n",
      "Epoch 106/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9766 - val_loss: 0.9182\n",
      "Epoch 107/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9765 - val_loss: 0.9181\n",
      "Epoch 108/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9764 - val_loss: 0.9181\n",
      "Epoch 109/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9763 - val_loss: 0.9180\n",
      "Epoch 110/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9763 - val_loss: 0.9179\n",
      "Epoch 111/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9762 - val_loss: 0.9178\n",
      "Epoch 112/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9761 - val_loss: 0.9178\n",
      "Epoch 113/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9761 - val_loss: 0.9177\n",
      "Epoch 114/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9760 - val_loss: 0.9177\n",
      "Epoch 115/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9759 - val_loss: 0.9176\n",
      "Epoch 116/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9759 - val_loss: 0.9175\n",
      "Epoch 117/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9758 - val_loss: 0.9175\n",
      "Epoch 118/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9758 - val_loss: 0.9175\n",
      "Epoch 119/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9757 - val_loss: 0.9174\n",
      "Epoch 120/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9757 - val_loss: 0.9174\n",
      "Epoch 121/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9756 - val_loss: 0.9173\n",
      "Epoch 122/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9756 - val_loss: 0.9173\n",
      "Epoch 123/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9756 - val_loss: 0.9173\n",
      "Epoch 124/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9755 - val_loss: 0.9172\n",
      "Epoch 125/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9755 - val_loss: 0.9172\n",
      "Epoch 126/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9754 - val_loss: 0.9172\n",
      "Epoch 127/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9754 - val_loss: 0.9171\n",
      "Epoch 128/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9754 - val_loss: 0.9171\n",
      "Epoch 129/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9754 - val_loss: 0.9171\n",
      "Epoch 130/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9753 - val_loss: 0.9171\n",
      "Epoch 131/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9753 - val_loss: 0.9170\n",
      "Epoch 132/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9753 - val_loss: 0.9170\n",
      "Epoch 133/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9753 - val_loss: 0.9170\n",
      "Epoch 134/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9752 - val_loss: 0.9170\n",
      "Epoch 135/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9752 - val_loss: 0.9170\n",
      "Epoch 136/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9752 - val_loss: 0.9169\n",
      "Epoch 137/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9752 - val_loss: 0.9169\n",
      "Epoch 138/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9752 - val_loss: 0.9169\n",
      "Epoch 139/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9751 - val_loss: 0.9169\n",
      "Epoch 140/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9751 - val_loss: 0.9169\n",
      "Epoch 141/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9751 - val_loss: 0.9169\n",
      "Epoch 142/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9751 - val_loss: 0.9168\n",
      "Epoch 143/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9751 - val_loss: 0.9168\n",
      "Epoch 144/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9751 - val_loss: 0.9168\n",
      "Epoch 145/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9751 - val_loss: 0.9168\n",
      "Epoch 146/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9750 - val_loss: 0.9168\n",
      "Epoch 147/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9750 - val_loss: 0.9168\n",
      "Epoch 148/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9750 - val_loss: 0.9168\n",
      "Epoch 149/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9750 - val_loss: 0.9168\n",
      "Epoch 150/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9750 - val_loss: 0.9168\n",
      "Model: \"model_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 1280)              83200     \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_23 (TFOpLam (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_23 (TFOpLambda)  (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_23 (TFOpL (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_23 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_23 (TFO ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_23 (AddLoss)        ()                        0         \n",
      "=================================================================\n",
      "Total params: 87,360\n",
      "Trainable params: 87,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 1s 2ms/step - loss: 14.2280 - val_loss: 7.9844\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 5.6107 - val_loss: 3.5804\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 3.1888 - val_loss: 2.5091\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 2.5158 - val_loss: 2.1197\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 2.2192 - val_loss: 1.9368\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 2.0633 - val_loss: 1.8219\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.9576 - val_loss: 1.7747\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.8915 - val_loss: 1.7196\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.8394 - val_loss: 1.6925\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.7988 - val_loss: 1.6719\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.7682 - val_loss: 1.6589\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.7435 - val_loss: 1.6511\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.7216 - val_loss: 1.6432\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.7063 - val_loss: 1.6394\n",
      "Epoch 15/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6914 - val_loss: 1.6343\n",
      "Epoch 16/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.6803 - val_loss: 1.6316\n",
      "Epoch 17/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6688 - val_loss: 1.6295\n",
      "Epoch 18/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6611 - val_loss: 1.6277\n",
      "Epoch 19/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6533 - val_loss: 1.6261\n",
      "Epoch 20/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6496 - val_loss: 1.6254\n",
      "Epoch 21/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6457 - val_loss: 1.6240\n",
      "Epoch 22/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6405 - val_loss: 1.6236\n",
      "Epoch 23/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6373 - val_loss: 1.6229\n",
      "Epoch 24/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6349 - val_loss: 1.6224\n",
      "Epoch 25/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6331 - val_loss: 1.6220\n",
      "Epoch 26/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6309 - val_loss: 1.6217\n",
      "Epoch 27/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6293 - val_loss: 1.6214\n",
      "Epoch 28/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6278 - val_loss: 1.6212\n",
      "Epoch 29/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6266 - val_loss: 1.6212\n",
      "Epoch 30/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6254 - val_loss: 1.6209\n",
      "Epoch 31/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6239 - val_loss: 1.6207\n",
      "Epoch 32/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6206\n",
      "Epoch 33/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6220 - val_loss: 1.6205\n",
      "Epoch 34/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6214 - val_loss: 1.6204\n",
      "Epoch 35/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6209 - val_loss: 1.6203\n",
      "Epoch 36/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6205 - val_loss: 1.6203\n",
      "Epoch 37/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6202 - val_loss: 1.6202\n",
      "Epoch 38/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6200 - val_loss: 1.6202\n",
      "Epoch 39/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6193 - val_loss: 1.6201\n",
      "Epoch 40/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6191 - val_loss: 1.6201\n",
      "Epoch 41/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6190 - val_loss: 1.6200\n",
      "Epoch 42/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6190 - val_loss: 1.6200\n",
      "Epoch 43/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6189 - val_loss: 1.6199\n",
      "Epoch 44/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6189 - val_loss: 1.6199\n",
      "Epoch 45/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6189 - val_loss: 1.6199\n",
      "Epoch 46/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6189 - val_loss: 1.6199\n",
      "Epoch 47/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6189 - val_loss: 1.6199\n",
      "Epoch 48/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 49/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 50/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 51/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 52/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 53/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 54/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 55/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 56/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 57/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 58/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 59/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 60/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 61/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 62/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 63/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 64/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 65/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 66/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 67/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 68/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 69/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 70/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 71/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 72/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 73/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 74/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 75/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 76/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 77/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 78/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 79/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 80/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 82/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 83/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 84/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 85/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 86/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 87/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 88/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 89/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 90/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 91/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 92/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 93/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 94/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 95/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 96/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 97/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 98/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 99/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Epoch 100/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6188 - val_loss: 1.6198\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_132 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_101 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_102 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_103 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 64)                192       \n",
      "=================================================================\n",
      "Total params: 17,156\n",
      "Trainable params: 17,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "101/101 [==============================] - 1s 3ms/step - loss: 4.8082 - val_loss: 3.1209\n",
      "Epoch 2/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 3.0475 - val_loss: 2.2575\n",
      "Epoch 3/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 2.3745 - val_loss: 1.8440\n",
      "Epoch 4/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 2.0203 - val_loss: 1.6109\n",
      "Epoch 5/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.8144 - val_loss: 1.4688\n",
      "Epoch 6/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.6674 - val_loss: 1.3765\n",
      "Epoch 7/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.5673 - val_loss: 1.3031\n",
      "Epoch 8/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.4900 - val_loss: 1.2488\n",
      "Epoch 9/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.4322 - val_loss: 1.2073\n",
      "Epoch 10/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.3773 - val_loss: 1.1728\n",
      "Epoch 11/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.3437 - val_loss: 1.1442\n",
      "Epoch 12/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.3049 - val_loss: 1.1197\n",
      "Epoch 13/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2761 - val_loss: 1.0986\n",
      "Epoch 14/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2519 - val_loss: 1.0808\n",
      "Epoch 15/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2265 - val_loss: 1.0656\n",
      "Epoch 16/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2154 - val_loss: 1.0513\n",
      "Epoch 17/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1975 - val_loss: 1.0394\n",
      "Epoch 18/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1814 - val_loss: 1.0283\n",
      "Epoch 19/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1675 - val_loss: 1.0184\n",
      "Epoch 20/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1565 - val_loss: 1.0095\n",
      "Epoch 21/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1462 - val_loss: 1.0011\n",
      "Epoch 22/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1368 - val_loss: 0.9935\n",
      "Epoch 23/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1253 - val_loss: 0.9866\n",
      "Epoch 24/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1187 - val_loss: 0.9803\n",
      "Epoch 25/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1107 - val_loss: 0.9744\n",
      "Epoch 26/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1043 - val_loss: 0.9688\n",
      "Epoch 27/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0943 - val_loss: 0.9638\n",
      "Epoch 28/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0901 - val_loss: 0.9589\n",
      "Epoch 29/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0836 - val_loss: 0.9544\n",
      "Epoch 30/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0787 - val_loss: 0.9501\n",
      "Epoch 31/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0732 - val_loss: 0.9461\n",
      "Epoch 32/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0679 - val_loss: 0.9424\n",
      "Epoch 33/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0622 - val_loss: 0.9389\n",
      "Epoch 34/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0595 - val_loss: 0.9355\n",
      "Epoch 35/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0552 - val_loss: 0.9323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0514 - val_loss: 0.9293\n",
      "Epoch 37/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0479 - val_loss: 0.9265\n",
      "Epoch 38/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0438 - val_loss: 0.9238\n",
      "Epoch 39/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0409 - val_loss: 0.9212\n",
      "Epoch 40/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0377 - val_loss: 0.9188\n",
      "Epoch 41/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0357 - val_loss: 0.9164\n",
      "Epoch 42/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0322 - val_loss: 0.9142\n",
      "Epoch 43/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0297 - val_loss: 0.9121\n",
      "Epoch 44/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0279 - val_loss: 0.9102\n",
      "Epoch 45/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0246 - val_loss: 0.9082\n",
      "Epoch 46/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0241 - val_loss: 0.9064\n",
      "Epoch 47/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0210 - val_loss: 0.9046\n",
      "Epoch 48/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0185 - val_loss: 0.9029\n",
      "Epoch 49/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0168 - val_loss: 0.9014\n",
      "Epoch 50/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0149 - val_loss: 0.8999\n",
      "Epoch 51/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0128 - val_loss: 0.8984\n",
      "Epoch 52/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0118 - val_loss: 0.8970\n",
      "Epoch 53/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0099 - val_loss: 0.8958\n",
      "Epoch 54/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0086 - val_loss: 0.8945\n",
      "Epoch 55/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0067 - val_loss: 0.8933\n",
      "Epoch 56/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0057 - val_loss: 0.8922\n",
      "Epoch 57/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0044 - val_loss: 0.8911\n",
      "Epoch 58/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0032 - val_loss: 0.8900\n",
      "Epoch 59/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 1.0020 - val_loss: 0.8890\n",
      "Epoch 60/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0010 - val_loss: 0.8881\n",
      "Epoch 61/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9997 - val_loss: 0.8872\n",
      "Epoch 62/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 0.8863\n",
      "Epoch 63/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9977 - val_loss: 0.8855\n",
      "Epoch 64/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 0.8847\n",
      "Epoch 65/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9960 - val_loss: 0.8840\n",
      "Epoch 66/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9953 - val_loss: 0.8832\n",
      "Epoch 67/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9944 - val_loss: 0.8826\n",
      "Epoch 68/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9938 - val_loss: 0.8819\n",
      "Epoch 69/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 0.8813\n",
      "Epoch 70/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9925 - val_loss: 0.8807\n",
      "Epoch 71/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9916 - val_loss: 0.8801\n",
      "Epoch 72/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9910 - val_loss: 0.8796\n",
      "Epoch 73/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9906 - val_loss: 0.8791\n",
      "Epoch 74/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9900 - val_loss: 0.8786\n",
      "Epoch 75/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9896 - val_loss: 0.8781\n",
      "Epoch 76/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9890 - val_loss: 0.8776\n",
      "Epoch 77/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9886 - val_loss: 0.8772\n",
      "Epoch 78/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9880 - val_loss: 0.8768\n",
      "Epoch 79/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9877 - val_loss: 0.8764\n",
      "Epoch 80/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9873 - val_loss: 0.8760\n",
      "Epoch 81/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9869 - val_loss: 0.8757\n",
      "Epoch 82/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9865 - val_loss: 0.8754\n",
      "Epoch 83/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9861 - val_loss: 0.8750\n",
      "Epoch 84/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9859 - val_loss: 0.8747\n",
      "Epoch 85/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9856 - val_loss: 0.8745\n",
      "Epoch 86/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9853 - val_loss: 0.8742\n",
      "Epoch 87/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9849 - val_loss: 0.8739\n",
      "Epoch 88/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9847 - val_loss: 0.8737\n",
      "Epoch 89/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9844 - val_loss: 0.8735\n",
      "Epoch 90/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9842 - val_loss: 0.8732\n",
      "Epoch 91/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9840 - val_loss: 0.8730\n",
      "Epoch 92/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9837 - val_loss: 0.8728\n",
      "Epoch 93/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9836 - val_loss: 0.8726\n",
      "Epoch 94/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9834 - val_loss: 0.8725\n",
      "Epoch 95/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9832 - val_loss: 0.8723\n",
      "Epoch 96/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9830 - val_loss: 0.8721\n",
      "Epoch 97/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9829 - val_loss: 0.8720\n",
      "Epoch 98/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9827 - val_loss: 0.8718\n",
      "Epoch 99/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9826 - val_loss: 0.8717\n",
      "Epoch 100/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9824 - val_loss: 0.8716\n",
      "Epoch 101/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9823 - val_loss: 0.8715\n",
      "Epoch 102/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9822 - val_loss: 0.8713\n",
      "Epoch 103/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9821 - val_loss: 0.8712\n",
      "Epoch 104/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9820 - val_loss: 0.8711\n",
      "Epoch 105/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9818 - val_loss: 0.8710\n",
      "Epoch 106/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9818 - val_loss: 0.8709\n",
      "Epoch 107/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9817 - val_loss: 0.8709\n",
      "Epoch 108/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9816 - val_loss: 0.8708\n",
      "Epoch 109/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9815 - val_loss: 0.8707\n",
      "Epoch 110/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9814 - val_loss: 0.8706\n",
      "Epoch 111/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9813 - val_loss: 0.8706\n",
      "Epoch 112/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9813 - val_loss: 0.8705\n",
      "Epoch 113/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9812 - val_loss: 0.8704\n",
      "Epoch 114/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9811 - val_loss: 0.8704\n",
      "Epoch 115/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9811 - val_loss: 0.8703\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9810 - val_loss: 0.8703\n",
      "Epoch 117/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9810 - val_loss: 0.8702\n",
      "Epoch 118/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9809 - val_loss: 0.8702\n",
      "Epoch 119/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9809 - val_loss: 0.8701\n",
      "Epoch 120/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9808 - val_loss: 0.8701\n",
      "Epoch 121/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9808 - val_loss: 0.8700\n",
      "Epoch 122/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9807 - val_loss: 0.8700\n",
      "Epoch 123/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9807 - val_loss: 0.8700\n",
      "Epoch 124/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9807 - val_loss: 0.8699\n",
      "Epoch 125/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9806 - val_loss: 0.8699\n",
      "Epoch 126/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9806 - val_loss: 0.8699\n",
      "Epoch 127/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9806 - val_loss: 0.8698\n",
      "Epoch 128/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9805 - val_loss: 0.8698\n",
      "Epoch 129/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9805 - val_loss: 0.8698\n",
      "Epoch 130/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9805 - val_loss: 0.8698\n",
      "Epoch 131/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9805 - val_loss: 0.8697\n",
      "Epoch 132/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9804 - val_loss: 0.8697\n",
      "Epoch 133/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9804 - val_loss: 0.8697\n",
      "Epoch 134/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9804 - val_loss: 0.8697\n",
      "Epoch 135/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9804 - val_loss: 0.8696\n",
      "Epoch 136/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9803 - val_loss: 0.8696\n",
      "Epoch 137/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9803 - val_loss: 0.8696\n",
      "Epoch 138/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9803 - val_loss: 0.8696\n",
      "Epoch 139/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9803 - val_loss: 0.8696\n",
      "Epoch 140/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9803 - val_loss: 0.8696\n",
      "Epoch 141/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9803 - val_loss: 0.8695\n",
      "Epoch 142/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9802 - val_loss: 0.8695\n",
      "Epoch 143/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9802 - val_loss: 0.8695\n",
      "Epoch 144/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9802 - val_loss: 0.8695\n",
      "Epoch 145/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9802 - val_loss: 0.8695\n",
      "Epoch 146/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9802 - val_loss: 0.8695\n",
      "Epoch 147/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9802 - val_loss: 0.8695\n",
      "Epoch 148/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9802 - val_loss: 0.8695\n",
      "Epoch 149/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9802 - val_loss: 0.8695\n",
      "Epoch 150/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9801 - val_loss: 0.8694\n",
      "Model: \"model_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_26 (InputLayer)        [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 1280)              83200     \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_25 (TFOpLam (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_25 (TFOpLambda)  (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_25 (TFOpL (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_25 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_25 (TFO ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_25 (AddLoss)        ()                        0         \n",
      "=================================================================\n",
      "Total params: 87,360\n",
      "Trainable params: 87,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 14.8260 - val_loss: 9.1325\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 5.8241 - val_loss: 4.3415\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 3.2486 - val_loss: 3.2221\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 2.6004 - val_loss: 2.7696\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 2.2822 - val_loss: 2.5388\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 2.0921 - val_loss: 2.4022\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.9970 - val_loss: 2.2995\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.9259 - val_loss: 2.2099\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.8777 - val_loss: 2.1452\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.8394 - val_loss: 2.1139\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.8043 - val_loss: 2.0700\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.7872 - val_loss: 2.0347\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.7598 - val_loss: 1.9850\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.7405 - val_loss: 1.9535\n",
      "Epoch 15/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.7260 - val_loss: 1.9354\n",
      "Epoch 16/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.7107 - val_loss: 1.9061\n",
      "Epoch 17/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.7031 - val_loss: 1.8785\n",
      "Epoch 18/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6898 - val_loss: 1.8655\n",
      "Epoch 19/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6811 - val_loss: 1.8449\n",
      "Epoch 20/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.6711 - val_loss: 1.8225\n",
      "Epoch 21/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6625 - val_loss: 1.8072\n",
      "Epoch 22/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6585 - val_loss: 1.7966\n",
      "Epoch 23/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6502 - val_loss: 1.7816\n",
      "Epoch 24/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6450 - val_loss: 1.7752\n",
      "Epoch 25/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6404 - val_loss: 1.7570\n",
      "Epoch 26/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6362 - val_loss: 1.7541\n",
      "Epoch 27/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6326 - val_loss: 1.7437\n",
      "Epoch 28/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.6296 - val_loss: 1.7289\n",
      "Epoch 29/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6268 - val_loss: 1.7229\n",
      "Epoch 30/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6246 - val_loss: 1.7001\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6223 - val_loss: 1.7056\n",
      "Epoch 32/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6210 - val_loss: 1.6973\n",
      "Epoch 33/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6198 - val_loss: 1.7003\n",
      "Epoch 34/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6189 - val_loss: 1.6876\n",
      "Epoch 35/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6181 - val_loss: 1.6887\n",
      "Epoch 36/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6176 - val_loss: 1.6878\n",
      "Epoch 37/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6172 - val_loss: 1.6857\n",
      "Epoch 38/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6169 - val_loss: 1.6853\n",
      "Epoch 39/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6166 - val_loss: 1.6833\n",
      "Epoch 40/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6164 - val_loss: 1.6833\n",
      "Epoch 41/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6163 - val_loss: 1.6819\n",
      "Epoch 42/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6162 - val_loss: 1.6827\n",
      "Epoch 43/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6161 - val_loss: 1.6818\n",
      "Epoch 44/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6160 - val_loss: 1.6831\n",
      "Epoch 45/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6160 - val_loss: 1.6796\n",
      "Epoch 46/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6159 - val_loss: 1.6784\n",
      "Epoch 47/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6159 - val_loss: 1.6773\n",
      "Epoch 48/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6782\n",
      "Epoch 49/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6787\n",
      "Epoch 50/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6783\n",
      "Epoch 51/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6786\n",
      "Epoch 52/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6784\n",
      "Epoch 53/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6783\n",
      "Epoch 54/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6783\n",
      "Epoch 55/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.6158 - val_loss: 1.6783\n",
      "Epoch 56/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6783\n",
      "Epoch 57/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.6158 - val_loss: 1.6782\n",
      "Epoch 58/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.6158 - val_loss: 1.6782\n",
      "Epoch 59/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6782\n",
      "Epoch 60/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 61/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 62/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 63/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 64/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 65/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 66/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 67/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 68/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 69/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 70/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 71/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 72/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 73/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 74/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 75/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 76/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 77/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 78/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 79/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 80/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 81/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 82/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 83/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 84/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 85/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 86/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 87/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 88/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 89/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 90/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 91/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 92/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 93/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 94/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 95/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 96/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 97/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 98/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 99/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Epoch 100/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6781\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_143 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_105 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "dropout_106 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_107 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_109 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_110 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_111 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 64)                192       \n",
      "=================================================================\n",
      "Total params: 17,156\n",
      "Trainable params: 17,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 1s 3ms/step - loss: 4.6988 - val_loss: 3.9023\n",
      "Epoch 2/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 2.9575 - val_loss: 2.8833\n",
      "Epoch 3/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 2.2915 - val_loss: 2.3164\n",
      "Epoch 4/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.9564 - val_loss: 2.0092\n",
      "Epoch 5/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.7598 - val_loss: 1.8143\n",
      "Epoch 6/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.6189 - val_loss: 1.6873\n",
      "Epoch 7/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.5174 - val_loss: 1.5954\n",
      "Epoch 8/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.4535 - val_loss: 1.5172\n",
      "Epoch 9/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.3916 - val_loss: 1.4653\n",
      "Epoch 10/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.3427 - val_loss: 1.4238\n",
      "Epoch 11/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.3124 - val_loss: 1.3890\n",
      "Epoch 12/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2721 - val_loss: 1.3619\n",
      "Epoch 13/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2477 - val_loss: 1.3385\n",
      "Epoch 14/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2219 - val_loss: 1.3195\n",
      "Epoch 15/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2020 - val_loss: 1.3032\n",
      "Epoch 16/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1871 - val_loss: 1.2877\n",
      "Epoch 17/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1701 - val_loss: 1.2748\n",
      "Epoch 18/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1516 - val_loss: 1.2643\n",
      "Epoch 19/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1412 - val_loss: 1.2536\n",
      "Epoch 20/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1291 - val_loss: 1.2444\n",
      "Epoch 21/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1172 - val_loss: 1.2360\n",
      "Epoch 22/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1080 - val_loss: 1.2285\n",
      "Epoch 23/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0986 - val_loss: 1.2215\n",
      "Epoch 24/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0918 - val_loss: 1.2152\n",
      "Epoch 25/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0837 - val_loss: 1.2092\n",
      "Epoch 26/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0762 - val_loss: 1.2036\n",
      "Epoch 27/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0681 - val_loss: 1.1985\n",
      "Epoch 28/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.1936\n",
      "Epoch 29/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0578 - val_loss: 1.1891\n",
      "Epoch 30/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0513 - val_loss: 1.1848\n",
      "Epoch 31/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0456 - val_loss: 1.1809\n",
      "Epoch 32/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0418 - val_loss: 1.1771\n",
      "Epoch 33/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0370 - val_loss: 1.1736\n",
      "Epoch 34/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0324 - val_loss: 1.1702\n",
      "Epoch 35/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0289 - val_loss: 1.1671\n",
      "Epoch 36/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0254 - val_loss: 1.1640\n",
      "Epoch 37/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0217 - val_loss: 1.1611\n",
      "Epoch 38/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0187 - val_loss: 1.1584\n",
      "Epoch 39/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0151 - val_loss: 1.1558\n",
      "Epoch 40/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0121 - val_loss: 1.1534\n",
      "Epoch 41/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0097 - val_loss: 1.1510\n",
      "Epoch 42/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0065 - val_loss: 1.1488\n",
      "Epoch 43/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0037 - val_loss: 1.1467\n",
      "Epoch 44/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0016 - val_loss: 1.1446\n",
      "Epoch 45/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.1427\n",
      "Epoch 46/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9964 - val_loss: 1.1409\n",
      "Epoch 47/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9950 - val_loss: 1.1392\n",
      "Epoch 48/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.1375\n",
      "Epoch 49/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9905 - val_loss: 1.1359\n",
      "Epoch 50/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9887 - val_loss: 1.1344\n",
      "Epoch 51/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9873 - val_loss: 1.1330\n",
      "Epoch 52/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9855 - val_loss: 1.1316\n",
      "Epoch 53/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9835 - val_loss: 1.1303\n",
      "Epoch 54/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9823 - val_loss: 1.1290\n",
      "Epoch 55/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9811 - val_loss: 1.1278\n",
      "Epoch 56/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9795 - val_loss: 1.1267\n",
      "Epoch 57/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9786 - val_loss: 1.1256\n",
      "Epoch 58/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9770 - val_loss: 1.1245\n",
      "Epoch 59/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9759 - val_loss: 1.1235\n",
      "Epoch 60/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9749 - val_loss: 1.1225\n",
      "Epoch 61/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9739 - val_loss: 1.1216\n",
      "Epoch 62/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9728 - val_loss: 1.1208\n",
      "Epoch 63/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9718 - val_loss: 1.1199\n",
      "Epoch 64/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9710 - val_loss: 1.1191\n",
      "Epoch 65/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9700 - val_loss: 1.1184\n",
      "Epoch 66/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9690 - val_loss: 1.1177\n",
      "Epoch 67/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9683 - val_loss: 1.1170\n",
      "Epoch 68/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9677 - val_loss: 1.1163\n",
      "Epoch 69/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9671 - val_loss: 1.1157\n",
      "Epoch 70/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9663 - val_loss: 1.1151\n",
      "Epoch 71/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9658 - val_loss: 1.1145\n",
      "Epoch 72/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9651 - val_loss: 1.1139\n",
      "Epoch 73/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9645 - val_loss: 1.1134\n",
      "Epoch 74/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9640 - val_loss: 1.1129\n",
      "Epoch 75/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9634 - val_loss: 1.1124\n",
      "Epoch 76/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9629 - val_loss: 1.1120\n",
      "Epoch 77/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9624 - val_loss: 1.1116\n",
      "Epoch 78/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9620 - val_loss: 1.1112\n",
      "Epoch 79/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9616 - val_loss: 1.1108\n",
      "Epoch 80/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9611 - val_loss: 1.1104\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9608 - val_loss: 1.1101\n",
      "Epoch 82/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9604 - val_loss: 1.1097\n",
      "Epoch 83/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9601 - val_loss: 1.1094\n",
      "Epoch 84/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9598 - val_loss: 1.1091\n",
      "Epoch 85/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9595 - val_loss: 1.1088\n",
      "Epoch 86/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9592 - val_loss: 1.1085\n",
      "Epoch 87/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9589 - val_loss: 1.1083\n",
      "Epoch 88/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9586 - val_loss: 1.1080\n",
      "Epoch 89/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9583 - val_loss: 1.1078\n",
      "Epoch 90/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9581 - val_loss: 1.1076\n",
      "Epoch 91/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9579 - val_loss: 1.1074\n",
      "Epoch 92/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9577 - val_loss: 1.1072\n",
      "Epoch 93/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9575 - val_loss: 1.1070\n",
      "Epoch 94/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9573 - val_loss: 1.1068\n",
      "Epoch 95/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9571 - val_loss: 1.1066\n",
      "Epoch 96/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9569 - val_loss: 1.1065\n",
      "Epoch 97/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9568 - val_loss: 1.1063\n",
      "Epoch 98/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9566 - val_loss: 1.1062\n",
      "Epoch 99/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9565 - val_loss: 1.1060\n",
      "Epoch 100/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9563 - val_loss: 1.1059\n",
      "Epoch 101/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9562 - val_loss: 1.1058\n",
      "Epoch 102/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9561 - val_loss: 1.1057\n",
      "Epoch 103/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9560 - val_loss: 1.1056\n",
      "Epoch 104/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9559 - val_loss: 1.1055\n",
      "Epoch 105/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9558 - val_loss: 1.1054\n",
      "Epoch 106/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9557 - val_loss: 1.1053\n",
      "Epoch 107/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9556 - val_loss: 1.1052\n",
      "Epoch 108/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9555 - val_loss: 1.1051\n",
      "Epoch 109/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9554 - val_loss: 1.1050\n",
      "Epoch 110/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9553 - val_loss: 1.1049\n",
      "Epoch 111/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9553 - val_loss: 1.1049\n",
      "Epoch 112/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9552 - val_loss: 1.1048\n",
      "Epoch 113/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9551 - val_loss: 1.1047\n",
      "Epoch 114/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9550 - val_loss: 1.1047\n",
      "Epoch 115/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9550 - val_loss: 1.1046\n",
      "Epoch 116/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9549 - val_loss: 1.1046\n",
      "Epoch 117/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9549 - val_loss: 1.1045\n",
      "Epoch 118/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9548 - val_loss: 1.1045\n",
      "Epoch 119/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9548 - val_loss: 1.1044\n",
      "Epoch 120/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9547 - val_loss: 1.1044\n",
      "Epoch 121/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9547 - val_loss: 1.1043\n",
      "Epoch 122/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9546 - val_loss: 1.1043\n",
      "Epoch 123/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9546 - val_loss: 1.1043\n",
      "Epoch 124/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9546 - val_loss: 1.1042\n",
      "Epoch 125/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9545 - val_loss: 1.1042\n",
      "Epoch 126/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9545 - val_loss: 1.1042\n",
      "Epoch 127/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9545 - val_loss: 1.1041\n",
      "Epoch 128/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9544 - val_loss: 1.1041\n",
      "Epoch 129/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9544 - val_loss: 1.1041\n",
      "Epoch 130/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9544 - val_loss: 1.1041\n",
      "Epoch 131/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9544 - val_loss: 1.1040\n",
      "Epoch 132/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9543 - val_loss: 1.1040\n",
      "Epoch 133/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9543 - val_loss: 1.1040\n",
      "Epoch 134/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9543 - val_loss: 1.1040\n",
      "Epoch 135/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9543 - val_loss: 1.1040\n",
      "Epoch 136/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9543 - val_loss: 1.1039\n",
      "Epoch 137/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9542 - val_loss: 1.1039\n",
      "Epoch 138/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9542 - val_loss: 1.1039\n",
      "Epoch 139/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9542 - val_loss: 1.1039\n",
      "Epoch 140/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9542 - val_loss: 1.1039\n",
      "Epoch 141/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9542 - val_loss: 1.1039\n",
      "Epoch 142/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9542 - val_loss: 1.1038\n",
      "Epoch 143/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9541 - val_loss: 1.1038\n",
      "Epoch 144/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9541 - val_loss: 1.1038\n",
      "Epoch 145/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9541 - val_loss: 1.1038\n",
      "Epoch 146/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9541 - val_loss: 1.1038\n",
      "Epoch 147/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9541 - val_loss: 1.1038\n",
      "Epoch 148/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9541 - val_loss: 1.1038\n",
      "Epoch 149/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9541 - val_loss: 1.1038\n",
      "Epoch 150/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9541 - val_loss: 1.1038\n",
      "Model: \"model_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_28 (InputLayer)        [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 1280)              83200     \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_27 (TFOpLam (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_27 (TFOpLambda)  (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_27 (TFOpL (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_27 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_27 (TFO ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_27 (AddLoss)        ()                        0         \n",
      "=================================================================\n",
      "Total params: 87,360\n",
      "Trainable params: 87,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 0s 2ms/step - loss: 15.0223 - val_loss: 8.4402\n",
      "Epoch 2/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 6.1195 - val_loss: 3.7460\n",
      "Epoch 3/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 3.3394 - val_loss: 2.5609\n",
      "Epoch 4/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 2.5767 - val_loss: 2.1864\n",
      "Epoch 5/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 2.2566 - val_loss: 2.0080\n",
      "Epoch 6/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 2.0841 - val_loss: 1.9168\n",
      "Epoch 7/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.9815 - val_loss: 1.8486\n",
      "Epoch 8/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.9046 - val_loss: 1.8110\n",
      "Epoch 9/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.8513 - val_loss: 1.7743\n",
      "Epoch 10/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.8113 - val_loss: 1.7491\n",
      "Epoch 11/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.7782 - val_loss: 1.7256\n",
      "Epoch 12/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.7532 - val_loss: 1.7079\n",
      "Epoch 13/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.7445 - val_loss: 1.6925\n",
      "Epoch 14/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.7162 - val_loss: 1.6764\n",
      "Epoch 15/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.7017 - val_loss: 1.6673\n",
      "Epoch 16/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6859 - val_loss: 1.6580\n",
      "Epoch 17/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6758 - val_loss: 1.6513\n",
      "Epoch 18/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6666 - val_loss: 1.6430\n",
      "Epoch 19/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6591 - val_loss: 1.6407\n",
      "Epoch 20/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6528 - val_loss: 1.6348\n",
      "Epoch 21/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6466 - val_loss: 1.6308\n",
      "Epoch 22/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6428 - val_loss: 1.6281\n",
      "Epoch 23/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6386 - val_loss: 1.6256\n",
      "Epoch 24/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6351 - val_loss: 1.6248\n",
      "Epoch 25/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6332 - val_loss: 1.6236\n",
      "Epoch 26/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6305 - val_loss: 1.6227\n",
      "Epoch 27/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6289 - val_loss: 1.6209\n",
      "Epoch 28/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6269 - val_loss: 1.6203\n",
      "Epoch 29/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6253 - val_loss: 1.6199\n",
      "Epoch 30/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6241 - val_loss: 1.6193\n",
      "Epoch 31/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6188\n",
      "Epoch 32/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6217 - val_loss: 1.6185\n",
      "Epoch 33/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6207 - val_loss: 1.6182\n",
      "Epoch 34/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6197 - val_loss: 1.6179\n",
      "Epoch 35/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6191 - val_loss: 1.6178\n",
      "Epoch 36/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6181 - val_loss: 1.6175\n",
      "Epoch 37/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6177 - val_loss: 1.6174\n",
      "Epoch 38/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6173 - val_loss: 1.6172\n",
      "Epoch 39/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6169 - val_loss: 1.6171\n",
      "Epoch 40/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6163 - val_loss: 1.6170\n",
      "Epoch 41/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6161 - val_loss: 1.6170\n",
      "Epoch 42/100\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 1.6160 - val_loss: 1.6168\n",
      "Epoch 43/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6159 - val_loss: 1.6168\n",
      "Epoch 44/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6159 - val_loss: 1.6167\n",
      "Epoch 45/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6167\n",
      "Epoch 46/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6167\n",
      "Epoch 47/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6167\n",
      "Epoch 48/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6167\n",
      "Epoch 49/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6166\n",
      "Epoch 50/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6158 - val_loss: 1.6166\n",
      "Epoch 51/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6166\n",
      "Epoch 52/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6166\n",
      "Epoch 53/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6166\n",
      "Epoch 54/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6166\n",
      "Epoch 55/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6166\n",
      "Epoch 56/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6166\n",
      "Epoch 57/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6166\n",
      "Epoch 58/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6166\n",
      "Epoch 59/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6166\n",
      "Epoch 60/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 61/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 62/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 63/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 64/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 65/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 66/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 67/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 68/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 69/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 70/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 71/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 72/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 73/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 74/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 75/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 76/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 77/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 78/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 79/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 80/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 82/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 83/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 84/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 85/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 86/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 87/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 88/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 89/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 90/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 91/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 92/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 93/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 94/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 95/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 96/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 97/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 98/100\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 99/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Epoch 100/100\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 1.6157 - val_loss: 1.6165\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_154 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_112 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_113 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "dropout_114 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_115 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_116 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_117 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 64)                192       \n",
      "=================================================================\n",
      "Total params: 17,156\n",
      "Trainable params: 17,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "101/101 [==============================] - 1s 3ms/step - loss: 4.8011 - val_loss: 3.4824\n",
      "Epoch 2/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 3.0220 - val_loss: 2.5025\n",
      "Epoch 3/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 2.3420 - val_loss: 2.0426\n",
      "Epoch 4/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.9843 - val_loss: 1.7750\n",
      "Epoch 5/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.7739 - val_loss: 1.6145\n",
      "Epoch 6/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.6280 - val_loss: 1.4970\n",
      "Epoch 7/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.5298 - val_loss: 1.4139\n",
      "Epoch 8/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.4533 - val_loss: 1.3539\n",
      "Epoch 9/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.4002 - val_loss: 1.3054\n",
      "Epoch 10/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.3529 - val_loss: 1.2678\n",
      "Epoch 11/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.3180 - val_loss: 1.2362\n",
      "Epoch 12/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2906 - val_loss: 1.2100\n",
      "Epoch 13/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2582 - val_loss: 1.1889\n",
      "Epoch 14/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2346 - val_loss: 1.1705\n",
      "Epoch 15/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.2148 - val_loss: 1.1539\n",
      "Epoch 16/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1973 - val_loss: 1.1399\n",
      "Epoch 17/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1827 - val_loss: 1.1272\n",
      "Epoch 18/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1650 - val_loss: 1.1162\n",
      "Epoch 19/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1544 - val_loss: 1.1063\n",
      "Epoch 20/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1412 - val_loss: 1.0972\n",
      "Epoch 21/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1315 - val_loss: 1.0889\n",
      "Epoch 22/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1253 - val_loss: 1.0811\n",
      "Epoch 23/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1137 - val_loss: 1.0744\n",
      "Epoch 24/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.1051 - val_loss: 1.0681\n",
      "Epoch 25/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0989 - val_loss: 1.0622\n",
      "Epoch 26/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0937 - val_loss: 1.0566\n",
      "Epoch 27/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0862 - val_loss: 1.0514\n",
      "Epoch 28/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0807 - val_loss: 1.0466\n",
      "Epoch 29/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0735 - val_loss: 1.0420\n",
      "Epoch 30/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0687 - val_loss: 1.0378\n",
      "Epoch 31/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0635 - val_loss: 1.0338\n",
      "Epoch 32/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0586 - val_loss: 1.0300\n",
      "Epoch 33/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0522 - val_loss: 1.0266\n",
      "Epoch 34/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0500 - val_loss: 1.0232\n",
      "Epoch 35/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0459 - val_loss: 1.0200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0404 - val_loss: 1.0170\n",
      "Epoch 37/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0377 - val_loss: 1.0142\n",
      "Epoch 38/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0338 - val_loss: 1.0115\n",
      "Epoch 39/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0313 - val_loss: 1.0089\n",
      "Epoch 40/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0288 - val_loss: 1.0065\n",
      "Epoch 41/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0258 - val_loss: 1.0042\n",
      "Epoch 42/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0224 - val_loss: 1.0020\n",
      "Epoch 43/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0199 - val_loss: 0.9999\n",
      "Epoch 44/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0177 - val_loss: 0.9979\n",
      "Epoch 45/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0155 - val_loss: 0.9960\n",
      "Epoch 46/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0132 - val_loss: 0.9941\n",
      "Epoch 47/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0112 - val_loss: 0.9924\n",
      "Epoch 48/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0091 - val_loss: 0.9907\n",
      "Epoch 49/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0068 - val_loss: 0.9892\n",
      "Epoch 50/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0049 - val_loss: 0.9877\n",
      "Epoch 51/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0030 - val_loss: 0.9862\n",
      "Epoch 52/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 1.0014 - val_loss: 0.9849\n",
      "Epoch 53/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9836\n",
      "Epoch 54/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 0.9823\n",
      "Epoch 55/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9974 - val_loss: 0.9811\n",
      "Epoch 56/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9958 - val_loss: 0.9800\n",
      "Epoch 57/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9947 - val_loss: 0.9789\n",
      "Epoch 58/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9936 - val_loss: 0.9778\n",
      "Epoch 59/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9922 - val_loss: 0.9768\n",
      "Epoch 60/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9912 - val_loss: 0.9759\n",
      "Epoch 61/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9902 - val_loss: 0.9750\n",
      "Epoch 62/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9892 - val_loss: 0.9741\n",
      "Epoch 63/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9882 - val_loss: 0.9733\n",
      "Epoch 64/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9873 - val_loss: 0.9725\n",
      "Epoch 65/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9863 - val_loss: 0.9717\n",
      "Epoch 66/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9855 - val_loss: 0.9710\n",
      "Epoch 67/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9848 - val_loss: 0.9703\n",
      "Epoch 68/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9840 - val_loss: 0.9696\n",
      "Epoch 69/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9834 - val_loss: 0.9690\n",
      "Epoch 70/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9825 - val_loss: 0.9684\n",
      "Epoch 71/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9820 - val_loss: 0.9679\n",
      "Epoch 72/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9814 - val_loss: 0.9673\n",
      "Epoch 73/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9808 - val_loss: 0.9668\n",
      "Epoch 74/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9803 - val_loss: 0.9663\n",
      "Epoch 75/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9797 - val_loss: 0.9658\n",
      "Epoch 76/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9792 - val_loss: 0.9654\n",
      "Epoch 77/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9787 - val_loss: 0.9650\n",
      "Epoch 78/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9783 - val_loss: 0.9645\n",
      "Epoch 79/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9779 - val_loss: 0.9642\n",
      "Epoch 80/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9775 - val_loss: 0.9638\n",
      "Epoch 81/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9771 - val_loss: 0.9634\n",
      "Epoch 82/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9768 - val_loss: 0.9631\n",
      "Epoch 83/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9764 - val_loss: 0.9628\n",
      "Epoch 84/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9761 - val_loss: 0.9625\n",
      "Epoch 85/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9758 - val_loss: 0.9622\n",
      "Epoch 86/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9755 - val_loss: 0.9619\n",
      "Epoch 87/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9752 - val_loss: 0.9617\n",
      "Epoch 88/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9749 - val_loss: 0.9614\n",
      "Epoch 89/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9746 - val_loss: 0.9612\n",
      "Epoch 90/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9744 - val_loss: 0.9610\n",
      "Epoch 91/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9742 - val_loss: 0.9608\n",
      "Epoch 92/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9740 - val_loss: 0.9606\n",
      "Epoch 93/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9738 - val_loss: 0.9604\n",
      "Epoch 94/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9736 - val_loss: 0.9602\n",
      "Epoch 95/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9734 - val_loss: 0.9600\n",
      "Epoch 96/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9733 - val_loss: 0.9599\n",
      "Epoch 97/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9731 - val_loss: 0.9597\n",
      "Epoch 98/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9729 - val_loss: 0.9596\n",
      "Epoch 99/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9728 - val_loss: 0.9594\n",
      "Epoch 100/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9726 - val_loss: 0.9593\n",
      "Epoch 101/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9725 - val_loss: 0.9592\n",
      "Epoch 102/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9724 - val_loss: 0.9591\n",
      "Epoch 103/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9723 - val_loss: 0.9590\n",
      "Epoch 104/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9722 - val_loss: 0.9589\n",
      "Epoch 105/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9721 - val_loss: 0.9588\n",
      "Epoch 106/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9720 - val_loss: 0.9587\n",
      "Epoch 107/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9719 - val_loss: 0.9586\n",
      "Epoch 108/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9718 - val_loss: 0.9585\n",
      "Epoch 109/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9717 - val_loss: 0.9584\n",
      "Epoch 110/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9716 - val_loss: 0.9584\n",
      "Epoch 111/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9716 - val_loss: 0.9583\n",
      "Epoch 112/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9715 - val_loss: 0.9582\n",
      "Epoch 113/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9714 - val_loss: 0.9582\n",
      "Epoch 114/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9714 - val_loss: 0.9581\n",
      "Epoch 115/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9713 - val_loss: 0.9580\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9712 - val_loss: 0.9580\n",
      "Epoch 117/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9712 - val_loss: 0.9579\n",
      "Epoch 118/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9711 - val_loss: 0.9579\n",
      "Epoch 119/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9711 - val_loss: 0.9579\n",
      "Epoch 120/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9710 - val_loss: 0.9578\n",
      "Epoch 121/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9710 - val_loss: 0.9578\n",
      "Epoch 122/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9710 - val_loss: 0.9577\n",
      "Epoch 123/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9709 - val_loss: 0.9577\n",
      "Epoch 124/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9709 - val_loss: 0.9577\n",
      "Epoch 125/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9708 - val_loss: 0.9576\n",
      "Epoch 126/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9708 - val_loss: 0.9576\n",
      "Epoch 127/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9708 - val_loss: 0.9576\n",
      "Epoch 128/150\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 0.9708 - val_loss: 0.9575\n",
      "Epoch 129/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9707 - val_loss: 0.9575\n",
      "Epoch 130/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9707 - val_loss: 0.9575\n",
      "Epoch 131/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9707 - val_loss: 0.9575\n",
      "Epoch 132/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9706 - val_loss: 0.9574\n",
      "Epoch 133/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9706 - val_loss: 0.9574\n",
      "Epoch 134/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9706 - val_loss: 0.9574\n",
      "Epoch 135/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9706 - val_loss: 0.9574\n",
      "Epoch 136/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9706 - val_loss: 0.9574\n",
      "Epoch 137/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9705 - val_loss: 0.9573\n",
      "Epoch 138/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9705 - val_loss: 0.9573\n",
      "Epoch 139/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9705 - val_loss: 0.9573\n",
      "Epoch 140/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9705 - val_loss: 0.9573\n",
      "Epoch 141/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9705 - val_loss: 0.9573\n",
      "Epoch 142/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9705 - val_loss: 0.9573\n",
      "Epoch 143/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9704 - val_loss: 0.9573\n",
      "Epoch 144/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9704 - val_loss: 0.9573\n",
      "Epoch 145/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9704 - val_loss: 0.9572\n",
      "Epoch 146/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9704 - val_loss: 0.9572\n",
      "Epoch 147/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9704 - val_loss: 0.9572\n",
      "Epoch 148/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9704 - val_loss: 0.9572\n",
      "Epoch 149/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9704 - val_loss: 0.9572\n",
      "Epoch 150/150\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 0.9704 - val_loss: 0.9572\n",
      "Model: \"model_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_30 (InputLayer)        [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 1280)              83200     \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_29 (TFOpLam (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_29 (TFOpLambda)  (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_29 (TFOpL (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_29 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_29 (TFO ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_29 (AddLoss)        ()                        0         \n",
      "=================================================================\n",
      "Total params: 87,360\n",
      "Trainable params: 87,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "107/107 [==============================] - 1s 3ms/step - loss: 13.6798 - val_loss: 7.0457\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 5.1603 - val_loss: 3.1293\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 3.0304 - val_loss: 2.2638\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 2.4418 - val_loss: 1.9600\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 2.1763 - val_loss: 1.8284\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 2.0267 - val_loss: 1.7535\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.9342 - val_loss: 1.7070\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.8606 - val_loss: 1.6788\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.8112 - val_loss: 1.6622\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.7737 - val_loss: 1.6517\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.7457 - val_loss: 1.6442\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.7216 - val_loss: 1.6404\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.7035 - val_loss: 1.6368\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6868 - val_loss: 1.6342\n",
      "Epoch 15/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6750 - val_loss: 1.6322\n",
      "Epoch 16/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6662 - val_loss: 1.6310\n",
      "Epoch 17/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6588 - val_loss: 1.6298\n",
      "Epoch 18/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6525 - val_loss: 1.6291\n",
      "Epoch 19/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6475 - val_loss: 1.6284\n",
      "Epoch 20/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6431 - val_loss: 1.6279\n",
      "Epoch 21/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6396 - val_loss: 1.6274\n",
      "Epoch 22/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.6376 - val_loss: 1.6271\n",
      "Epoch 23/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6340 - val_loss: 1.6267\n",
      "Epoch 24/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6311 - val_loss: 1.6264\n",
      "Epoch 25/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.6294 - val_loss: 1.6260\n",
      "Epoch 26/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.6279 - val_loss: 1.6259\n",
      "Epoch 27/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.6269 - val_loss: 1.6255\n",
      "Epoch 28/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6258 - val_loss: 1.6254\n",
      "Epoch 29/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.6251 - val_loss: 1.6252\n",
      "Epoch 30/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.6246 - val_loss: 1.6251\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 3ms/step - loss: 1.6243 - val_loss: 1.6249\n",
      "Epoch 32/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6240 - val_loss: 1.6248\n",
      "Epoch 33/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6238 - val_loss: 1.6247\n",
      "Epoch 34/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6236 - val_loss: 1.6246\n",
      "Epoch 35/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6235 - val_loss: 1.6245\n",
      "Epoch 36/100\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.623 - 0s 2ms/step - loss: 1.6234 - val_loss: 1.6245\n",
      "Epoch 37/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6233 - val_loss: 1.6244\n",
      "Epoch 38/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6232 - val_loss: 1.6243\n",
      "Epoch 39/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6232 - val_loss: 1.6243\n",
      "Epoch 40/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6231 - val_loss: 1.6242\n",
      "Epoch 41/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6231 - val_loss: 1.6242\n",
      "Epoch 42/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6231 - val_loss: 1.6242\n",
      "Epoch 43/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6231 - val_loss: 1.6241\n",
      "Epoch 44/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6241\n",
      "Epoch 45/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6241\n",
      "Epoch 46/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6240\n",
      "Epoch 47/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6240\n",
      "Epoch 48/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6240\n",
      "Epoch 49/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6240\n",
      "Epoch 50/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6240\n",
      "Epoch 51/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6240\n",
      "Epoch 52/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6240\n",
      "Epoch 53/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6240\n",
      "Epoch 54/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 55/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 56/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 57/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 58/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 59/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 60/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 61/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 62/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 63/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 64/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 65/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 66/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 67/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 68/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 69/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 70/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 71/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 72/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 73/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 74/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 75/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 76/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 77/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 78/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 79/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 80/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 81/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 82/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 83/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 84/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 85/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 86/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 87/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 88/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 89/100\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 90/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 91/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 92/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 93/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 94/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 95/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 96/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 97/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 98/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 99/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "Epoch 100/100\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 1.6230 - val_loss: 1.6239\n",
      "第 pendigits 個資料處理中....\n",
      "\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_165 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_120 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_121 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dropout_122 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_123 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_124 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_125 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_126 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_127 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 16)                48        \n",
      "=================================================================\n",
      "Total params: 9,140\n",
      "Trainable params: 9,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 1s 3ms/step - loss: 2.1014 - val_loss: 1.7502\n",
      "Epoch 2/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.5700 - val_loss: 1.4573\n",
      "Epoch 3/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3742 - val_loss: 1.3225\n",
      "Epoch 4/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2771 - val_loss: 1.2506\n",
      "Epoch 5/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2227 - val_loss: 1.2069\n",
      "Epoch 6/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1867 - val_loss: 1.1775\n",
      "Epoch 7/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1600 - val_loss: 1.1563\n",
      "Epoch 8/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1423 - val_loss: 1.1397\n",
      "Epoch 9/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1249 - val_loss: 1.1267\n",
      "Epoch 10/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1133 - val_loss: 1.1160\n",
      "Epoch 11/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1038 - val_loss: 1.1069\n",
      "Epoch 12/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0949 - val_loss: 1.0990\n",
      "Epoch 13/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0859 - val_loss: 1.0921\n",
      "Epoch 14/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0787 - val_loss: 1.0861\n",
      "Epoch 15/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0731 - val_loss: 1.0807\n",
      "Epoch 16/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0677 - val_loss: 1.0759\n",
      "Epoch 17/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0611 - val_loss: 1.0715\n",
      "Epoch 18/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0575 - val_loss: 1.0676\n",
      "Epoch 19/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0525 - val_loss: 1.0640\n",
      "Epoch 20/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0491 - val_loss: 1.0607\n",
      "Epoch 21/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0451 - val_loss: 1.0577\n",
      "Epoch 22/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0420 - val_loss: 1.0550\n",
      "Epoch 23/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0391 - val_loss: 1.0525\n",
      "Epoch 24/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0363 - val_loss: 1.0502\n",
      "Epoch 25/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0337 - val_loss: 1.0480\n",
      "Epoch 26/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0317 - val_loss: 1.0460\n",
      "Epoch 27/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0293 - val_loss: 1.0442\n",
      "Epoch 28/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0271 - val_loss: 1.0424\n",
      "Epoch 29/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0253 - val_loss: 1.0408\n",
      "Epoch 30/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0232 - val_loss: 1.0393\n",
      "Epoch 31/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0220 - val_loss: 1.0379\n",
      "Epoch 32/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0199 - val_loss: 1.0366\n",
      "Epoch 33/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0185 - val_loss: 1.0354\n",
      "Epoch 34/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0177 - val_loss: 1.0342\n",
      "Epoch 35/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0162 - val_loss: 1.0332\n",
      "Epoch 36/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0153 - val_loss: 1.0322\n",
      "Epoch 37/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0141 - val_loss: 1.0312\n",
      "Epoch 38/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0130 - val_loss: 1.0304\n",
      "Epoch 39/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0122 - val_loss: 1.0295\n",
      "Epoch 40/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0113 - val_loss: 1.0288\n",
      "Epoch 41/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0106 - val_loss: 1.0281\n",
      "Epoch 42/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0098 - val_loss: 1.0273\n",
      "Epoch 43/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0091 - val_loss: 1.0267\n",
      "Epoch 44/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0083 - val_loss: 1.0261\n",
      "Epoch 45/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0077 - val_loss: 1.0255\n",
      "Epoch 46/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0070 - val_loss: 1.0250\n",
      "Epoch 47/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0065 - val_loss: 1.0245\n",
      "Epoch 48/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0059 - val_loss: 1.0240\n",
      "Epoch 49/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0056 - val_loss: 1.0236\n",
      "Epoch 50/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0051 - val_loss: 1.0232\n",
      "Epoch 51/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0047 - val_loss: 1.0228\n",
      "Epoch 52/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0043 - val_loss: 1.0224\n",
      "Epoch 53/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0040 - val_loss: 1.0221\n",
      "Epoch 54/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0036 - val_loss: 1.0217\n",
      "Epoch 55/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0033 - val_loss: 1.0214\n",
      "Epoch 56/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0030 - val_loss: 1.0212\n",
      "Epoch 57/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0027 - val_loss: 1.0209\n",
      "Epoch 58/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0024 - val_loss: 1.0206\n",
      "Epoch 59/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0022 - val_loss: 1.0204\n",
      "Epoch 60/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0020 - val_loss: 1.0202\n",
      "Epoch 61/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0017 - val_loss: 1.0200\n",
      "Epoch 62/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0015 - val_loss: 1.0198\n",
      "Epoch 63/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0013 - val_loss: 1.0196\n",
      "Epoch 64/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0012 - val_loss: 1.0195\n",
      "Epoch 65/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0010 - val_loss: 1.0193\n",
      "Epoch 66/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0008 - val_loss: 1.0192\n",
      "Epoch 67/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0007 - val_loss: 1.0190\n",
      "Epoch 68/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0006 - val_loss: 1.0189\n",
      "Epoch 69/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0004 - val_loss: 1.0188\n",
      "Epoch 70/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0003 - val_loss: 1.0186\n",
      "Epoch 71/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0185\n",
      "Epoch 72/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 1.0184\n",
      "Epoch 73/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0183\n",
      "Epoch 74/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 1.0182\n",
      "Epoch 75/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 1.0182\n",
      "Epoch 76/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0181\n",
      "Epoch 77/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0180\n",
      "Epoch 78/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0179\n",
      "Epoch 79/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 1.0179\n",
      "Epoch 80/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 1.0178\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 1.0177\n",
      "Epoch 82/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 1.0177\n",
      "Epoch 83/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 1.0176\n",
      "Epoch 84/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0176\n",
      "Epoch 85/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0175\n",
      "Epoch 86/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 1.0175\n",
      "Epoch 87/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 1.0175\n",
      "Epoch 88/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 1.0174\n",
      "Epoch 89/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0174\n",
      "Epoch 90/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0173\n",
      "Epoch 91/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0173\n",
      "Epoch 92/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 1.0173\n",
      "Epoch 93/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 1.0173\n",
      "Epoch 94/150\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 0.9989 - val_loss: 1.0172\n",
      "Epoch 95/150\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 0.9988 - val_loss: 1.0172\n",
      "Epoch 96/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 1.0172\n",
      "Epoch 97/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 1.0172\n",
      "Epoch 98/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 1.0171\n",
      "Epoch 99/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0171\n",
      "Epoch 100/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0171\n",
      "Epoch 101/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0171\n",
      "Epoch 102/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0170\n",
      "Epoch 103/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0170\n",
      "Epoch 104/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 1.0170\n",
      "Epoch 105/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 1.0170\n",
      "Epoch 106/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 1.0170\n",
      "Epoch 107/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 1.0170\n",
      "Epoch 108/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 1.0169\n",
      "Epoch 109/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 1.0169\n",
      "Epoch 110/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 1.0169\n",
      "Epoch 111/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 1.0169\n",
      "Epoch 112/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 1.0169\n",
      "Epoch 113/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 1.0169\n",
      "Epoch 114/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 1.0169\n",
      "Epoch 115/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 1.0169\n",
      "Epoch 116/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 1.0169\n",
      "Epoch 117/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 1.0168\n",
      "Epoch 118/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 1.0168\n",
      "Epoch 119/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 1.0168\n",
      "Epoch 120/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0168\n",
      "Epoch 121/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0168\n",
      "Epoch 122/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0168\n",
      "Epoch 123/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0168\n",
      "Epoch 124/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0168\n",
      "Epoch 125/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0168\n",
      "Epoch 126/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0168\n",
      "Epoch 127/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0168\n",
      "Epoch 128/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0168\n",
      "Epoch 129/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0168\n",
      "Epoch 130/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0168\n",
      "Epoch 131/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0167\n",
      "Epoch 132/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0167\n",
      "Epoch 133/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0167\n",
      "Epoch 134/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0167\n",
      "Epoch 135/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0167\n",
      "Epoch 136/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0167\n",
      "Epoch 137/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0167\n",
      "Epoch 138/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0167\n",
      "Epoch 139/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0167\n",
      "Epoch 140/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0167\n",
      "Epoch 141/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0167\n",
      "Epoch 142/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0167\n",
      "Epoch 143/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0167\n",
      "Epoch 144/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0167\n",
      "Epoch 145/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0167\n",
      "Epoch 146/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0167\n",
      "Epoch 147/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0167\n",
      "Epoch 148/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0167\n",
      "Epoch 149/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0167\n",
      "Epoch 150/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0167\n",
      "Model: \"model_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_32 (InputLayer)        [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 320)               5440      \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_31 (TFOpLam (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_31 (TFOpLambda)  (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_31 (TFOpL (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_31 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_31 (TFO ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_31 (AddLoss)        ()                        0         \n",
      "=================================================================\n",
      "Total params: 5,712\n",
      "Trainable params: 5,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 1ms/step - loss: 3.2433 - val_loss: 1.6639\n",
      "Epoch 2/100\n",
      "141/141 [==============================] - 0s 790us/step - loss: 1.1043 - val_loss: 0.8119\n",
      "Epoch 3/100\n",
      "141/141 [==============================] - 0s 823us/step - loss: 0.6742 - val_loss: 0.5993\n",
      "Epoch 4/100\n",
      "141/141 [==============================] - 0s 813us/step - loss: 0.5469 - val_loss: 0.5150\n",
      "Epoch 5/100\n",
      "141/141 [==============================] - 0s 868us/step - loss: 0.4888 - val_loss: 0.4730\n",
      "Epoch 6/100\n",
      "141/141 [==============================] - 0s 805us/step - loss: 0.4596 - val_loss: 0.4517\n",
      "Epoch 7/100\n",
      "141/141 [==============================] - 0s 836us/step - loss: 0.4446 - val_loss: 0.4407\n",
      "Epoch 8/100\n",
      "141/141 [==============================] - 0s 801us/step - loss: 0.4369 - val_loss: 0.4351\n",
      "Epoch 9/100\n",
      "141/141 [==============================] - 0s 850us/step - loss: 0.4329 - val_loss: 0.4320\n",
      "Epoch 10/100\n",
      "141/141 [==============================] - 0s 859us/step - loss: 0.4307 - val_loss: 0.4303\n",
      "Epoch 11/100\n",
      "141/141 [==============================] - 0s 844us/step - loss: 0.4294 - val_loss: 0.4292\n",
      "Epoch 12/100\n",
      "141/141 [==============================] - 0s 914us/step - loss: 0.4287 - val_loss: 0.4285\n",
      "Epoch 13/100\n",
      "141/141 [==============================] - 0s 925us/step - loss: 0.4282 - val_loss: 0.4281\n",
      "Epoch 14/100\n",
      "141/141 [==============================] - 0s 910us/step - loss: 0.4278 - val_loss: 0.4278\n",
      "Epoch 15/100\n",
      "141/141 [==============================] - 0s 930us/step - loss: 0.4276 - val_loss: 0.4275\n",
      "Epoch 16/100\n",
      "141/141 [==============================] - 0s 941us/step - loss: 0.4274 - val_loss: 0.4274\n",
      "Epoch 17/100\n",
      "141/141 [==============================] - 0s 946us/step - loss: 0.4273 - val_loss: 0.4273\n",
      "Epoch 18/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4272 - val_loss: 0.4272\n",
      "Epoch 19/100\n",
      "141/141 [==============================] - 0s 883us/step - loss: 0.4271 - val_loss: 0.4271\n",
      "Epoch 20/100\n",
      "141/141 [==============================] - 0s 988us/step - loss: 0.4271 - val_loss: 0.4271\n",
      "Epoch 21/100\n",
      "141/141 [==============================] - 0s 959us/step - loss: 0.4270 - val_loss: 0.4270\n",
      "Epoch 22/100\n",
      "141/141 [==============================] - 0s 958us/step - loss: 0.4270 - val_loss: 0.4270\n",
      "Epoch 23/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4270 - val_loss: 0.4270\n",
      "Epoch 24/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4269 - val_loss: 0.4270\n",
      "Epoch 25/100\n",
      "141/141 [==============================] - 0s 957us/step - loss: 0.4269 - val_loss: 0.4269\n",
      "Epoch 26/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4269 - val_loss: 0.4269\n",
      "Epoch 27/100\n",
      "141/141 [==============================] - 0s 974us/step - loss: 0.4269 - val_loss: 0.4269\n",
      "Epoch 28/100\n",
      "141/141 [==============================] - 0s 902us/step - loss: 0.4269 - val_loss: 0.4269\n",
      "Epoch 29/100\n",
      "141/141 [==============================] - 0s 854us/step - loss: 0.4269 - val_loss: 0.4269\n",
      "Epoch 30/100\n",
      "141/141 [==============================] - 0s 966us/step - loss: 0.4269 - val_loss: 0.4269\n",
      "Epoch 31/100\n",
      "141/141 [==============================] - 0s 968us/step - loss: 0.4269 - val_loss: 0.4269\n",
      "Epoch 32/100\n",
      "141/141 [==============================] - 0s 978us/step - loss: 0.4269 - val_loss: 0.4269\n",
      "Epoch 33/100\n",
      "141/141 [==============================] - 0s 944us/step - loss: 0.4269 - val_loss: 0.4269\n",
      "Epoch 34/100\n",
      "141/141 [==============================] - 0s 954us/step - loss: 0.4268 - val_loss: 0.4269\n",
      "Epoch 35/100\n",
      "141/141 [==============================] - 0s 996us/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 36/100\n",
      "141/141 [==============================] - 0s 905us/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 37/100\n",
      "141/141 [==============================] - 0s 993us/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 38/100\n",
      "141/141 [==============================] - 0s 987us/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 39/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 40/100\n",
      "141/141 [==============================] - 0s 935us/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 41/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 42/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 43/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 44/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 45/100\n",
      "141/141 [==============================] - 0s 968us/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 46/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 47/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 48/100\n",
      "141/141 [==============================] - 0s 954us/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 49/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 50/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 51/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 52/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 53/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 54/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 55/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 56/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 57/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 58/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 59/100\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 60/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 61/100\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 62/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 63/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 64/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 65/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 66/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 67/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 68/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 69/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 70/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 71/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 72/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 73/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 74/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 75/100\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 76/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 77/100\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 78/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 79/100\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 80/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 82/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 83/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 84/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 85/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 86/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 87/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 88/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 89/100\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 90/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 91/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 92/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 93/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 94/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 95/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 96/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 97/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 98/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 99/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 100/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_176 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_128 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_129 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dropout_130 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_131 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_132 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_133 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_134 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_135 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 16)                48        \n",
      "=================================================================\n",
      "Total params: 9,140\n",
      "Trainable params: 9,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "133/133 [==============================] - 1s 3ms/step - loss: 2.0982 - val_loss: 1.7398\n",
      "Epoch 2/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.5737 - val_loss: 1.4604\n",
      "Epoch 3/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.3831 - val_loss: 1.3296\n",
      "Epoch 4/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.2888 - val_loss: 1.2583\n",
      "Epoch 5/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.2329 - val_loss: 1.2137\n",
      "Epoch 6/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.1938 - val_loss: 1.1831\n",
      "Epoch 7/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.1664 - val_loss: 1.1604\n",
      "Epoch 8/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.1477 - val_loss: 1.1433\n",
      "Epoch 9/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.1312 - val_loss: 1.1287\n",
      "Epoch 10/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.1185 - val_loss: 1.1173\n",
      "Epoch 11/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 1.1055 - val_loss: 1.1074\n",
      "Epoch 12/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0960 - val_loss: 1.0991\n",
      "Epoch 13/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0885 - val_loss: 1.0918\n",
      "Epoch 14/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0806 - val_loss: 1.0855\n",
      "Epoch 15/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0742 - val_loss: 1.0797\n",
      "Epoch 16/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0691 - val_loss: 1.0747\n",
      "Epoch 17/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0627 - val_loss: 1.0700\n",
      "Epoch 18/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0574 - val_loss: 1.0660\n",
      "Epoch 19/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0538 - val_loss: 1.0622\n",
      "Epoch 20/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0505 - val_loss: 1.0588\n",
      "Epoch 21/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0457 - val_loss: 1.0556\n",
      "Epoch 22/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0425 - val_loss: 1.0528\n",
      "Epoch 23/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0394 - val_loss: 1.0501\n",
      "Epoch 24/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0364 - val_loss: 1.0477\n",
      "Epoch 25/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0342 - val_loss: 1.0454\n",
      "Epoch 26/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0315 - val_loss: 1.0434\n",
      "Epoch 27/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0292 - val_loss: 1.0414\n",
      "Epoch 28/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0279 - val_loss: 1.0396\n",
      "Epoch 29/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0257 - val_loss: 1.0379\n",
      "Epoch 30/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0236 - val_loss: 1.0363\n",
      "Epoch 31/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0220 - val_loss: 1.0349\n",
      "Epoch 32/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0207 - val_loss: 1.0335\n",
      "Epoch 33/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0188 - val_loss: 1.0323\n",
      "Epoch 34/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0176 - val_loss: 1.0311\n",
      "Epoch 35/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0162 - val_loss: 1.0300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0150 - val_loss: 1.0290\n",
      "Epoch 37/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0143 - val_loss: 1.0280\n",
      "Epoch 38/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0133 - val_loss: 1.0271\n",
      "Epoch 39/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0122 - val_loss: 1.0263\n",
      "Epoch 40/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0115 - val_loss: 1.0254\n",
      "Epoch 41/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0106 - val_loss: 1.0247\n",
      "Epoch 42/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0099 - val_loss: 1.0240\n",
      "Epoch 43/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0090 - val_loss: 1.0234\n",
      "Epoch 44/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0086 - val_loss: 1.0227\n",
      "Epoch 45/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0080 - val_loss: 1.0221\n",
      "Epoch 46/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0073 - val_loss: 1.0215\n",
      "Epoch 47/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0067 - val_loss: 1.0210\n",
      "Epoch 48/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0062 - val_loss: 1.0205\n",
      "Epoch 49/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 1.0057 - val_loss: 1.0201\n",
      "Epoch 50/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0052 - val_loss: 1.0197\n",
      "Epoch 51/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0049 - val_loss: 1.0193\n",
      "Epoch 52/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0045 - val_loss: 1.0189\n",
      "Epoch 53/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0041 - val_loss: 1.0186\n",
      "Epoch 54/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0037 - val_loss: 1.0182\n",
      "Epoch 55/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0035 - val_loss: 1.0179\n",
      "Epoch 56/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0032 - val_loss: 1.0176\n",
      "Epoch 57/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0029 - val_loss: 1.0174\n",
      "Epoch 58/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0027 - val_loss: 1.0171\n",
      "Epoch 59/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0024 - val_loss: 1.0169\n",
      "Epoch 60/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0022 - val_loss: 1.0167\n",
      "Epoch 61/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0020 - val_loss: 1.0164\n",
      "Epoch 62/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0018 - val_loss: 1.0163\n",
      "Epoch 63/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0016 - val_loss: 1.0161\n",
      "Epoch 64/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0014 - val_loss: 1.0159\n",
      "Epoch 65/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0012 - val_loss: 1.0157\n",
      "Epoch 66/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0011 - val_loss: 1.0156\n",
      "Epoch 67/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0009 - val_loss: 1.0154\n",
      "Epoch 68/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0008 - val_loss: 1.0153\n",
      "Epoch 69/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0007 - val_loss: 1.0152\n",
      "Epoch 70/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0006 - val_loss: 1.0151\n",
      "Epoch 71/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0005 - val_loss: 1.0150\n",
      "Epoch 72/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0004 - val_loss: 1.0148\n",
      "Epoch 73/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0003 - val_loss: 1.0147\n",
      "Epoch 74/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0147\n",
      "Epoch 75/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 1.0146\n",
      "Epoch 76/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0145\n",
      "Epoch 77/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 1.0144\n",
      "Epoch 78/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 1.0143\n",
      "Epoch 79/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 1.0143\n",
      "Epoch 80/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 1.0142\n",
      "Epoch 81/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0141\n",
      "Epoch 82/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0141\n",
      "Epoch 83/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0140\n",
      "Epoch 84/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 1.0140\n",
      "Epoch 85/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 1.0139\n",
      "Epoch 86/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 1.0139\n",
      "Epoch 87/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 1.0139\n",
      "Epoch 88/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 1.0138\n",
      "Epoch 89/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 1.0138\n",
      "Epoch 90/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 1.0137\n",
      "Epoch 91/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 1.0137\n",
      "Epoch 92/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0137\n",
      "Epoch 93/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0136\n",
      "Epoch 94/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0136\n",
      "Epoch 95/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0136\n",
      "Epoch 96/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 1.0136\n",
      "Epoch 97/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 1.0135\n",
      "Epoch 98/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 1.0135\n",
      "Epoch 99/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 1.0135\n",
      "Epoch 100/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 1.0135\n",
      "Epoch 101/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0134\n",
      "Epoch 102/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0134\n",
      "Epoch 103/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0134\n",
      "Epoch 104/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0134\n",
      "Epoch 105/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0134\n",
      "Epoch 106/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0133\n",
      "Epoch 107/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 1.0133\n",
      "Epoch 108/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 1.0133\n",
      "Epoch 109/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 1.0133\n",
      "Epoch 110/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 1.0133\n",
      "Epoch 111/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 1.0133\n",
      "Epoch 112/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 1.0133\n",
      "Epoch 113/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 1.0133\n",
      "Epoch 114/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 1.0132\n",
      "Epoch 115/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 1.0132\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 1.0132\n",
      "Epoch 117/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 1.0132\n",
      "Epoch 118/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 1.0132\n",
      "Epoch 119/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 1.0132\n",
      "Epoch 120/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 1.0132\n",
      "Epoch 121/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 1.0132\n",
      "Epoch 122/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 1.0132\n",
      "Epoch 123/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 1.0132\n",
      "Epoch 124/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 1.0132\n",
      "Epoch 125/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 1.0132\n",
      "Epoch 126/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 1.0131\n",
      "Epoch 127/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 1.0131\n",
      "Epoch 128/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 1.0131\n",
      "Epoch 129/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 1.0131\n",
      "Epoch 130/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 1.0131\n",
      "Epoch 131/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 1.0131\n",
      "Epoch 132/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0131\n",
      "Epoch 133/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0131\n",
      "Epoch 134/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0131\n",
      "Epoch 135/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0131\n",
      "Epoch 136/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0131\n",
      "Epoch 137/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0131\n",
      "Epoch 138/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0131\n",
      "Epoch 139/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0131\n",
      "Epoch 140/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0131\n",
      "Epoch 141/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0131\n",
      "Epoch 142/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0131\n",
      "Epoch 143/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0131\n",
      "Epoch 144/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0131\n",
      "Epoch 145/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0130\n",
      "Epoch 146/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0130\n",
      "Epoch 147/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0130\n",
      "Epoch 148/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0130\n",
      "Epoch 149/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0130\n",
      "Epoch 150/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0130\n",
      "Model: \"model_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_34 (InputLayer)        [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 320)               5440      \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_33 (TFOpLam (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_33 (TFOpLambda)  (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_33 (TFOpL (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_33 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_33 (TFO ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_33 (AddLoss)        ()                        0         \n",
      "=================================================================\n",
      "Total params: 5,712\n",
      "Trainable params: 5,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 3.2940 - val_loss: 1.6841\n",
      "Epoch 2/100\n",
      "141/141 [==============================] - 0s 900us/step - loss: 1.1321 - val_loss: 0.8322\n",
      "Epoch 3/100\n",
      "141/141 [==============================] - 0s 786us/step - loss: 0.6876 - val_loss: 0.6116\n",
      "Epoch 4/100\n",
      "141/141 [==============================] - 0s 862us/step - loss: 0.5545 - val_loss: 0.5235\n",
      "Epoch 5/100\n",
      "141/141 [==============================] - 0s 834us/step - loss: 0.4937 - val_loss: 0.4775\n",
      "Epoch 6/100\n",
      "141/141 [==============================] - 0s 816us/step - loss: 0.4621 - val_loss: 0.4537\n",
      "Epoch 7/100\n",
      "141/141 [==============================] - 0s 924us/step - loss: 0.4456 - val_loss: 0.4414\n",
      "Epoch 8/100\n",
      "141/141 [==============================] - 0s 931us/step - loss: 0.4373 - val_loss: 0.4351\n",
      "Epoch 9/100\n",
      "141/141 [==============================] - 0s 906us/step - loss: 0.4329 - val_loss: 0.4316\n",
      "Epoch 10/100\n",
      "141/141 [==============================] - 0s 921us/step - loss: 0.4304 - val_loss: 0.4296\n",
      "Epoch 11/100\n",
      "141/141 [==============================] - 0s 868us/step - loss: 0.4290 - val_loss: 0.4285\n",
      "Epoch 12/100\n",
      "141/141 [==============================] - 0s 988us/step - loss: 0.4281 - val_loss: 0.4277\n",
      "Epoch 13/100\n",
      "141/141 [==============================] - 0s 986us/step - loss: 0.4276 - val_loss: 0.4273\n",
      "Epoch 14/100\n",
      "141/141 [==============================] - 0s 967us/step - loss: 0.4272 - val_loss: 0.4270\n",
      "Epoch 15/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4269 - val_loss: 0.4267\n",
      "Epoch 16/100\n",
      "141/141 [==============================] - 0s 979us/step - loss: 0.4268 - val_loss: 0.4266\n",
      "Epoch 17/100\n",
      "141/141 [==============================] - 0s 921us/step - loss: 0.4266 - val_loss: 0.4265\n",
      "Epoch 18/100\n",
      "141/141 [==============================] - 0s 946us/step - loss: 0.4265 - val_loss: 0.4264\n",
      "Epoch 19/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4264 - val_loss: 0.4263\n",
      "Epoch 20/100\n",
      "141/141 [==============================] - 0s 938us/step - loss: 0.4263 - val_loss: 0.4263\n",
      "Epoch 21/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4263 - val_loss: 0.4262\n",
      "Epoch 22/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4263 - val_loss: 0.4262\n",
      "Epoch 23/100\n",
      "141/141 [==============================] - 0s 984us/step - loss: 0.4262 - val_loss: 0.4262\n",
      "Epoch 24/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4262 - val_loss: 0.4262\n",
      "Epoch 25/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4262 - val_loss: 0.4262\n",
      "Epoch 26/100\n",
      "141/141 [==============================] - 0s 955us/step - loss: 0.4262 - val_loss: 0.4261\n",
      "Epoch 27/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4262 - val_loss: 0.4261\n",
      "Epoch 28/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 29/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 31/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 32/100\n",
      "141/141 [==============================] - 0s 989us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 33/100\n",
      "141/141 [==============================] - 0s 941us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 34/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 35/100\n",
      "141/141 [==============================] - 0s 976us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 36/100\n",
      "141/141 [==============================] - 0s 979us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 37/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 38/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 39/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 40/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 41/100\n",
      "141/141 [==============================] - 0s 946us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 42/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 43/100\n",
      "141/141 [==============================] - 0s 996us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 44/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 45/100\n",
      "141/141 [==============================] - 0s 954us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 46/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 47/100\n",
      "141/141 [==============================] - 0s 969us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 48/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 49/100\n",
      "141/141 [==============================] - 0s 921us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 50/100\n",
      "141/141 [==============================] - 0s 974us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 51/100\n",
      "141/141 [==============================] - 0s 972us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 52/100\n",
      "141/141 [==============================] - 0s 997us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 53/100\n",
      "141/141 [==============================] - 0s 976us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 54/100\n",
      "141/141 [==============================] - 0s 968us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 55/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 56/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 57/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 58/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 59/100\n",
      "141/141 [==============================] - 0s 1000us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 60/100\n",
      "141/141 [==============================] - 0s 963us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 61/100\n",
      "141/141 [==============================] - 0s 964us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 62/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 63/100\n",
      "141/141 [==============================] - 0s 955us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 64/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 65/100\n",
      "141/141 [==============================] - 0s 942us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 66/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 67/100\n",
      "141/141 [==============================] - 0s 979us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 68/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 69/100\n",
      "141/141 [==============================] - 0s 934us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 70/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 71/100\n",
      "141/141 [==============================] - 0s 938us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 72/100\n",
      "141/141 [==============================] - 0s 973us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 73/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 74/100\n",
      "141/141 [==============================] - 0s 981us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 75/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 76/100\n",
      "141/141 [==============================] - 0s 984us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 77/100\n",
      "141/141 [==============================] - 0s 979us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 78/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 79/100\n",
      "141/141 [==============================] - 0s 993us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 80/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 81/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 82/100\n",
      "141/141 [==============================] - 0s 983us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 83/100\n",
      "141/141 [==============================] - 0s 971us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 84/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 85/100\n",
      "141/141 [==============================] - 0s 967us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 86/100\n",
      "141/141 [==============================] - 0s 979us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 87/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 88/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 89/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 90/100\n",
      "141/141 [==============================] - 0s 954us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 91/100\n",
      "141/141 [==============================] - 0s 937us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 92/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 93/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 94/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 95/100\n",
      "141/141 [==============================] - 0s 964us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 96/100\n",
      "141/141 [==============================] - 0s 965us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 97/100\n",
      "141/141 [==============================] - 0s 996us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 98/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 99/100\n",
      "141/141 [==============================] - 0s 950us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 100/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_187 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_136 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_137 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dropout_138 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_139 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_140 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_141 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_142 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_143 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (None, 16)                48        \n",
      "=================================================================\n",
      "Total params: 9,140\n",
      "Trainable params: 9,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 1s 3ms/step - loss: 2.1092 - val_loss: 1.7285\n",
      "Epoch 2/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.5717 - val_loss: 1.4470\n",
      "Epoch 3/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3808 - val_loss: 1.3181\n",
      "Epoch 4/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2815 - val_loss: 1.2483\n",
      "Epoch 5/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2279 - val_loss: 1.2053\n",
      "Epoch 6/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1901 - val_loss: 1.1757\n",
      "Epoch 7/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1664 - val_loss: 1.1536\n",
      "Epoch 8/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1453 - val_loss: 1.1369\n",
      "Epoch 9/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1274 - val_loss: 1.1234\n",
      "Epoch 10/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1165 - val_loss: 1.1122\n",
      "Epoch 11/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1041 - val_loss: 1.1027\n",
      "Epoch 12/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0962 - val_loss: 1.0946\n",
      "Epoch 13/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0878 - val_loss: 1.0875\n",
      "Epoch 14/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0803 - val_loss: 1.0812\n",
      "Epoch 15/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0738 - val_loss: 1.0757\n",
      "Epoch 16/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0678 - val_loss: 1.0706\n",
      "Epoch 17/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0618 - val_loss: 1.0662\n",
      "Epoch 18/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0563 - val_loss: 1.0623\n",
      "Epoch 19/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0529 - val_loss: 1.0587\n",
      "Epoch 20/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0496 - val_loss: 1.0553\n",
      "Epoch 21/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0460 - val_loss: 1.0522\n",
      "Epoch 22/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0426 - val_loss: 1.0494\n",
      "Epoch 23/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0398 - val_loss: 1.0468\n",
      "Epoch 24/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0365 - val_loss: 1.0444\n",
      "Epoch 25/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0337 - val_loss: 1.0422\n",
      "Epoch 26/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0319 - val_loss: 1.0401\n",
      "Epoch 27/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0295 - val_loss: 1.0383\n",
      "Epoch 28/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0273 - val_loss: 1.0365\n",
      "Epoch 29/150\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 1.0254 - val_loss: 1.0349\n",
      "Epoch 30/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0237 - val_loss: 1.0334\n",
      "Epoch 31/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0220 - val_loss: 1.0319\n",
      "Epoch 32/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0203 - val_loss: 1.0306\n",
      "Epoch 33/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0190 - val_loss: 1.0293\n",
      "Epoch 34/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0176 - val_loss: 1.0281\n",
      "Epoch 35/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0167 - val_loss: 1.0271\n",
      "Epoch 36/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0152 - val_loss: 1.0261\n",
      "Epoch 37/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0143 - val_loss: 1.0251\n",
      "Epoch 38/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0133 - val_loss: 1.0242\n",
      "Epoch 39/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0125 - val_loss: 1.0234\n",
      "Epoch 40/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0116 - val_loss: 1.0226\n",
      "Epoch 41/150\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 1.0108 - val_loss: 1.0218\n",
      "Epoch 42/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0099 - val_loss: 1.0211\n",
      "Epoch 43/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0093 - val_loss: 1.0205\n",
      "Epoch 44/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0086 - val_loss: 1.0199\n",
      "Epoch 45/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0079 - val_loss: 1.0193\n",
      "Epoch 46/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0074 - val_loss: 1.0188\n",
      "Epoch 47/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0068 - val_loss: 1.0183\n",
      "Epoch 48/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0064 - val_loss: 1.0178\n",
      "Epoch 49/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0059 - val_loss: 1.0174\n",
      "Epoch 50/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0056 - val_loss: 1.0170\n",
      "Epoch 51/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0051 - val_loss: 1.0166\n",
      "Epoch 52/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0047 - val_loss: 1.0162\n",
      "Epoch 53/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0044 - val_loss: 1.0159\n",
      "Epoch 54/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0040 - val_loss: 1.0155\n",
      "Epoch 55/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0037 - val_loss: 1.0152\n",
      "Epoch 56/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0034 - val_loss: 1.0150\n",
      "Epoch 57/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0031 - val_loss: 1.0147\n",
      "Epoch 58/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0028 - val_loss: 1.0145\n",
      "Epoch 59/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0026 - val_loss: 1.0143\n",
      "Epoch 60/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0024 - val_loss: 1.0140\n",
      "Epoch 61/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0022 - val_loss: 1.0138\n",
      "Epoch 62/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0020 - val_loss: 1.0136\n",
      "Epoch 63/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0018 - val_loss: 1.0134\n",
      "Epoch 64/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0017 - val_loss: 1.0133\n",
      "Epoch 65/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0015 - val_loss: 1.0131\n",
      "Epoch 66/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0013 - val_loss: 1.0130\n",
      "Epoch 67/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0012 - val_loss: 1.0128\n",
      "Epoch 68/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0011 - val_loss: 1.0127\n",
      "Epoch 69/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0009 - val_loss: 1.0126\n",
      "Epoch 70/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0008 - val_loss: 1.0125\n",
      "Epoch 71/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0007 - val_loss: 1.0124\n",
      "Epoch 72/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0006 - val_loss: 1.0122\n",
      "Epoch 73/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0005 - val_loss: 1.0122\n",
      "Epoch 74/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0005 - val_loss: 1.0121\n",
      "Epoch 75/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0004 - val_loss: 1.0120\n",
      "Epoch 76/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0003 - val_loss: 1.0119\n",
      "Epoch 77/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0118\n",
      "Epoch 78/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 1.0118\n",
      "Epoch 79/150\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 1.0001 - val_loss: 1.0117\n",
      "Epoch 80/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0116\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0116\n",
      "Epoch 82/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 1.0115\n",
      "Epoch 83/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 1.0115\n",
      "Epoch 84/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 1.0114\n",
      "Epoch 85/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 1.0114\n",
      "Epoch 86/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0113\n",
      "Epoch 87/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0113\n",
      "Epoch 88/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0112\n",
      "Epoch 89/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0112\n",
      "Epoch 90/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0112\n",
      "Epoch 91/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 1.0111\n",
      "Epoch 92/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 1.0111\n",
      "Epoch 93/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 1.0111\n",
      "Epoch 94/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 1.0110\n",
      "Epoch 95/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 1.0110\n",
      "Epoch 96/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 1.0110\n",
      "Epoch 97/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 1.0110\n",
      "Epoch 98/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 1.0109\n",
      "Epoch 99/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 1.0109\n",
      "Epoch 100/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 1.0109\n",
      "Epoch 101/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 1.0109\n",
      "Epoch 102/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 1.0109\n",
      "Epoch 103/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 1.0108\n",
      "Epoch 104/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 1.0108\n",
      "Epoch 105/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 1.0108\n",
      "Epoch 106/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0108\n",
      "Epoch 107/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0108\n",
      "Epoch 108/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0108\n",
      "Epoch 109/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0108\n",
      "Epoch 110/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0107\n",
      "Epoch 111/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0107\n",
      "Epoch 112/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0107\n",
      "Epoch 113/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0107\n",
      "Epoch 114/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 1.0107\n",
      "Epoch 115/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 1.0107\n",
      "Epoch 116/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 1.0107\n",
      "Epoch 117/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 1.0107\n",
      "Epoch 118/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 1.0107\n",
      "Epoch 119/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 1.0106\n",
      "Epoch 120/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 1.0106\n",
      "Epoch 121/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 1.0106\n",
      "Epoch 122/150\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 0.9991 - val_loss: 1.0106\n",
      "Epoch 123/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 1.0106\n",
      "Epoch 124/150\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 0.9991 - val_loss: 1.0106\n",
      "Epoch 125/150\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 0.9991 - val_loss: 1.0106\n",
      "Epoch 126/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 1.0106\n",
      "Epoch 127/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 1.0106\n",
      "Epoch 128/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0106\n",
      "Epoch 129/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0106\n",
      "Epoch 130/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0106\n",
      "Epoch 131/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0106\n",
      "Epoch 132/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0106\n",
      "Epoch 133/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0106\n",
      "Epoch 134/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0106\n",
      "Epoch 135/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0105\n",
      "Epoch 136/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0105\n",
      "Epoch 137/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0105\n",
      "Epoch 138/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0105\n",
      "Epoch 139/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0105\n",
      "Epoch 140/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0105\n",
      "Epoch 141/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0105\n",
      "Epoch 142/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0105\n",
      "Epoch 143/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0105\n",
      "Epoch 144/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0105\n",
      "Epoch 145/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0105\n",
      "Epoch 146/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0105\n",
      "Epoch 147/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0105\n",
      "Epoch 148/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0105\n",
      "Epoch 149/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0105\n",
      "Epoch 150/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0105\n",
      "Model: \"model_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_36 (InputLayer)        [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 320)               5440      \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_35 (TFOpLam (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_35 (TFOpLambda)  (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_35 (TFOpL (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_35 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_35 (TFO ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_35 (AddLoss)        ()                        0         \n",
      "=================================================================\n",
      "Total params: 5,712\n",
      "Trainable params: 5,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 1ms/step - loss: 3.2277 - val_loss: 1.6077\n",
      "Epoch 2/100\n",
      "141/141 [==============================] - 0s 893us/step - loss: 1.0921 - val_loss: 0.7853\n",
      "Epoch 3/100\n",
      "141/141 [==============================] - 0s 882us/step - loss: 0.6707 - val_loss: 0.5853\n",
      "Epoch 4/100\n",
      "141/141 [==============================] - 0s 908us/step - loss: 0.5446 - val_loss: 0.5072\n",
      "Epoch 5/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4875 - val_loss: 0.4692\n",
      "Epoch 6/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4588 - val_loss: 0.4498\n",
      "Epoch 7/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4442 - val_loss: 0.4400\n",
      "Epoch 8/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4367 - val_loss: 0.4348\n",
      "Epoch 9/100\n",
      "141/141 [==============================] - 0s 950us/step - loss: 0.4327 - val_loss: 0.4319\n",
      "Epoch 10/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4305 - val_loss: 0.4302\n",
      "Epoch 11/100\n",
      "141/141 [==============================] - 0s 951us/step - loss: 0.4292 - val_loss: 0.4291\n",
      "Epoch 12/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4284 - val_loss: 0.4284\n",
      "Epoch 13/100\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.4279 - val_loss: 0.4279\n",
      "Epoch 14/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4276 - val_loss: 0.4276\n",
      "Epoch 15/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4273 - val_loss: 0.4274\n",
      "Epoch 16/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4272 - val_loss: 0.4272\n",
      "Epoch 17/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4271 - val_loss: 0.4271\n",
      "Epoch 18/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4270 - val_loss: 0.4270\n",
      "Epoch 19/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4269 - val_loss: 0.4269\n",
      "Epoch 20/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 21/100\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 22/100\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 0.4268\n",
      "Epoch 23/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4267 - val_loss: 0.4267\n",
      "Epoch 24/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4267 - val_loss: 0.4267\n",
      "Epoch 25/100\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.4267 - val_loss: 0.4267\n",
      "Epoch 26/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4267 - val_loss: 0.4267\n",
      "Epoch 27/100\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.4267 - val_loss: 0.4267\n",
      "Epoch 28/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4267 - val_loss: 0.4267\n",
      "Epoch 29/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4267 - val_loss: 0.4266\n",
      "Epoch 30/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 31/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 32/100\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 33/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 34/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 35/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 36/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 37/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 38/100\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 39/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 40/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 41/100\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 42/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 43/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 44/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 45/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 46/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 47/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 48/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 49/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 50/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 51/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 52/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 53/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 54/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 55/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 56/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 57/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 58/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 59/100\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 60/100\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 61/100\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 62/100\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 63/100\n",
      "141/141 [==============================] - 0s 939us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 64/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 65/100\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 66/100\n",
      "141/141 [==============================] - 0s 925us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 67/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 68/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 69/100\n",
      "141/141 [==============================] - 0s 902us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 70/100\n",
      "141/141 [==============================] - 0s 911us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 71/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 72/100\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 73/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 74/100\n",
      "141/141 [==============================] - 0s 996us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 75/100\n",
      "141/141 [==============================] - 0s 872us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 76/100\n",
      "141/141 [==============================] - 0s 921us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 77/100\n",
      "141/141 [==============================] - 0s 943us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 78/100\n",
      "141/141 [==============================] - 0s 923us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 79/100\n",
      "141/141 [==============================] - 0s 927us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 80/100\n",
      "141/141 [==============================] - 0s 932us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 926us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 82/100\n",
      "141/141 [==============================] - 0s 907us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 83/100\n",
      "141/141 [==============================] - 0s 913us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 84/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 85/100\n",
      "141/141 [==============================] - 0s 912us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 86/100\n",
      "141/141 [==============================] - 0s 911us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 87/100\n",
      "141/141 [==============================] - 0s 906us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 88/100\n",
      "141/141 [==============================] - 0s 895us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 89/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 90/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 91/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 92/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 93/100\n",
      "141/141 [==============================] - 0s 976us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 94/100\n",
      "141/141 [==============================] - 0s 981us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 95/100\n",
      "141/141 [==============================] - 0s 863us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 96/100\n",
      "141/141 [==============================] - 0s 907us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 97/100\n",
      "141/141 [==============================] - 0s 836us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 98/100\n",
      "141/141 [==============================] - 0s 869us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 99/100\n",
      "141/141 [==============================] - 0s 860us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 100/100\n",
      "141/141 [==============================] - 0s 850us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_198 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_144 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_145 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dropout_146 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_147 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_148 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_149 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_150 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_151 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 16)                48        \n",
      "=================================================================\n",
      "Total params: 9,140\n",
      "Trainable params: 9,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "134/134 [==============================] - 1s 3ms/step - loss: 2.0932 - val_loss: 1.7406\n",
      "Epoch 2/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.5715 - val_loss: 1.4597\n",
      "Epoch 3/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3813 - val_loss: 1.3288\n",
      "Epoch 4/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2854 - val_loss: 1.2566\n",
      "Epoch 5/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2313 - val_loss: 1.2123\n",
      "Epoch 6/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1935 - val_loss: 1.1820\n",
      "Epoch 7/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1653 - val_loss: 1.1597\n",
      "Epoch 8/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1468 - val_loss: 1.1430\n",
      "Epoch 9/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1280 - val_loss: 1.1289\n",
      "Epoch 10/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1151 - val_loss: 1.1177\n",
      "Epoch 11/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1055 - val_loss: 1.1082\n",
      "Epoch 12/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0965 - val_loss: 1.1001\n",
      "Epoch 13/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0873 - val_loss: 1.0930\n",
      "Epoch 14/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0796 - val_loss: 1.0868\n",
      "Epoch 15/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0736 - val_loss: 1.0812\n",
      "Epoch 16/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0677 - val_loss: 1.0764\n",
      "Epoch 17/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0622 - val_loss: 1.0719\n",
      "Epoch 18/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0580 - val_loss: 1.0679\n",
      "Epoch 19/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0529 - val_loss: 1.0642\n",
      "Epoch 20/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0494 - val_loss: 1.0609\n",
      "Epoch 21/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0456 - val_loss: 1.0578\n",
      "Epoch 22/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0419 - val_loss: 1.0551\n",
      "Epoch 23/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0396 - val_loss: 1.0525\n",
      "Epoch 24/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0362 - val_loss: 1.0502\n",
      "Epoch 25/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0338 - val_loss: 1.0480\n",
      "Epoch 26/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0318 - val_loss: 1.0460\n",
      "Epoch 27/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0290 - val_loss: 1.0441\n",
      "Epoch 28/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0271 - val_loss: 1.0424\n",
      "Epoch 29/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0252 - val_loss: 1.0408\n",
      "Epoch 30/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0234 - val_loss: 1.0393\n",
      "Epoch 31/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0221 - val_loss: 1.0379\n",
      "Epoch 32/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0202 - val_loss: 1.0365\n",
      "Epoch 33/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0188 - val_loss: 1.0353\n",
      "Epoch 34/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0175 - val_loss: 1.0342\n",
      "Epoch 35/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0160 - val_loss: 1.0331\n",
      "Epoch 36/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0152 - val_loss: 1.0321\n",
      "Epoch 37/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0140 - val_loss: 1.0312\n",
      "Epoch 38/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0130 - val_loss: 1.0303\n",
      "Epoch 39/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0121 - val_loss: 1.0295\n",
      "Epoch 40/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0113 - val_loss: 1.0287\n",
      "Epoch 41/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0104 - val_loss: 1.0280\n",
      "Epoch 42/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0097 - val_loss: 1.0273\n",
      "Epoch 43/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0089 - val_loss: 1.0267\n",
      "Epoch 44/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0082 - val_loss: 1.0261\n",
      "Epoch 45/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0076 - val_loss: 1.0256\n",
      "Epoch 46/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0070 - val_loss: 1.0250\n",
      "Epoch 47/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0065 - val_loss: 1.0245\n",
      "Epoch 48/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0059 - val_loss: 1.0241\n",
      "Epoch 49/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0054 - val_loss: 1.0237\n",
      "Epoch 50/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0050 - val_loss: 1.0232\n",
      "Epoch 51/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0046 - val_loss: 1.0229\n",
      "Epoch 52/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0042 - val_loss: 1.0225\n",
      "Epoch 53/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0038 - val_loss: 1.0222\n",
      "Epoch 54/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0034 - val_loss: 1.0219\n",
      "Epoch 55/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0031 - val_loss: 1.0216\n",
      "Epoch 56/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0028 - val_loss: 1.0213\n",
      "Epoch 57/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0025 - val_loss: 1.0211\n",
      "Epoch 58/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0023 - val_loss: 1.0209\n",
      "Epoch 59/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0020 - val_loss: 1.0207\n",
      "Epoch 60/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0018 - val_loss: 1.0205\n",
      "Epoch 61/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0016 - val_loss: 1.0203\n",
      "Epoch 62/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0014 - val_loss: 1.0201\n",
      "Epoch 63/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0012 - val_loss: 1.0199\n",
      "Epoch 64/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0010 - val_loss: 1.0198\n",
      "Epoch 65/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0009 - val_loss: 1.0196\n",
      "Epoch 66/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0007 - val_loss: 1.0195\n",
      "Epoch 67/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0006 - val_loss: 1.0194\n",
      "Epoch 68/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0004 - val_loss: 1.0192\n",
      "Epoch 69/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0003 - val_loss: 1.0191\n",
      "Epoch 70/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0190\n",
      "Epoch 71/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 1.0189\n",
      "Epoch 72/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0188\n",
      "Epoch 73/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 1.0188\n",
      "Epoch 74/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 1.0187\n",
      "Epoch 75/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0186\n",
      "Epoch 76/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0185\n",
      "Epoch 77/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0185\n",
      "Epoch 78/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 1.0184\n",
      "Epoch 79/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 1.0183\n",
      "Epoch 80/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 1.0183\n",
      "Epoch 81/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 1.0182\n",
      "Epoch 82/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0182\n",
      "Epoch 83/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0181\n",
      "Epoch 84/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 1.0181\n",
      "Epoch 85/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 1.0181\n",
      "Epoch 86/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0180\n",
      "Epoch 87/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0180\n",
      "Epoch 88/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 1.0180\n",
      "Epoch 89/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 1.0179\n",
      "Epoch 90/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 1.0179\n",
      "Epoch 91/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 1.0179\n",
      "Epoch 92/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 1.0178\n",
      "Epoch 93/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 1.0178\n",
      "Epoch 94/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 1.0178\n",
      "Epoch 95/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0178\n",
      "Epoch 96/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0177\n",
      "Epoch 97/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0177\n",
      "Epoch 98/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0177\n",
      "Epoch 99/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 1.0177\n",
      "Epoch 100/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 1.0177\n",
      "Epoch 101/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 1.0177\n",
      "Epoch 102/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 1.0176\n",
      "Epoch 103/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 1.0176\n",
      "Epoch 104/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 1.0176\n",
      "Epoch 105/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 1.0176\n",
      "Epoch 106/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 1.0176\n",
      "Epoch 107/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 1.0176\n",
      "Epoch 108/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 1.0176\n",
      "Epoch 109/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 1.0176\n",
      "Epoch 110/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 1.0176\n",
      "Epoch 111/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0175\n",
      "Epoch 112/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0175\n",
      "Epoch 113/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0175\n",
      "Epoch 114/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0175\n",
      "Epoch 115/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0175\n",
      "Epoch 116/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0175\n",
      "Epoch 117/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0175\n",
      "Epoch 118/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0175\n",
      "Epoch 119/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0175\n",
      "Epoch 120/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0175\n",
      "Epoch 121/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0175\n",
      "Epoch 122/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0175\n",
      "Epoch 123/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0175\n",
      "Epoch 124/150\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.996 - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0174\n",
      "Epoch 125/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0174\n",
      "Epoch 126/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0174\n",
      "Epoch 127/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0174\n",
      "Epoch 128/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0174\n",
      "Epoch 129/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0174\n",
      "Epoch 130/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0174\n",
      "Epoch 131/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0174\n",
      "Epoch 132/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0174\n",
      "Epoch 133/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0174\n",
      "Epoch 134/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0174\n",
      "Epoch 135/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0174\n",
      "Epoch 136/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0174\n",
      "Epoch 137/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 1.0174\n",
      "Epoch 138/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 1.0174\n",
      "Epoch 139/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 1.0174\n",
      "Epoch 140/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 1.0174\n",
      "Epoch 141/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 1.0174\n",
      "Epoch 142/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 1.0174\n",
      "Epoch 143/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 1.0174\n",
      "Epoch 144/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 1.0174\n",
      "Epoch 145/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 1.0174\n",
      "Epoch 146/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 1.0174\n",
      "Epoch 147/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 1.0174\n",
      "Epoch 148/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 1.0174\n",
      "Epoch 149/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 1.0174\n",
      "Epoch 150/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 1.0174\n",
      "Model: \"model_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_38 (InputLayer)        [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 320)               5440      \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_37 (TFOpLam (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_37 (TFOpLambda)  (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_37 (TFOpL (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_37 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_37 (TFO ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_37 (AddLoss)        ()                        0         \n",
      "=================================================================\n",
      "Total params: 5,712\n",
      "Trainable params: 5,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "141/141 [==============================] - 1s 1ms/step - loss: 3.2831 - val_loss: 1.6865\n",
      "Epoch 2/100\n",
      "141/141 [==============================] - 0s 925us/step - loss: 1.1285 - val_loss: 0.8215\n",
      "Epoch 3/100\n",
      "141/141 [==============================] - 0s 835us/step - loss: 0.6858 - val_loss: 0.6030\n",
      "Epoch 4/100\n",
      "141/141 [==============================] - 0s 992us/step - loss: 0.5517 - val_loss: 0.5179\n",
      "Epoch 5/100\n",
      "141/141 [==============================] - 0s 918us/step - loss: 0.4912 - val_loss: 0.4750\n",
      "Epoch 6/100\n",
      "141/141 [==============================] - 0s 909us/step - loss: 0.4605 - val_loss: 0.4527\n",
      "Epoch 7/100\n",
      "141/141 [==============================] - 0s 928us/step - loss: 0.4449 - val_loss: 0.4411\n",
      "Epoch 8/100\n",
      "141/141 [==============================] - 0s 930us/step - loss: 0.4369 - val_loss: 0.4351\n",
      "Epoch 9/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4326 - val_loss: 0.4318\n",
      "Epoch 10/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4303 - val_loss: 0.4299\n",
      "Epoch 11/100\n",
      "141/141 [==============================] - 0s 995us/step - loss: 0.4289 - val_loss: 0.4287\n",
      "Epoch 12/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4280 - val_loss: 0.4280\n",
      "Epoch 13/100\n",
      "141/141 [==============================] - 0s 971us/step - loss: 0.4275 - val_loss: 0.4275\n",
      "Epoch 14/100\n",
      "141/141 [==============================] - 0s 992us/step - loss: 0.4271 - val_loss: 0.4272\n",
      "Epoch 15/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4269 - val_loss: 0.4269\n",
      "Epoch 16/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4267 - val_loss: 0.4267\n",
      "Epoch 17/100\n",
      "141/141 [==============================] - 0s 991us/step - loss: 0.4266 - val_loss: 0.4266\n",
      "Epoch 18/100\n",
      "141/141 [==============================] - 0s 951us/step - loss: 0.4265 - val_loss: 0.4265\n",
      "Epoch 19/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4264 - val_loss: 0.4264\n",
      "Epoch 20/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4263 - val_loss: 0.4264\n",
      "Epoch 21/100\n",
      "141/141 [==============================] - 0s 961us/step - loss: 0.4263 - val_loss: 0.4263\n",
      "Epoch 22/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4262 - val_loss: 0.4263\n",
      "Epoch 23/100\n",
      "141/141 [==============================] - 0s 949us/step - loss: 0.4262 - val_loss: 0.4262\n",
      "Epoch 24/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4262 - val_loss: 0.4262\n",
      "Epoch 25/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4262 - val_loss: 0.4262\n",
      "Epoch 26/100\n",
      "141/141 [==============================] - 0s 995us/step - loss: 0.4262 - val_loss: 0.4262\n",
      "Epoch 27/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 28/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 30/100\n",
      "141/141 [==============================] - 0s 919us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 31/100\n",
      "141/141 [==============================] - 0s 978us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 32/100\n",
      "141/141 [==============================] - 0s 906us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 33/100\n",
      "141/141 [==============================] - 0s 945us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 34/100\n",
      "141/141 [==============================] - 0s 923us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 35/100\n",
      "141/141 [==============================] - 0s 980us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 36/100\n",
      "141/141 [==============================] - 0s 991us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 37/100\n",
      "141/141 [==============================] - 0s 992us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 38/100\n",
      "141/141 [==============================] - 0s 951us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 39/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 40/100\n",
      "141/141 [==============================] - 0s 935us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 41/100\n",
      "141/141 [==============================] - 0s 997us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 42/100\n",
      "141/141 [==============================] - 0s 957us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 43/100\n",
      "141/141 [==============================] - 0s 994us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 44/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 45/100\n",
      "141/141 [==============================] - 0s 978us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 46/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 47/100\n",
      "141/141 [==============================] - 0s 979us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 48/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 49/100\n",
      "141/141 [==============================] - 0s 981us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 50/100\n",
      "141/141 [==============================] - 0s 946us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 51/100\n",
      "141/141 [==============================] - 0s 987us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 52/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 53/100\n",
      "141/141 [==============================] - 0s 988us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 54/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 55/100\n",
      "141/141 [==============================] - 0s 973us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 56/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 57/100\n",
      "141/141 [==============================] - 0s 953us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 58/100\n",
      "141/141 [==============================] - 0s 993us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 59/100\n",
      "141/141 [==============================] - 0s 972us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 60/100\n",
      "141/141 [==============================] - 0s 985us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 61/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 62/100\n",
      "141/141 [==============================] - 0s 948us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 63/100\n",
      "141/141 [==============================] - 0s 970us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 64/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 65/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 66/100\n",
      "141/141 [==============================] - 0s 972us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 67/100\n",
      "141/141 [==============================] - 0s 974us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 68/100\n",
      "141/141 [==============================] - 0s 932us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 69/100\n",
      "141/141 [==============================] - 0s 961us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 70/100\n",
      "141/141 [==============================] - 0s 987us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 71/100\n",
      "141/141 [==============================] - 0s 986us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 72/100\n",
      "141/141 [==============================] - 0s 975us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 73/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 74/100\n",
      "141/141 [==============================] - 0s 950us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 75/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 76/100\n",
      "141/141 [==============================] - 0s 936us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 77/100\n",
      "141/141 [==============================] - 0s 952us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 78/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 79/100\n",
      "141/141 [==============================] - 0s 978us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 80/100\n",
      "141/141 [==============================] - 0s 976us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 81/100\n",
      "141/141 [==============================] - 0s 961us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 82/100\n",
      "141/141 [==============================] - 0s 966us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 83/100\n",
      "141/141 [==============================] - 0s 973us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 84/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 85/100\n",
      "141/141 [==============================] - 0s 931us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 86/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 87/100\n",
      "141/141 [==============================] - 0s 912us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 88/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 89/100\n",
      "141/141 [==============================] - 0s 960us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 90/100\n",
      "141/141 [==============================] - 0s 969us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 91/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 92/100\n",
      "141/141 [==============================] - 0s 951us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 93/100\n",
      "141/141 [==============================] - 0s 974us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 94/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 95/100\n",
      "141/141 [==============================] - 0s 987us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 96/100\n",
      "141/141 [==============================] - 0s 970us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 97/100\n",
      "141/141 [==============================] - 0s 996us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 98/100\n",
      "141/141 [==============================] - 0s 933us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 99/100\n",
      "141/141 [==============================] - 0s 983us/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 100/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_209 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_152 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_153 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dropout_154 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_155 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_156 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_157 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_158 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_159 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 16)                48        \n",
      "=================================================================\n",
      "Total params: 9,140\n",
      "Trainable params: 9,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 1s 3ms/step - loss: 2.0957 - val_loss: 1.7408\n",
      "Epoch 2/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.5703 - val_loss: 1.4557\n",
      "Epoch 3/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.3814 - val_loss: 1.3228\n",
      "Epoch 4/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2860 - val_loss: 1.2497\n",
      "Epoch 5/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.2306 - val_loss: 1.2047\n",
      "Epoch 6/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1925 - val_loss: 1.1733\n",
      "Epoch 7/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1663 - val_loss: 1.1506\n",
      "Epoch 8/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1469 - val_loss: 1.1334\n",
      "Epoch 9/150\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 1.1317 - val_loss: 1.1191\n",
      "Epoch 10/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1181 - val_loss: 1.1076\n",
      "Epoch 11/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1068 - val_loss: 1.0977\n",
      "Epoch 12/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0959 - val_loss: 1.0895\n",
      "Epoch 13/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0895 - val_loss: 1.0821\n",
      "Epoch 14/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0818 - val_loss: 1.0759\n",
      "Epoch 15/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0739 - val_loss: 1.0702\n",
      "Epoch 16/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0694 - val_loss: 1.0651\n",
      "Epoch 17/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0628 - val_loss: 1.0606\n",
      "Epoch 18/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0597 - val_loss: 1.0566\n",
      "Epoch 19/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0529\n",
      "Epoch 20/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0504 - val_loss: 1.0495\n",
      "Epoch 21/150\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 1.0463 - val_loss: 1.0463\n",
      "Epoch 22/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0429 - val_loss: 1.0436\n",
      "Epoch 23/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0406 - val_loss: 1.0409\n",
      "Epoch 24/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0368 - val_loss: 1.0386\n",
      "Epoch 25/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0345 - val_loss: 1.0363\n",
      "Epoch 26/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0327 - val_loss: 1.0343\n",
      "Epoch 27/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0304 - val_loss: 1.0324\n",
      "Epoch 28/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0279 - val_loss: 1.0306\n",
      "Epoch 29/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0259 - val_loss: 1.0289\n",
      "Epoch 30/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0242 - val_loss: 1.0274\n",
      "Epoch 31/150\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 1.0226 - val_loss: 1.0260\n",
      "Epoch 32/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0211 - val_loss: 1.0247\n",
      "Epoch 33/150\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 1.0199 - val_loss: 1.0234\n",
      "Epoch 34/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0186 - val_loss: 1.0222\n",
      "Epoch 35/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0172 - val_loss: 1.0212\n",
      "Epoch 36/150\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 1.0162 - val_loss: 1.0201\n",
      "Epoch 37/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0151 - val_loss: 1.0192\n",
      "Epoch 38/150\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 1.0140 - val_loss: 1.0183\n",
      "Epoch 39/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0131 - val_loss: 1.0174\n",
      "Epoch 40/150\n",
      "134/134 [==============================] - 1s 5ms/step - loss: 1.0123 - val_loss: 1.0167\n",
      "Epoch 41/150\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 1.0114 - val_loss: 1.0159\n",
      "Epoch 42/150\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 1.0108 - val_loss: 1.0152\n",
      "Epoch 43/150\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 1.0100 - val_loss: 1.0146\n",
      "Epoch 44/150\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 1.0093 - val_loss: 1.0140\n",
      "Epoch 45/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0087 - val_loss: 1.0134\n",
      "Epoch 46/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0081 - val_loss: 1.0129\n",
      "Epoch 47/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0075 - val_loss: 1.0124\n",
      "Epoch 48/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0070 - val_loss: 1.0119\n",
      "Epoch 49/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0065 - val_loss: 1.0115\n",
      "Epoch 50/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0061 - val_loss: 1.0111\n",
      "Epoch 51/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0058 - val_loss: 1.0107\n",
      "Epoch 52/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0054 - val_loss: 1.0103\n",
      "Epoch 53/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0049 - val_loss: 1.0100\n",
      "Epoch 54/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0046 - val_loss: 1.0097\n",
      "Epoch 55/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0043 - val_loss: 1.0094\n",
      "Epoch 56/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0040 - val_loss: 1.0091\n",
      "Epoch 57/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0037 - val_loss: 1.0088\n",
      "Epoch 58/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0035 - val_loss: 1.0086\n",
      "Epoch 59/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0033 - val_loss: 1.0084\n",
      "Epoch 60/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0031 - val_loss: 1.0082\n",
      "Epoch 61/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0028 - val_loss: 1.0080\n",
      "Epoch 62/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0026 - val_loss: 1.0078\n",
      "Epoch 63/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0024 - val_loss: 1.0076\n",
      "Epoch 64/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0023 - val_loss: 1.0074\n",
      "Epoch 65/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0021 - val_loss: 1.0073\n",
      "Epoch 66/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0020 - val_loss: 1.0071\n",
      "Epoch 67/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0019 - val_loss: 1.0070\n",
      "Epoch 68/150\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 1.0017 - val_loss: 1.0069\n",
      "Epoch 69/150\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 1.0016 - val_loss: 1.0068\n",
      "Epoch 70/150\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 1.0015 - val_loss: 1.0066\n",
      "Epoch 71/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0014 - val_loss: 1.0065\n",
      "Epoch 72/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0013 - val_loss: 1.0064\n",
      "Epoch 73/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0012 - val_loss: 1.0063\n",
      "Epoch 74/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0011 - val_loss: 1.0063\n",
      "Epoch 75/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0010 - val_loss: 1.0062\n",
      "Epoch 76/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0009 - val_loss: 1.0061\n",
      "Epoch 77/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0009 - val_loss: 1.0060\n",
      "Epoch 78/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0008 - val_loss: 1.0060\n",
      "Epoch 79/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0007 - val_loss: 1.0059\n",
      "Epoch 80/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0007 - val_loss: 1.0058\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0006 - val_loss: 1.0058\n",
      "Epoch 82/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0006 - val_loss: 1.0057\n",
      "Epoch 83/150\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 1.0005 - val_loss: 1.0057\n",
      "Epoch 84/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0005 - val_loss: 1.0056\n",
      "Epoch 85/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0004 - val_loss: 1.0056\n",
      "Epoch 86/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0004 - val_loss: 1.0055\n",
      "Epoch 87/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0003 - val_loss: 1.0055\n",
      "Epoch 88/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0003 - val_loss: 1.0055\n",
      "Epoch 89/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0003 - val_loss: 1.0054\n",
      "Epoch 90/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0054\n",
      "Epoch 91/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0054\n",
      "Epoch 92/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0053\n",
      "Epoch 93/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 1.0053\n",
      "Epoch 94/150\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 1.0001 - val_loss: 1.0053\n",
      "Epoch 95/150\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 1.0001 - val_loss: 1.0053\n",
      "Epoch 96/150\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 1.0001 - val_loss: 1.0052\n",
      "Epoch 97/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0052\n",
      "Epoch 98/150\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 1.0000 - val_loss: 1.0052\n",
      "Epoch 99/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0052\n",
      "Epoch 100/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0051\n",
      "Epoch 101/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0051\n",
      "Epoch 102/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 1.0051\n",
      "Epoch 103/150\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 0.9999 - val_loss: 1.0051\n",
      "Epoch 104/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 1.0051\n",
      "Epoch 105/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 1.0051\n",
      "Epoch 106/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 1.0050\n",
      "Epoch 107/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 1.0050\n",
      "Epoch 108/150\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 0.9999 - val_loss: 1.0050\n",
      "Epoch 109/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 1.0050\n",
      "Epoch 110/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 1.0050\n",
      "Epoch 111/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 1.0050\n",
      "Epoch 112/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 1.0050\n",
      "Epoch 113/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 1.0050\n",
      "Epoch 114/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 1.0049\n",
      "Epoch 115/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 1.0049\n",
      "Epoch 116/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 1.0049\n",
      "Epoch 117/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 1.0049\n",
      "Epoch 118/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0049\n",
      "Epoch 119/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0049\n",
      "Epoch 120/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0049\n",
      "Epoch 121/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0049\n",
      "Epoch 122/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0049\n",
      "Epoch 123/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0049\n",
      "Epoch 124/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0049\n",
      "Epoch 125/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0049\n",
      "Epoch 126/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0048\n",
      "Epoch 127/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0048\n",
      "Epoch 128/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0048\n",
      "Epoch 129/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0048\n",
      "Epoch 130/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0048\n",
      "Epoch 131/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0048\n",
      "Epoch 132/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0048\n",
      "Epoch 133/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0048\n",
      "Epoch 134/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0048\n",
      "Epoch 135/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0048\n",
      "Epoch 136/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0048\n",
      "Epoch 137/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0048\n",
      "Epoch 138/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0048\n",
      "Epoch 139/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0048\n",
      "Epoch 140/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0048\n",
      "Epoch 141/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0048\n",
      "Epoch 142/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0048\n",
      "Epoch 143/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0048\n",
      "Epoch 144/150\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 0.9996 - val_loss: 1.0048\n",
      "Epoch 145/150\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 0.9996 - val_loss: 1.0048\n",
      "Epoch 146/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0048\n",
      "Epoch 147/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0048\n",
      "Epoch 148/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0048\n",
      "Epoch 149/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0047\n",
      "Epoch 150/150\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0047\n",
      "Model: \"model_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_40 (InputLayer)        [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 320)               5440      \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_39 (TFOpLam (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_39 (TFOpLambda)  (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_39 (TFOpL (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_39 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_39 (TFO ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_39 (AddLoss)        ()                        0         \n",
      "=================================================================\n",
      "Total params: 5,712\n",
      "Trainable params: 5,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 1ms/step - loss: 3.2620 - val_loss: 1.6139\n",
      "Epoch 2/100\n",
      "141/141 [==============================] - 0s 955us/step - loss: 1.1144 - val_loss: 0.8009\n",
      "Epoch 3/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.6769 - val_loss: 0.5926\n",
      "Epoch 4/100\n",
      "141/141 [==============================] - 0s 993us/step - loss: 0.5472 - val_loss: 0.5123\n",
      "Epoch 5/100\n",
      "141/141 [==============================] - 0s 924us/step - loss: 0.4885 - val_loss: 0.4706\n",
      "Epoch 6/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4588 - val_loss: 0.4496\n",
      "Epoch 7/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4436 - val_loss: 0.4389\n",
      "Epoch 8/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4357 - val_loss: 0.4333\n",
      "Epoch 9/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4316 - val_loss: 0.4303\n",
      "Epoch 10/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4293 - val_loss: 0.4286\n",
      "Epoch 11/100\n",
      "141/141 [==============================] - 0s 994us/step - loss: 0.4280 - val_loss: 0.4276\n",
      "Epoch 12/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4272 - val_loss: 0.4270\n",
      "Epoch 13/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4267 - val_loss: 0.4266\n",
      "Epoch 14/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4263 - val_loss: 0.4263\n",
      "Epoch 15/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4261\n",
      "Epoch 16/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4259 - val_loss: 0.4259\n",
      "Epoch 17/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4258 - val_loss: 0.4258\n",
      "Epoch 18/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4257 - val_loss: 0.4257\n",
      "Epoch 19/100\n",
      "141/141 [==============================] - 0s 948us/step - loss: 0.4256 - val_loss: 0.4257\n",
      "Epoch 20/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4256 - val_loss: 0.4256\n",
      "Epoch 21/100\n",
      "141/141 [==============================] - 0s 988us/step - loss: 0.4255 - val_loss: 0.4256\n",
      "Epoch 22/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4255 - val_loss: 0.4255\n",
      "Epoch 23/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4255 - val_loss: 0.4255\n",
      "Epoch 24/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4255 - val_loss: 0.4255\n",
      "Epoch 25/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4254 - val_loss: 0.4254\n",
      "Epoch 26/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4254 - val_loss: 0.4254\n",
      "Epoch 27/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4254 - val_loss: 0.4254\n",
      "Epoch 28/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4254 - val_loss: 0.4254\n",
      "Epoch 29/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4254 - val_loss: 0.4254\n",
      "Epoch 30/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4254 - val_loss: 0.4254\n",
      "Epoch 31/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4254 - val_loss: 0.4254\n",
      "Epoch 32/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4254 - val_loss: 0.4254\n",
      "Epoch 33/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4254 - val_loss: 0.4254\n",
      "Epoch 34/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4254 - val_loss: 0.4254\n",
      "Epoch 35/100\n",
      "141/141 [==============================] - 0s 973us/step - loss: 0.4254 - val_loss: 0.4254\n",
      "Epoch 36/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4254 - val_loss: 0.4254\n",
      "Epoch 37/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4254\n",
      "Epoch 38/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4254\n",
      "Epoch 39/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4254\n",
      "Epoch 40/100\n",
      "141/141 [==============================] - 0s 964us/step - loss: 0.4253 - val_loss: 0.4254\n",
      "Epoch 41/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 42/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 43/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 44/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 45/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 46/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 47/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 48/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 49/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 50/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 51/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 52/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 53/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 54/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 55/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 56/100\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 57/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 58/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 59/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 60/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 61/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 62/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 63/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 64/100\n",
      "141/141 [==============================] - 0s 984us/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 65/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 66/100\n",
      "141/141 [==============================] - 0s 985us/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 67/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 68/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 69/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 70/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 71/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 72/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 73/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 74/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 75/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 76/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 77/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 78/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 79/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 80/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 82/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 83/100\n",
      "141/141 [==============================] - 0s 958us/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 84/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 85/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 86/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 87/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 88/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 89/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 90/100\n",
      "141/141 [==============================] - 0s 983us/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 91/100\n",
      "141/141 [==============================] - 0s 993us/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 92/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 93/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 94/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 95/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 96/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 97/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 98/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 99/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "Epoch 100/100\n",
      "141/141 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4253\n",
      "第 satimage_2 個資料處理中....\n",
      "\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_220 (Dense)            (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "dropout_160 (Dropout)        (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "dropout_161 (Dropout)        (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 2)                 74        \n",
      "_________________________________________________________________\n",
      "dropout_162 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_163 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_164 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_225 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_165 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_226 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_166 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_167 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_228 (Dense)            (None, 36)                108       \n",
      "=================================================================\n",
      "Total params: 11,360\n",
      "Trainable params: 11,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "114/114 [==============================] - 1s 3ms/step - loss: 2.6836 - val_loss: 2.0322\n",
      "Epoch 2/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.8694 - val_loss: 1.6957\n",
      "Epoch 3/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.6284 - val_loss: 1.5166\n",
      "Epoch 4/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.4952 - val_loss: 1.4086\n",
      "Epoch 5/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.4067 - val_loss: 1.3389\n",
      "Epoch 6/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.3508 - val_loss: 1.2885\n",
      "Epoch 7/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.3047 - val_loss: 1.2506\n",
      "Epoch 8/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.2668 - val_loss: 1.2225\n",
      "Epoch 9/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.2430 - val_loss: 1.1972\n",
      "Epoch 10/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.2216 - val_loss: 1.1780\n",
      "Epoch 11/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1999 - val_loss: 1.1612\n",
      "Epoch 12/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1792 - val_loss: 1.1471\n",
      "Epoch 13/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1705 - val_loss: 1.1353\n",
      "Epoch 14/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1538 - val_loss: 1.1247\n",
      "Epoch 15/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1421 - val_loss: 1.1149\n",
      "Epoch 16/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1331 - val_loss: 1.1068\n",
      "Epoch 17/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1240 - val_loss: 1.0990\n",
      "Epoch 18/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1164 - val_loss: 1.0923\n",
      "Epoch 19/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1086 - val_loss: 1.0862\n",
      "Epoch 20/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0994 - val_loss: 1.0807\n",
      "Epoch 21/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0955 - val_loss: 1.0756\n",
      "Epoch 22/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0879 - val_loss: 1.0710\n",
      "Epoch 23/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0842 - val_loss: 1.0666\n",
      "Epoch 24/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0779 - val_loss: 1.0626\n",
      "Epoch 25/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0763 - val_loss: 1.0589\n",
      "Epoch 26/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0698 - val_loss: 1.0554\n",
      "Epoch 27/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0649 - val_loss: 1.0522\n",
      "Epoch 28/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0613 - val_loss: 1.0491\n",
      "Epoch 29/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0571 - val_loss: 1.0464\n",
      "Epoch 30/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0549 - val_loss: 1.0437\n",
      "Epoch 31/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0518 - val_loss: 1.0412\n",
      "Epoch 32/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0473 - val_loss: 1.0389\n",
      "Epoch 33/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0449 - val_loss: 1.0367\n",
      "Epoch 34/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0426 - val_loss: 1.0347\n",
      "Epoch 35/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0413 - val_loss: 1.0328\n",
      "Epoch 36/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0384 - val_loss: 1.0309\n",
      "Epoch 37/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0360 - val_loss: 1.0292\n",
      "Epoch 38/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0340 - val_loss: 1.0276\n",
      "Epoch 39/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0321 - val_loss: 1.0261\n",
      "Epoch 40/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0303 - val_loss: 1.0247\n",
      "Epoch 41/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0286 - val_loss: 1.0233\n",
      "Epoch 42/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0267 - val_loss: 1.0220\n",
      "Epoch 43/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0258 - val_loss: 1.0208\n",
      "Epoch 44/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0244 - val_loss: 1.0196\n",
      "Epoch 45/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0225 - val_loss: 1.0186\n",
      "Epoch 46/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0214 - val_loss: 1.0176\n",
      "Epoch 47/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0200 - val_loss: 1.0166\n",
      "Epoch 48/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0193 - val_loss: 1.0157\n",
      "Epoch 49/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0177 - val_loss: 1.0148\n",
      "Epoch 50/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0170 - val_loss: 1.0140\n",
      "Epoch 51/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0164 - val_loss: 1.0132\n",
      "Epoch 52/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0153 - val_loss: 1.0125\n",
      "Epoch 53/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0142 - val_loss: 1.0118\n",
      "Epoch 54/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0135 - val_loss: 1.0112\n",
      "Epoch 55/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0129 - val_loss: 1.0105\n",
      "Epoch 56/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0122 - val_loss: 1.0099\n",
      "Epoch 57/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0114 - val_loss: 1.0094\n",
      "Epoch 58/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0110 - val_loss: 1.0088\n",
      "Epoch 59/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0101 - val_loss: 1.0083\n",
      "Epoch 60/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0095 - val_loss: 1.0079\n",
      "Epoch 61/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0087 - val_loss: 1.0075\n",
      "Epoch 62/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0087 - val_loss: 1.0071\n",
      "Epoch 63/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0082 - val_loss: 1.0067\n",
      "Epoch 64/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0075 - val_loss: 1.0063\n",
      "Epoch 65/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0071 - val_loss: 1.0060\n",
      "Epoch 66/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0065 - val_loss: 1.0057\n",
      "Epoch 67/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0062 - val_loss: 1.0054\n",
      "Epoch 68/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0061 - val_loss: 1.0050\n",
      "Epoch 69/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0057 - val_loss: 1.0048\n",
      "Epoch 70/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0053 - val_loss: 1.0045\n",
      "Epoch 71/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0049 - val_loss: 1.0043\n",
      "Epoch 72/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0047 - val_loss: 1.0041\n",
      "Epoch 73/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0045 - val_loss: 1.0039\n",
      "Epoch 74/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0042 - val_loss: 1.0037\n",
      "Epoch 75/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0040 - val_loss: 1.0035\n",
      "Epoch 76/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0037 - val_loss: 1.0033\n",
      "Epoch 77/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0036 - val_loss: 1.0031\n",
      "Epoch 78/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0034 - val_loss: 1.0030\n",
      "Epoch 79/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0032 - val_loss: 1.0029\n",
      "Epoch 80/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0029 - val_loss: 1.0027\n",
      "Epoch 81/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0028 - val_loss: 1.0026\n",
      "Epoch 82/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0027 - val_loss: 1.0025\n",
      "Epoch 83/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0025 - val_loss: 1.0024\n",
      "Epoch 84/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0024 - val_loss: 1.0023\n",
      "Epoch 85/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0022 - val_loss: 1.0022\n",
      "Epoch 86/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0021 - val_loss: 1.0021\n",
      "Epoch 87/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0020 - val_loss: 1.0020\n",
      "Epoch 88/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0019 - val_loss: 1.0020\n",
      "Epoch 89/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0018 - val_loss: 1.0019\n",
      "Epoch 90/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0017 - val_loss: 1.0019\n",
      "Epoch 91/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0016 - val_loss: 1.0018\n",
      "Epoch 92/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0015 - val_loss: 1.0017\n",
      "Epoch 93/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0014 - val_loss: 1.0017\n",
      "Epoch 94/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0013 - val_loss: 1.0016\n",
      "Epoch 95/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0013 - val_loss: 1.0016\n",
      "Epoch 96/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0012 - val_loss: 1.0015\n",
      "Epoch 97/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0012 - val_loss: 1.0015\n",
      "Epoch 98/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0011 - val_loss: 1.0015\n",
      "Epoch 99/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0010 - val_loss: 1.0014\n",
      "Epoch 100/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0010 - val_loss: 1.0014\n",
      "Epoch 101/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0009 - val_loss: 1.0014\n",
      "Epoch 102/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0009 - val_loss: 1.0013\n",
      "Epoch 103/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0008 - val_loss: 1.0013\n",
      "Epoch 104/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0008 - val_loss: 1.0013\n",
      "Epoch 105/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0008 - val_loss: 1.0013\n",
      "Epoch 106/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0007 - val_loss: 1.0013\n",
      "Epoch 107/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0007 - val_loss: 1.0013\n",
      "Epoch 108/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0006 - val_loss: 1.0012\n",
      "Epoch 109/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0006 - val_loss: 1.0012\n",
      "Epoch 110/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0006 - val_loss: 1.0012\n",
      "Epoch 111/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0005 - val_loss: 1.0012\n",
      "Epoch 112/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0005 - val_loss: 1.0012\n",
      "Epoch 113/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0005 - val_loss: 1.0012\n",
      "Epoch 114/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0005 - val_loss: 1.0012\n",
      "Epoch 115/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0005 - val_loss: 1.0011\n",
      "Epoch 116/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0004 - val_loss: 1.0011\n",
      "Epoch 117/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0004 - val_loss: 1.0011\n",
      "Epoch 118/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0004 - val_loss: 1.0011\n",
      "Epoch 119/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0004 - val_loss: 1.0011\n",
      "Epoch 120/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0004 - val_loss: 1.0011\n",
      "Epoch 121/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0003 - val_loss: 1.0011\n",
      "Epoch 122/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0003 - val_loss: 1.0011\n",
      "Epoch 123/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0003 - val_loss: 1.0011\n",
      "Epoch 124/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0003 - val_loss: 1.0011\n",
      "Epoch 125/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0003 - val_loss: 1.0011\n",
      "Epoch 126/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0003 - val_loss: 1.0011\n",
      "Epoch 127/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0011\n",
      "Epoch 128/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0011\n",
      "Epoch 129/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0011\n",
      "Epoch 130/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0011\n",
      "Epoch 131/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0011\n",
      "Epoch 132/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0011\n",
      "Epoch 133/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0011\n",
      "Epoch 134/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0011\n",
      "Epoch 135/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0011\n",
      "Epoch 136/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0011\n",
      "Epoch 137/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 1.0010\n",
      "Epoch 138/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 1.0011\n",
      "Epoch 139/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 1.0010\n",
      "Epoch 140/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 1.0011\n",
      "Epoch 141/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 1.0010\n",
      "Epoch 142/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 1.0010\n",
      "Epoch 143/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 1.0010\n",
      "Epoch 144/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 1.0010\n",
      "Epoch 145/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 1.0010\n",
      "Epoch 146/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 1.0010\n",
      "Epoch 147/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 1.0011\n",
      "Epoch 148/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0001 - val_loss: 1.0011\n",
      "Epoch 149/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 1.0011\n",
      "Epoch 150/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 1.0011\n",
      "Model: \"model_62\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_42 (InputLayer)        [(None, 36)]              0         \n",
      "_________________________________________________________________\n",
      "dense_230 (Dense)            (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 720)               26640     \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_41 (TFOpLam (None, 720)               0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_41 (TFOpLambda)  (None, 720)               0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_41 (TFOpL (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_41 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_41 (TFO ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_41 (AddLoss)        ()                        0         \n",
      "=================================================================\n",
      "Total params: 27,972\n",
      "Trainable params: 27,972\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "121/121 [==============================] - 1s 2ms/step - loss: 5.5394 - val_loss: 2.4471\n",
      "Epoch 2/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.9545 - val_loss: 1.5890\n",
      "Epoch 3/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.4397 - val_loss: 1.3137\n",
      "Epoch 4/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.2532 - val_loss: 1.1958\n",
      "Epoch 5/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.1700 - val_loss: 1.1395\n",
      "Epoch 6/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.1242 - val_loss: 1.1086\n",
      "Epoch 7/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0995 - val_loss: 1.0912\n",
      "Epoch 8/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0852 - val_loss: 1.0806\n",
      "Epoch 9/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0762 - val_loss: 1.0738\n",
      "Epoch 10/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0706 - val_loss: 1.0692\n",
      "Epoch 11/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0666 - val_loss: 1.0659\n",
      "Epoch 12/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0639 - val_loss: 1.0636\n",
      "Epoch 13/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0618 - val_loss: 1.0618\n",
      "Epoch 14/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0602 - val_loss: 1.0604\n",
      "Epoch 15/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0589 - val_loss: 1.0593\n",
      "Epoch 16/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0580 - val_loss: 1.0584\n",
      "Epoch 17/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0572 - val_loss: 1.0577\n",
      "Epoch 18/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0566 - val_loss: 1.0571\n",
      "Epoch 19/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0563 - val_loss: 1.0566\n",
      "Epoch 20/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0557 - val_loss: 1.0562\n",
      "Epoch 21/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0554 - val_loss: 1.0559\n",
      "Epoch 22/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0556\n",
      "Epoch 23/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0549 - val_loss: 1.0553\n",
      "Epoch 24/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0547 - val_loss: 1.0551\n",
      "Epoch 25/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0545 - val_loss: 1.0549\n",
      "Epoch 26/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0543 - val_loss: 1.0548\n",
      "Epoch 27/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0542 - val_loss: 1.0546\n",
      "Epoch 28/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0541 - val_loss: 1.0545\n",
      "Epoch 29/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0540 - val_loss: 1.0544\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0539 - val_loss: 1.0543\n",
      "Epoch 31/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0539 - val_loss: 1.0542\n",
      "Epoch 32/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0538 - val_loss: 1.0541\n",
      "Epoch 33/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0537 - val_loss: 1.0541\n",
      "Epoch 34/100\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 1.0537 - val_loss: 1.0540\n",
      "Epoch 35/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0537 - val_loss: 1.0540\n",
      "Epoch 36/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0536 - val_loss: 1.0539\n",
      "Epoch 37/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0536 - val_loss: 1.0539\n",
      "Epoch 38/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0536 - val_loss: 1.0538\n",
      "Epoch 39/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0535 - val_loss: 1.0538\n",
      "Epoch 40/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0535 - val_loss: 1.0538\n",
      "Epoch 41/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0535 - val_loss: 1.0537\n",
      "Epoch 42/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0535 - val_loss: 1.0537\n",
      "Epoch 43/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0535 - val_loss: 1.0537\n",
      "Epoch 44/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0537\n",
      "Epoch 45/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0536\n",
      "Epoch 46/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0536\n",
      "Epoch 47/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0536\n",
      "Epoch 48/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0536\n",
      "Epoch 49/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0536\n",
      "Epoch 50/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0536\n",
      "Epoch 51/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 52/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 53/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 54/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 55/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 56/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 57/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 58/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 59/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 60/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 61/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0534\n",
      "Epoch 62/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0534\n",
      "Epoch 63/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 64/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 65/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 66/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 67/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 68/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 69/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 70/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 71/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 72/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 73/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 74/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 75/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 76/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 77/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 78/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 79/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 80/100\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 81/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 82/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 83/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 84/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 85/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 86/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 87/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 88/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 89/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 90/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 91/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 92/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 93/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 94/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 95/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 96/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 97/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 98/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 99/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Epoch 100/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0533 - val_loss: 1.0534\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_231 (Dense)            (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "dropout_168 (Dropout)        (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_232 (Dense)            (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "dropout_169 (Dropout)        (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_233 (Dense)            (None, 2)                 74        \n",
      "_________________________________________________________________\n",
      "dropout_170 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_171 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_172 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_236 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_173 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_237 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_174 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_238 (Dense)            (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_175 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_239 (Dense)            (None, 36)                108       \n",
      "=================================================================\n",
      "Total params: 11,360\n",
      "Trainable params: 11,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 3ms/step - loss: 2.6992 - val_loss: 2.0147\n",
      "Epoch 2/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.8711 - val_loss: 1.6845\n",
      "Epoch 3/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.6217 - val_loss: 1.5079\n",
      "Epoch 4/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.4912 - val_loss: 1.4053\n",
      "Epoch 5/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.4058 - val_loss: 1.3384\n",
      "Epoch 6/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.3449 - val_loss: 1.2900\n",
      "Epoch 7/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.3063 - val_loss: 1.2530\n",
      "Epoch 8/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.2673 - val_loss: 1.2242\n",
      "Epoch 9/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.2383 - val_loss: 1.2022\n",
      "Epoch 10/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.2187 - val_loss: 1.1840\n",
      "Epoch 11/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1985 - val_loss: 1.1660\n",
      "Epoch 12/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1812 - val_loss: 1.1528\n",
      "Epoch 13/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1636 - val_loss: 1.1405\n",
      "Epoch 14/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1532 - val_loss: 1.1303\n",
      "Epoch 15/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1416 - val_loss: 1.1208\n",
      "Epoch 16/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1317 - val_loss: 1.1126\n",
      "Epoch 17/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1229 - val_loss: 1.1051\n",
      "Epoch 18/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1143 - val_loss: 1.0986\n",
      "Epoch 19/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1048 - val_loss: 1.0927\n",
      "Epoch 20/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1005 - val_loss: 1.0873\n",
      "Epoch 21/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0927 - val_loss: 1.0823\n",
      "Epoch 22/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0849 - val_loss: 1.0778\n",
      "Epoch 23/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0832 - val_loss: 1.0735\n",
      "Epoch 24/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0782 - val_loss: 1.0695\n",
      "Epoch 25/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0734 - val_loss: 1.0658\n",
      "Epoch 26/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0683 - val_loss: 1.0624\n",
      "Epoch 27/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0646 - val_loss: 1.0592\n",
      "Epoch 28/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0605 - val_loss: 1.0562\n",
      "Epoch 29/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0559 - val_loss: 1.0535\n",
      "Epoch 30/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0528 - val_loss: 1.0509\n",
      "Epoch 31/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0501 - val_loss: 1.0484\n",
      "Epoch 32/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0467 - val_loss: 1.0462\n",
      "Epoch 33/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0448 - val_loss: 1.0440\n",
      "Epoch 34/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0426 - val_loss: 1.0420\n",
      "Epoch 35/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0391 - val_loss: 1.0401\n",
      "Epoch 36/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0379 - val_loss: 1.0383\n",
      "Epoch 37/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0356 - val_loss: 1.0366\n",
      "Epoch 38/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0342 - val_loss: 1.0350\n",
      "Epoch 39/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0310 - val_loss: 1.0335\n",
      "Epoch 40/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0287 - val_loss: 1.0321\n",
      "Epoch 41/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0277 - val_loss: 1.0308\n",
      "Epoch 42/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0263 - val_loss: 1.0295\n",
      "Epoch 43/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0245 - val_loss: 1.0283\n",
      "Epoch 44/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0228 - val_loss: 1.0272\n",
      "Epoch 45/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0224 - val_loss: 1.0261\n",
      "Epoch 46/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0206 - val_loss: 1.0251\n",
      "Epoch 47/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0197 - val_loss: 1.0241\n",
      "Epoch 48/150\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 1.0185 - val_loss: 1.0232\n",
      "Epoch 49/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0171 - val_loss: 1.0223\n",
      "Epoch 50/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0159 - val_loss: 1.0216\n",
      "Epoch 51/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0152 - val_loss: 1.0208\n",
      "Epoch 52/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0138 - val_loss: 1.0201\n",
      "Epoch 53/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0136 - val_loss: 1.0194\n",
      "Epoch 54/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0127 - val_loss: 1.0188\n",
      "Epoch 55/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0119 - val_loss: 1.0181\n",
      "Epoch 56/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0108 - val_loss: 1.0176\n",
      "Epoch 57/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0104 - val_loss: 1.0171\n",
      "Epoch 58/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0099 - val_loss: 1.0165\n",
      "Epoch 59/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0091 - val_loss: 1.0160\n",
      "Epoch 60/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0087 - val_loss: 1.0156\n",
      "Epoch 61/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0078 - val_loss: 1.0152\n",
      "Epoch 62/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0073 - val_loss: 1.0148\n",
      "Epoch 63/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0073 - val_loss: 1.0144\n",
      "Epoch 64/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0068 - val_loss: 1.0140\n",
      "Epoch 65/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0063 - val_loss: 1.0137\n",
      "Epoch 66/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0059 - val_loss: 1.0134\n",
      "Epoch 67/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0053 - val_loss: 1.0131\n",
      "Epoch 68/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0050 - val_loss: 1.0129\n",
      "Epoch 69/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0050 - val_loss: 1.0125\n",
      "Epoch 70/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0043 - val_loss: 1.0123\n",
      "Epoch 71/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0044 - val_loss: 1.0120\n",
      "Epoch 72/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0039 - val_loss: 1.0118\n",
      "Epoch 73/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0036 - val_loss: 1.0117\n",
      "Epoch 74/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0034 - val_loss: 1.0114\n",
      "Epoch 75/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0031 - val_loss: 1.0113\n",
      "Epoch 76/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0029 - val_loss: 1.0111\n",
      "Epoch 77/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0027 - val_loss: 1.0110\n",
      "Epoch 78/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0024 - val_loss: 1.0108\n",
      "Epoch 79/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0024 - val_loss: 1.0107\n",
      "Epoch 80/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0021 - val_loss: 1.0106\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0020 - val_loss: 1.0104\n",
      "Epoch 82/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0018 - val_loss: 1.0103\n",
      "Epoch 83/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0016 - val_loss: 1.0102\n",
      "Epoch 84/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0015 - val_loss: 1.0101\n",
      "Epoch 85/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0013 - val_loss: 1.0100\n",
      "Epoch 86/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0013 - val_loss: 1.0099\n",
      "Epoch 87/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0011 - val_loss: 1.0099\n",
      "Epoch 88/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0010 - val_loss: 1.0098\n",
      "Epoch 89/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0009 - val_loss: 1.0097\n",
      "Epoch 90/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0008 - val_loss: 1.0097\n",
      "Epoch 91/150\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.995 - 0s 2ms/step - loss: 1.0007 - val_loss: 1.0096\n",
      "Epoch 92/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0006 - val_loss: 1.0096\n",
      "Epoch 93/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0005 - val_loss: 1.0096\n",
      "Epoch 94/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0004 - val_loss: 1.0095\n",
      "Epoch 95/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0004 - val_loss: 1.0095\n",
      "Epoch 96/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0004 - val_loss: 1.0094\n",
      "Epoch 97/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0003 - val_loss: 1.0094\n",
      "Epoch 98/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0094\n",
      "Epoch 99/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0093\n",
      "Epoch 100/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 1.0093\n",
      "Epoch 101/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 1.0092\n",
      "Epoch 102/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0092\n",
      "Epoch 103/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 1.0092\n",
      "Epoch 104/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 1.0092\n",
      "Epoch 105/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 1.0092\n",
      "Epoch 106/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 1.0092\n",
      "Epoch 107/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 1.0091\n",
      "Epoch 108/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 1.0092\n",
      "Epoch 109/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0091\n",
      "Epoch 110/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.0091\n",
      "Epoch 111/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9997 - val_loss: 1.0091\n",
      "Epoch 112/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0091\n",
      "Epoch 113/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0091\n",
      "Epoch 114/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0091\n",
      "Epoch 115/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0091\n",
      "Epoch 116/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 1.0090\n",
      "Epoch 117/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 1.0091\n",
      "Epoch 118/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 1.0090\n",
      "Epoch 119/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 1.0090\n",
      "Epoch 120/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 1.0090\n",
      "Epoch 121/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 1.0090\n",
      "Epoch 122/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 1.0090\n",
      "Epoch 123/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 1.0090\n",
      "Epoch 124/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 1.0090\n",
      "Epoch 125/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 1.0090\n",
      "Epoch 126/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 1.0090\n",
      "Epoch 127/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 1.0090\n",
      "Epoch 128/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 1.0090\n",
      "Epoch 129/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 1.0090\n",
      "Epoch 130/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 1.0090\n",
      "Epoch 131/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 1.0090\n",
      "Epoch 132/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 1.0090\n",
      "Epoch 133/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 1.0090\n",
      "Epoch 134/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 1.0090\n",
      "Epoch 135/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 1.0090\n",
      "Epoch 136/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 1.0090\n",
      "Epoch 137/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0090\n",
      "Epoch 138/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0090\n",
      "Epoch 139/150\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.9992 - val_loss: 1.0090\n",
      "Epoch 140/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0090\n",
      "Epoch 141/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0090\n",
      "Epoch 142/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0090\n",
      "Epoch 143/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0090\n",
      "Epoch 144/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0090\n",
      "Epoch 145/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0090\n",
      "Epoch 146/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0090\n",
      "Epoch 147/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0090\n",
      "Epoch 148/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0090\n",
      "Epoch 149/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0090\n",
      "Epoch 150/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 1.0090\n",
      "Model: \"model_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_44 (InputLayer)        [(None, 36)]              0         \n",
      "_________________________________________________________________\n",
      "dense_241 (Dense)            (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 720)               26640     \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_43 (TFOpLam (None, 720)               0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_43 (TFOpLambda)  (None, 720)               0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_43 (TFOpL (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_43 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_43 (TFO ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_43 (AddLoss)        ()                        0         \n",
      "=================================================================\n",
      "Total params: 27,972\n",
      "Trainable params: 27,972\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 1ms/step - loss: 5.5232 - val_loss: 2.5040\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 889us/step - loss: 1.9562 - val_loss: 1.6012\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 881us/step - loss: 1.4368 - val_loss: 1.3229\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 876us/step - loss: 1.2529 - val_loss: 1.2062\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 879us/step - loss: 1.1684 - val_loss: 1.1470\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 916us/step - loss: 1.1243 - val_loss: 1.1146\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 994us/step - loss: 1.0998 - val_loss: 1.0954\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 996us/step - loss: 1.0851 - val_loss: 1.0834\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0760 - val_loss: 1.0756\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0700 - val_loss: 1.0702\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0659 - val_loss: 1.0665\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0630 - val_loss: 1.0638\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0609 - val_loss: 1.0618\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0594 - val_loss: 1.0602\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0581 - val_loss: 1.0589\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0572 - val_loss: 1.0579\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 1000us/step - loss: 1.0564 - val_loss: 1.0571\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0558 - val_loss: 1.0564\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0552 - val_loss: 1.0558\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0548 - val_loss: 1.0554\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0545 - val_loss: 1.0550\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0542 - val_loss: 1.0547\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0539 - val_loss: 1.0544\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0537 - val_loss: 1.0542\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0535 - val_loss: 1.0540\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0538\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0532 - val_loss: 1.0537\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0531 - val_loss: 1.0535\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0530 - val_loss: 1.0534\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0529 - val_loss: 1.0533\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0529 - val_loss: 1.0532\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0528 - val_loss: 1.0531\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0527 - val_loss: 1.0530\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0527 - val_loss: 1.0530\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0526 - val_loss: 1.0529\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0526 - val_loss: 1.0529\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0526 - val_loss: 1.0528\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0525 - val_loss: 1.0528\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0525 - val_loss: 1.0527\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0525 - val_loss: 1.0527\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0525 - val_loss: 1.0527\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0525 - val_loss: 1.0526\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0524 - val_loss: 1.0526\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0524 - val_loss: 1.0526\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0524 - val_loss: 1.0526\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0524 - val_loss: 1.0526\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0524 - val_loss: 1.0526\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0524 - val_loss: 1.0525\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0524 - val_loss: 1.0525\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0524 - val_loss: 1.0525\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0524 - val_loss: 1.0525\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0524 - val_loss: 1.0525\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0524 - val_loss: 1.0525\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0525\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0525\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0525\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0525\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0525\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0523 - val_loss: 1.0524\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_242 (Dense)            (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "dropout_176 (Dropout)        (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_243 (Dense)            (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "dropout_177 (Dropout)        (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_244 (Dense)            (None, 2)                 74        \n",
      "_________________________________________________________________\n",
      "dropout_178 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_245 (Dense)            (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_179 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_246 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_180 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_247 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_181 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_248 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_182 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_249 (Dense)            (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_183 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_250 (Dense)            (None, 36)                108       \n",
      "=================================================================\n",
      "Total params: 11,360\n",
      "Trainable params: 11,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "114/114 [==============================] - 1s 3ms/step - loss: 2.6413 - val_loss: 2.1226\n",
      "Epoch 2/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.8526 - val_loss: 1.7819\n",
      "Epoch 3/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.6110 - val_loss: 1.5994\n",
      "Epoch 4/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.4801 - val_loss: 1.4917\n",
      "Epoch 5/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.3915 - val_loss: 1.4209\n",
      "Epoch 6/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.3402 - val_loss: 1.3704\n",
      "Epoch 7/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.2918 - val_loss: 1.3316\n",
      "Epoch 8/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.2570 - val_loss: 1.3017\n",
      "Epoch 9/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.2332 - val_loss: 1.2786\n",
      "Epoch 10/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.2118 - val_loss: 1.2576\n",
      "Epoch 11/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1901 - val_loss: 1.2405\n",
      "Epoch 12/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.1689 - val_loss: 1.2256\n",
      "Epoch 13/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1577 - val_loss: 1.2130\n",
      "Epoch 14/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1458 - val_loss: 1.2030\n",
      "Epoch 15/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1349 - val_loss: 1.1922\n",
      "Epoch 16/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1234 - val_loss: 1.1840\n",
      "Epoch 17/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1153 - val_loss: 1.1764\n",
      "Epoch 18/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1062 - val_loss: 1.1690\n",
      "Epoch 19/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0979 - val_loss: 1.1626\n",
      "Epoch 20/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0933 - val_loss: 1.1567\n",
      "Epoch 21/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0866 - val_loss: 1.1514\n",
      "Epoch 22/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0792 - val_loss: 1.1465\n",
      "Epoch 23/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0772 - val_loss: 1.1419\n",
      "Epoch 24/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0687 - val_loss: 1.1377\n",
      "Epoch 25/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0650 - val_loss: 1.1339\n",
      "Epoch 26/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0609 - val_loss: 1.1301\n",
      "Epoch 27/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0558 - val_loss: 1.1267\n",
      "Epoch 28/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0530 - val_loss: 1.1236\n",
      "Epoch 29/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0485 - val_loss: 1.1205\n",
      "Epoch 30/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0473 - val_loss: 1.1177\n",
      "Epoch 31/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0432 - val_loss: 1.1150\n",
      "Epoch 32/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0407 - val_loss: 1.1125\n",
      "Epoch 33/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0363 - val_loss: 1.1102\n",
      "Epoch 34/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0352 - val_loss: 1.1081\n",
      "Epoch 35/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0328 - val_loss: 1.1060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0311 - val_loss: 1.1039\n",
      "Epoch 37/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0275 - val_loss: 1.1021\n",
      "Epoch 38/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0255 - val_loss: 1.1003\n",
      "Epoch 39/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0241 - val_loss: 1.0987\n",
      "Epoch 40/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0227 - val_loss: 1.0970\n",
      "Epoch 41/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0206 - val_loss: 1.0956\n",
      "Epoch 42/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0190 - val_loss: 1.0941\n",
      "Epoch 43/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0173 - val_loss: 1.0928\n",
      "Epoch 44/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0161 - val_loss: 1.0916\n",
      "Epoch 45/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0150 - val_loss: 1.0904\n",
      "Epoch 46/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0133 - val_loss: 1.0892\n",
      "Epoch 47/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0119 - val_loss: 1.0882\n",
      "Epoch 48/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0107 - val_loss: 1.0872\n",
      "Epoch 49/150\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 1.0102 - val_loss: 1.0862\n",
      "Epoch 50/150\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 1.0092 - val_loss: 1.0853\n",
      "Epoch 51/150\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 1.0084 - val_loss: 1.0844\n",
      "Epoch 52/150\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 1.0076 - val_loss: 1.0835\n",
      "Epoch 53/150\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 1.0065 - val_loss: 1.0827\n",
      "Epoch 54/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0059 - val_loss: 1.0820\n",
      "Epoch 55/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0052 - val_loss: 1.0813\n",
      "Epoch 56/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0045 - val_loss: 1.0805\n",
      "Epoch 57/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0037 - val_loss: 1.0799\n",
      "Epoch 58/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0030 - val_loss: 1.0793\n",
      "Epoch 59/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0020 - val_loss: 1.0787\n",
      "Epoch 60/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0021 - val_loss: 1.0782\n",
      "Epoch 61/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0013 - val_loss: 1.0776\n",
      "Epoch 62/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0009 - val_loss: 1.0771\n",
      "Epoch 63/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0766\n",
      "Epoch 64/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 1.0762\n",
      "Epoch 65/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 1.0758\n",
      "Epoch 66/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 1.0754\n",
      "Epoch 67/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 1.0750\n",
      "Epoch 68/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 1.0746\n",
      "Epoch 69/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9981 - val_loss: 1.0743\n",
      "Epoch 70/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9977 - val_loss: 1.0739\n",
      "Epoch 71/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9973 - val_loss: 1.0736\n",
      "Epoch 72/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9972 - val_loss: 1.0733\n",
      "Epoch 73/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 1.0730\n",
      "Epoch 74/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9966 - val_loss: 1.0728\n",
      "Epoch 75/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9964 - val_loss: 1.0725\n",
      "Epoch 76/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9962 - val_loss: 1.0723\n",
      "Epoch 77/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9959 - val_loss: 1.0721\n",
      "Epoch 78/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9958 - val_loss: 1.0719\n",
      "Epoch 79/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9956 - val_loss: 1.0717\n",
      "Epoch 80/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9955 - val_loss: 1.0715\n",
      "Epoch 81/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9953 - val_loss: 1.0713\n",
      "Epoch 82/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9952 - val_loss: 1.0711\n",
      "Epoch 83/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9950 - val_loss: 1.0710\n",
      "Epoch 84/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9948 - val_loss: 1.0708\n",
      "Epoch 85/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9947 - val_loss: 1.0707\n",
      "Epoch 86/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9945 - val_loss: 1.0705\n",
      "Epoch 87/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9944 - val_loss: 1.0704\n",
      "Epoch 88/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9943 - val_loss: 1.0703\n",
      "Epoch 89/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9942 - val_loss: 1.0702\n",
      "Epoch 90/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9942 - val_loss: 1.0701\n",
      "Epoch 91/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9941 - val_loss: 1.0700\n",
      "Epoch 92/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9940 - val_loss: 1.0699\n",
      "Epoch 93/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9939 - val_loss: 1.0698\n",
      "Epoch 94/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9938 - val_loss: 1.0697\n",
      "Epoch 95/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9938 - val_loss: 1.0696\n",
      "Epoch 96/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9937 - val_loss: 1.0695\n",
      "Epoch 97/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9937 - val_loss: 1.0695\n",
      "Epoch 98/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9936 - val_loss: 1.0694\n",
      "Epoch 99/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9935 - val_loss: 1.0693\n",
      "Epoch 100/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9935 - val_loss: 1.0693\n",
      "Epoch 101/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9935 - val_loss: 1.0692\n",
      "Epoch 102/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9934 - val_loss: 1.0691\n",
      "Epoch 103/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9933 - val_loss: 1.0691\n",
      "Epoch 104/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9933 - val_loss: 1.0690\n",
      "Epoch 105/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9933 - val_loss: 1.0690\n",
      "Epoch 106/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9932 - val_loss: 1.0689\n",
      "Epoch 107/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9932 - val_loss: 1.0689\n",
      "Epoch 108/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9932 - val_loss: 1.0688\n",
      "Epoch 109/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9931 - val_loss: 1.0688\n",
      "Epoch 110/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9931 - val_loss: 1.0688\n",
      "Epoch 111/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9931 - val_loss: 1.0687\n",
      "Epoch 112/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9931 - val_loss: 1.0687\n",
      "Epoch 113/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9931 - val_loss: 1.0687\n",
      "Epoch 114/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 1.0686\n",
      "Epoch 115/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 1.0686\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 1.0686\n",
      "Epoch 117/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 1.0685\n",
      "Epoch 118/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0685\n",
      "Epoch 119/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0685\n",
      "Epoch 120/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9929 - val_loss: 1.0685\n",
      "Epoch 121/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9929 - val_loss: 1.0684\n",
      "Epoch 122/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0684\n",
      "Epoch 123/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 1.0684\n",
      "Epoch 124/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0684\n",
      "Epoch 125/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0684\n",
      "Epoch 126/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9928 - val_loss: 1.0683\n",
      "Epoch 127/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0683\n",
      "Epoch 128/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0683\n",
      "Epoch 129/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0683\n",
      "Epoch 130/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0683\n",
      "Epoch 131/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0683\n",
      "Epoch 132/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 1.0682\n",
      "Epoch 133/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 1.0682\n",
      "Epoch 134/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 1.0682\n",
      "Epoch 135/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 1.0682\n",
      "Epoch 136/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 1.0682\n",
      "Epoch 137/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 1.0682\n",
      "Epoch 138/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 1.0682\n",
      "Epoch 139/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 1.0682\n",
      "Epoch 140/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 1.0681\n",
      "Epoch 141/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 1.0681\n",
      "Epoch 142/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 1.0681\n",
      "Epoch 143/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 1.0681\n",
      "Epoch 144/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 1.0681\n",
      "Epoch 145/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 1.0681\n",
      "Epoch 146/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 1.0681\n",
      "Epoch 147/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 1.0681\n",
      "Epoch 148/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9926 - val_loss: 1.0681\n",
      "Epoch 149/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9926 - val_loss: 1.0681\n",
      "Epoch 150/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9926 - val_loss: 1.0680\n",
      "Model: \"model_68\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_46 (InputLayer)        [(None, 36)]              0         \n",
      "_________________________________________________________________\n",
      "dense_252 (Dense)            (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 720)               26640     \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_45 (TFOpLam (None, 720)               0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_45 (TFOpLambda)  (None, 720)               0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_45 (TFOpL (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_45 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_45 (TFO ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_45 (AddLoss)        ()                        0         \n",
      "=================================================================\n",
      "Total params: 27,972\n",
      "Trainable params: 27,972\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 5.4446 - val_loss: 2.4233\n",
      "Epoch 2/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.9212 - val_loss: 1.5658\n",
      "Epoch 3/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.4230 - val_loss: 1.3136\n",
      "Epoch 4/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.2459 - val_loss: 1.2008\n",
      "Epoch 5/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.1652 - val_loss: 1.1458\n",
      "Epoch 6/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.1233 - val_loss: 1.1139\n",
      "Epoch 7/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.1004 - val_loss: 1.0950\n",
      "Epoch 8/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0855 - val_loss: 1.0834\n",
      "Epoch 9/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0769 - val_loss: 1.0762\n",
      "Epoch 10/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0715 - val_loss: 1.0714\n",
      "Epoch 11/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0677 - val_loss: 1.0679\n",
      "Epoch 12/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0650 - val_loss: 1.0655\n",
      "Epoch 13/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0631 - val_loss: 1.0637\n",
      "Epoch 14/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0616 - val_loss: 1.0623\n",
      "Epoch 15/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0605 - val_loss: 1.0612\n",
      "Epoch 16/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0595 - val_loss: 1.0603\n",
      "Epoch 17/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0588 - val_loss: 1.0595\n",
      "Epoch 18/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0582 - val_loss: 1.0589\n",
      "Epoch 19/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0578 - val_loss: 1.0584\n",
      "Epoch 20/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0574 - val_loss: 1.0580\n",
      "Epoch 21/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0571 - val_loss: 1.0577\n",
      "Epoch 22/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0568 - val_loss: 1.0574\n",
      "Epoch 23/100\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 1.0566 - val_loss: 1.0571\n",
      "Epoch 24/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0564 - val_loss: 1.0569\n",
      "Epoch 25/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0562 - val_loss: 1.0567\n",
      "Epoch 26/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0561 - val_loss: 1.0565\n",
      "Epoch 27/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0559 - val_loss: 1.0564\n",
      "Epoch 28/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0558 - val_loss: 1.0563\n",
      "Epoch 29/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0558 - val_loss: 1.0561\n",
      "Epoch 30/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0557 - val_loss: 1.0561\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0556 - val_loss: 1.0560\n",
      "Epoch 32/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0555 - val_loss: 1.0559\n",
      "Epoch 33/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0555 - val_loss: 1.0558\n",
      "Epoch 34/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0555 - val_loss: 1.0558\n",
      "Epoch 35/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0554 - val_loss: 1.0557\n",
      "Epoch 36/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0554 - val_loss: 1.0556\n",
      "Epoch 37/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0554 - val_loss: 1.0556\n",
      "Epoch 38/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0553 - val_loss: 1.0556\n",
      "Epoch 39/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0553 - val_loss: 1.0555\n",
      "Epoch 40/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0553 - val_loss: 1.0555\n",
      "Epoch 41/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0553 - val_loss: 1.0555\n",
      "Epoch 42/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0552 - val_loss: 1.0554\n",
      "Epoch 43/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0552 - val_loss: 1.0554\n",
      "Epoch 44/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0552 - val_loss: 1.0554\n",
      "Epoch 45/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0552 - val_loss: 1.0554\n",
      "Epoch 46/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0552 - val_loss: 1.0554\n",
      "Epoch 47/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0552 - val_loss: 1.0554\n",
      "Epoch 48/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0552 - val_loss: 1.0553\n",
      "Epoch 49/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0552 - val_loss: 1.0553\n",
      "Epoch 50/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0552 - val_loss: 1.0553\n",
      "Epoch 51/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0552 - val_loss: 1.0553\n",
      "Epoch 52/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0552 - val_loss: 1.0553\n",
      "Epoch 53/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0553\n",
      "Epoch 54/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0553\n",
      "Epoch 55/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0553\n",
      "Epoch 56/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0553\n",
      "Epoch 57/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0553\n",
      "Epoch 58/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 59/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 60/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 61/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 62/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 63/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 64/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 65/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 66/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 67/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 68/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 69/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 70/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 71/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 72/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 73/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 74/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 75/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 76/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 77/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 78/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 79/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 80/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 81/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 82/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 83/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 84/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 85/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 86/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 87/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 88/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 89/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 90/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 91/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 92/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 93/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 94/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 95/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 96/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 97/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 98/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 99/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 100/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_253 (Dense)            (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "dropout_184 (Dropout)        (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_254 (Dense)            (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "dropout_185 (Dropout)        (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_255 (Dense)            (None, 2)                 74        \n",
      "_________________________________________________________________\n",
      "dropout_186 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_256 (Dense)            (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_187 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_257 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_188 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_258 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_189 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_259 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_190 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_260 (Dense)            (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_191 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_261 (Dense)            (None, 36)                108       \n",
      "=================================================================\n",
      "Total params: 11,360\n",
      "Trainable params: 11,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 3ms/step - loss: 2.6584 - val_loss: 2.0132\n",
      "Epoch 2/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.8645 - val_loss: 1.6817\n",
      "Epoch 3/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.6264 - val_loss: 1.5073\n",
      "Epoch 4/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.4901 - val_loss: 1.4018\n",
      "Epoch 5/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.4092 - val_loss: 1.3335\n",
      "Epoch 6/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.3476 - val_loss: 1.2830\n",
      "Epoch 7/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.3042 - val_loss: 1.2468\n",
      "Epoch 8/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.2661 - val_loss: 1.2172\n",
      "Epoch 9/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.2413 - val_loss: 1.1947\n",
      "Epoch 10/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.2168 - val_loss: 1.1748\n",
      "Epoch 11/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.2010 - val_loss: 1.1577\n",
      "Epoch 12/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1822 - val_loss: 1.1444\n",
      "Epoch 13/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1691 - val_loss: 1.1313\n",
      "Epoch 14/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1572 - val_loss: 1.1207\n",
      "Epoch 15/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1426 - val_loss: 1.1114\n",
      "Epoch 16/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1348 - val_loss: 1.1026\n",
      "Epoch 17/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1246 - val_loss: 1.0952\n",
      "Epoch 18/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1168 - val_loss: 1.0883\n",
      "Epoch 19/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1085 - val_loss: 1.0819\n",
      "Epoch 20/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1006 - val_loss: 1.0763\n",
      "Epoch 21/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0925 - val_loss: 1.0713\n",
      "Epoch 22/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0897 - val_loss: 1.0666\n",
      "Epoch 23/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0829 - val_loss: 1.0622\n",
      "Epoch 24/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0784 - val_loss: 1.0581\n",
      "Epoch 25/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0730 - val_loss: 1.0544\n",
      "Epoch 26/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0694 - val_loss: 1.0509\n",
      "Epoch 27/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0663 - val_loss: 1.0476\n",
      "Epoch 28/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0606 - val_loss: 1.0445\n",
      "Epoch 29/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0579 - val_loss: 1.0416\n",
      "Epoch 30/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0543 - val_loss: 1.0390\n",
      "Epoch 31/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0518 - val_loss: 1.0364\n",
      "Epoch 32/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0479 - val_loss: 1.0341\n",
      "Epoch 33/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0464 - val_loss: 1.0318\n",
      "Epoch 34/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0430 - val_loss: 1.0297\n",
      "Epoch 35/150\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 1.0407 - val_loss: 1.0277\n",
      "Epoch 36/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0388 - val_loss: 1.0258\n",
      "Epoch 37/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0375 - val_loss: 1.0240\n",
      "Epoch 38/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0344 - val_loss: 1.0223\n",
      "Epoch 39/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0330 - val_loss: 1.0207\n",
      "Epoch 40/150\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 1.0307 - val_loss: 1.0192\n",
      "Epoch 41/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0294 - val_loss: 1.0178\n",
      "Epoch 42/150\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 1.0275 - val_loss: 1.0164\n",
      "Epoch 43/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0263 - val_loss: 1.0152\n",
      "Epoch 44/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0253 - val_loss: 1.0139\n",
      "Epoch 45/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0239 - val_loss: 1.0128\n",
      "Epoch 46/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0217 - val_loss: 1.0117\n",
      "Epoch 47/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0207 - val_loss: 1.0107\n",
      "Epoch 48/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0200 - val_loss: 1.0097\n",
      "Epoch 49/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0188 - val_loss: 1.0088\n",
      "Epoch 50/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0178 - val_loss: 1.0079\n",
      "Epoch 51/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0169 - val_loss: 1.0071\n",
      "Epoch 52/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0159 - val_loss: 1.0063\n",
      "Epoch 53/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0153 - val_loss: 1.0056\n",
      "Epoch 54/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0141 - val_loss: 1.0048\n",
      "Epoch 55/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0135 - val_loss: 1.0042\n",
      "Epoch 56/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0128 - val_loss: 1.0035\n",
      "Epoch 57/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0122 - val_loss: 1.0029\n",
      "Epoch 58/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0115 - val_loss: 1.0024\n",
      "Epoch 59/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0109 - val_loss: 1.0018\n",
      "Epoch 60/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0102 - val_loss: 1.0013\n",
      "Epoch 61/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0100 - val_loss: 1.0008\n",
      "Epoch 62/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0091 - val_loss: 1.0004\n",
      "Epoch 63/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0089 - val_loss: 1.0000\n",
      "Epoch 64/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0085 - val_loss: 0.9995\n",
      "Epoch 65/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0078 - val_loss: 0.9991\n",
      "Epoch 66/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0075 - val_loss: 0.9988\n",
      "Epoch 67/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0071 - val_loss: 0.9985\n",
      "Epoch 68/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0067 - val_loss: 0.9981\n",
      "Epoch 69/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0064 - val_loss: 0.9978\n",
      "Epoch 70/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0062 - val_loss: 0.9975\n",
      "Epoch 71/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0058 - val_loss: 0.9973\n",
      "Epoch 72/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0056 - val_loss: 0.9970\n",
      "Epoch 73/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0052 - val_loss: 0.9968\n",
      "Epoch 74/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0051 - val_loss: 0.9965\n",
      "Epoch 75/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0049 - val_loss: 0.9963\n",
      "Epoch 76/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0045 - val_loss: 0.9961\n",
      "Epoch 77/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0045 - val_loss: 0.9959\n",
      "Epoch 78/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0042 - val_loss: 0.9957\n",
      "Epoch 79/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0041 - val_loss: 0.9955\n",
      "Epoch 80/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0038 - val_loss: 0.9954\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0037 - val_loss: 0.9952\n",
      "Epoch 82/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0035 - val_loss: 0.9951\n",
      "Epoch 83/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0035 - val_loss: 0.9950\n",
      "Epoch 84/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0033 - val_loss: 0.9948\n",
      "Epoch 85/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0031 - val_loss: 0.9947\n",
      "Epoch 86/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0030 - val_loss: 0.9946\n",
      "Epoch 87/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0029 - val_loss: 0.9945\n",
      "Epoch 88/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0027 - val_loss: 0.9944\n",
      "Epoch 89/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0026 - val_loss: 0.9943\n",
      "Epoch 90/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0026 - val_loss: 0.9942\n",
      "Epoch 91/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0025 - val_loss: 0.9941\n",
      "Epoch 92/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0024 - val_loss: 0.9940\n",
      "Epoch 93/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0023 - val_loss: 0.9940\n",
      "Epoch 94/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0022 - val_loss: 0.9939\n",
      "Epoch 95/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0022 - val_loss: 0.9938\n",
      "Epoch 96/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0021 - val_loss: 0.9938\n",
      "Epoch 97/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0021 - val_loss: 0.9937\n",
      "Epoch 98/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0020 - val_loss: 0.9936\n",
      "Epoch 99/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0019 - val_loss: 0.9936\n",
      "Epoch 100/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0019 - val_loss: 0.9935\n",
      "Epoch 101/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0018 - val_loss: 0.9935\n",
      "Epoch 102/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0018 - val_loss: 0.9935\n",
      "Epoch 103/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0017 - val_loss: 0.9934\n",
      "Epoch 104/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0017 - val_loss: 0.9934\n",
      "Epoch 105/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0017 - val_loss: 0.9933\n",
      "Epoch 106/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0016 - val_loss: 0.9933\n",
      "Epoch 107/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0016 - val_loss: 0.9933\n",
      "Epoch 108/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0016 - val_loss: 0.9932\n",
      "Epoch 109/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0015 - val_loss: 0.9932\n",
      "Epoch 110/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0015 - val_loss: 0.9932\n",
      "Epoch 111/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0015 - val_loss: 0.9932\n",
      "Epoch 112/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0014 - val_loss: 0.9931\n",
      "Epoch 113/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0014 - val_loss: 0.9931\n",
      "Epoch 114/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0014 - val_loss: 0.9931\n",
      "Epoch 115/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0014 - val_loss: 0.9931\n",
      "Epoch 116/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0013 - val_loss: 0.9930\n",
      "Epoch 117/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0013 - val_loss: 0.9930\n",
      "Epoch 118/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0013 - val_loss: 0.9930\n",
      "Epoch 119/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0013 - val_loss: 0.9930\n",
      "Epoch 120/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0013 - val_loss: 0.9930\n",
      "Epoch 121/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0013 - val_loss: 0.9930\n",
      "Epoch 122/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0012 - val_loss: 0.9929\n",
      "Epoch 123/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0012 - val_loss: 0.9929\n",
      "Epoch 124/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0012 - val_loss: 0.9929\n",
      "Epoch 125/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0012 - val_loss: 0.9929\n",
      "Epoch 126/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0012 - val_loss: 0.9929\n",
      "Epoch 127/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0012 - val_loss: 0.9929\n",
      "Epoch 128/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0011 - val_loss: 0.9929\n",
      "Epoch 129/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0011 - val_loss: 0.9929\n",
      "Epoch 130/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0011 - val_loss: 0.9928\n",
      "Epoch 131/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0011 - val_loss: 0.9928\n",
      "Epoch 132/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0011 - val_loss: 0.9928\n",
      "Epoch 133/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0011 - val_loss: 0.9928\n",
      "Epoch 134/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0011 - val_loss: 0.9928\n",
      "Epoch 135/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0011 - val_loss: 0.9928\n",
      "Epoch 136/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0011 - val_loss: 0.9928\n",
      "Epoch 137/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0011 - val_loss: 0.9928\n",
      "Epoch 138/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0011 - val_loss: 0.9928\n",
      "Epoch 139/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0010 - val_loss: 0.9928\n",
      "Epoch 140/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0010 - val_loss: 0.9928\n",
      "Epoch 141/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0010 - val_loss: 0.9928\n",
      "Epoch 142/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0010 - val_loss: 0.9928\n",
      "Epoch 143/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0010 - val_loss: 0.9928\n",
      "Epoch 144/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0010 - val_loss: 0.9927\n",
      "Epoch 145/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0010 - val_loss: 0.9927\n",
      "Epoch 146/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0010 - val_loss: 0.9927\n",
      "Epoch 147/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0010 - val_loss: 0.9927\n",
      "Epoch 148/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0010 - val_loss: 0.9927\n",
      "Epoch 149/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0010 - val_loss: 0.9927\n",
      "Epoch 150/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0010 - val_loss: 0.9927\n",
      "Model: \"model_71\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_48 (InputLayer)        [(None, 36)]              0         \n",
      "_________________________________________________________________\n",
      "dense_263 (Dense)            (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 720)               26640     \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_47 (TFOpLam (None, 720)               0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_47 (TFOpLambda)  (None, 720)               0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_47 (TFOpL (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_47 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_47 (TFO ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_47 (AddLoss)        ()                        0         \n",
      "=================================================================\n",
      "Total params: 27,972\n",
      "Trainable params: 27,972\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 2ms/step - loss: 5.5754 - val_loss: 2.4904\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.9711 - val_loss: 1.6125\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.4486 - val_loss: 1.3360\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.2605 - val_loss: 1.2121\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.1740 - val_loss: 1.1489\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.1287 - val_loss: 1.1145\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.1034 - val_loss: 1.0945\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0883 - val_loss: 1.0823\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0790 - val_loss: 1.0747\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0729 - val_loss: 1.0699\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0688 - val_loss: 1.0664\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0658 - val_loss: 1.0640\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0637 - val_loss: 1.0624\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0621 - val_loss: 1.0610\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0608 - val_loss: 1.0600\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0598 - val_loss: 1.0592\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0591 - val_loss: 1.0586\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0584 - val_loss: 1.0580\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0579 - val_loss: 1.0576\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0575 - val_loss: 1.0572\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0571 - val_loss: 1.0569\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0569 - val_loss: 1.0567\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0566 - val_loss: 1.0565\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0564 - val_loss: 1.0563\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0562 - val_loss: 1.0562\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0561 - val_loss: 1.0561\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0559 - val_loss: 1.0559\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0558 - val_loss: 1.0558\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0557 - val_loss: 1.0558\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0556 - val_loss: 1.0557\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0556 - val_loss: 1.0556\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0555 - val_loss: 1.0555\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0555 - val_loss: 1.0555\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0554 - val_loss: 1.0555\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0554 - val_loss: 1.0554\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0553 - val_loss: 1.0554\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0553 - val_loss: 1.0553\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0553 - val_loss: 1.0553\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0552 - val_loss: 1.0553\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0552 - val_loss: 1.0553\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0552 - val_loss: 1.0553\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0552 - val_loss: 1.0552\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0552 - val_loss: 1.0552\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0552 - val_loss: 1.0552\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0552\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0551\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0551\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0551\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0551\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0551\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0551\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0551\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0551\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0551\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0551\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0551\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0551 - val_loss: 1.0551\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0550 - val_loss: 1.0551\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_264 (Dense)            (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "dropout_192 (Dropout)        (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_265 (Dense)            (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "dropout_193 (Dropout)        (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_266 (Dense)            (None, 2)                 74        \n",
      "_________________________________________________________________\n",
      "dropout_194 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_267 (Dense)            (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dropout_195 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_268 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_196 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_269 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_197 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_270 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_198 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_271 (Dense)            (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_199 (Dropout)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_272 (Dense)            (None, 36)                108       \n",
      "=================================================================\n",
      "Total params: 11,360\n",
      "Trainable params: 11,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "114/114 [==============================] - 1s 3ms/step - loss: 2.6244 - val_loss: 2.1794\n",
      "Epoch 2/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.8436 - val_loss: 1.8236\n",
      "Epoch 3/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.6114 - val_loss: 1.6341\n",
      "Epoch 4/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.4783 - val_loss: 1.5212\n",
      "Epoch 5/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.3899 - val_loss: 1.4470\n",
      "Epoch 6/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.3297 - val_loss: 1.3936\n",
      "Epoch 7/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.2919 - val_loss: 1.3520\n",
      "Epoch 8/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.2612 - val_loss: 1.3212\n",
      "Epoch 9/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.2255 - val_loss: 1.2942\n",
      "Epoch 10/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.2069 - val_loss: 1.2738\n",
      "Epoch 11/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1880 - val_loss: 1.2545\n",
      "Epoch 12/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1714 - val_loss: 1.2409\n",
      "Epoch 13/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1560 - val_loss: 1.2290\n",
      "Epoch 14/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1425 - val_loss: 1.2165\n",
      "Epoch 15/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1346 - val_loss: 1.2046\n",
      "Epoch 16/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1217 - val_loss: 1.1948\n",
      "Epoch 17/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1159 - val_loss: 1.1865\n",
      "Epoch 18/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.1039 - val_loss: 1.1791\n",
      "Epoch 19/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.1022 - val_loss: 1.1720\n",
      "Epoch 20/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0891 - val_loss: 1.1657\n",
      "Epoch 21/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0849 - val_loss: 1.1600\n",
      "Epoch 22/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0787 - val_loss: 1.1546\n",
      "Epoch 23/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0741 - val_loss: 1.1497\n",
      "Epoch 24/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0687 - val_loss: 1.1452\n",
      "Epoch 25/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0661 - val_loss: 1.1410\n",
      "Epoch 26/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0577 - val_loss: 1.1367\n",
      "Epoch 27/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0544 - val_loss: 1.1331\n",
      "Epoch 28/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0529 - val_loss: 1.1296\n",
      "Epoch 29/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0482 - val_loss: 1.1264\n",
      "Epoch 30/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0454 - val_loss: 1.1235\n",
      "Epoch 31/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0421 - val_loss: 1.1206\n",
      "Epoch 32/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0399 - val_loss: 1.1178\n",
      "Epoch 33/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0359 - val_loss: 1.1152\n",
      "Epoch 34/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0338 - val_loss: 1.1127\n",
      "Epoch 35/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0326 - val_loss: 1.1103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0307 - val_loss: 1.1082\n",
      "Epoch 37/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0271 - val_loss: 1.1059\n",
      "Epoch 38/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0260 - val_loss: 1.1039\n",
      "Epoch 39/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0236 - val_loss: 1.1020\n",
      "Epoch 40/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0221 - val_loss: 1.1003\n",
      "Epoch 41/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0194 - val_loss: 1.0985\n",
      "Epoch 42/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0193 - val_loss: 1.0971\n",
      "Epoch 43/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0181 - val_loss: 1.0957\n",
      "Epoch 44/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0156 - val_loss: 1.0941\n",
      "Epoch 45/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0147 - val_loss: 1.0925\n",
      "Epoch 46/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0132 - val_loss: 1.0912\n",
      "Epoch 47/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0120 - val_loss: 1.0899\n",
      "Epoch 48/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0110 - val_loss: 1.0889\n",
      "Epoch 49/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0100 - val_loss: 1.0877\n",
      "Epoch 50/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0087 - val_loss: 1.0867\n",
      "Epoch 51/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0083 - val_loss: 1.0857\n",
      "Epoch 52/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0074 - val_loss: 1.0845\n",
      "Epoch 53/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0066 - val_loss: 1.0836\n",
      "Epoch 54/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0058 - val_loss: 1.0826\n",
      "Epoch 55/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0053 - val_loss: 1.0819\n",
      "Epoch 56/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0044 - val_loss: 1.0809\n",
      "Epoch 57/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0036 - val_loss: 1.0802\n",
      "Epoch 58/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0032 - val_loss: 1.0794\n",
      "Epoch 59/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0024 - val_loss: 1.0787\n",
      "Epoch 60/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0020 - val_loss: 1.0780\n",
      "Epoch 61/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 1.0013 - val_loss: 1.0773\n",
      "Epoch 62/150\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.996 - 0s 2ms/step - loss: 1.0008 - val_loss: 1.0767\n",
      "Epoch 63/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1.0005 - val_loss: 1.0762\n",
      "Epoch 64/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 1.0755\n",
      "Epoch 65/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 1.0750\n",
      "Epoch 66/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9993 - val_loss: 1.0744\n",
      "Epoch 67/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 1.0739\n",
      "Epoch 68/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 1.0736\n",
      "Epoch 69/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 1.0729\n",
      "Epoch 70/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9980 - val_loss: 1.0725\n",
      "Epoch 71/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9976 - val_loss: 1.0722\n",
      "Epoch 72/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9974 - val_loss: 1.0718\n",
      "Epoch 73/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9972 - val_loss: 1.0715\n",
      "Epoch 74/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 1.0710\n",
      "Epoch 75/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9967 - val_loss: 1.0707\n",
      "Epoch 76/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9964 - val_loss: 1.0702\n",
      "Epoch 77/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9964 - val_loss: 1.0701\n",
      "Epoch 78/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9961 - val_loss: 1.0697\n",
      "Epoch 79/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9960 - val_loss: 1.0695\n",
      "Epoch 80/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9958 - val_loss: 1.0692\n",
      "Epoch 81/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9956 - val_loss: 1.0688\n",
      "Epoch 82/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9955 - val_loss: 1.0686\n",
      "Epoch 83/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9953 - val_loss: 1.0683\n",
      "Epoch 84/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9953 - val_loss: 1.0682\n",
      "Epoch 85/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9951 - val_loss: 1.0679\n",
      "Epoch 86/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9950 - val_loss: 1.0677\n",
      "Epoch 87/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9949 - val_loss: 1.0675\n",
      "Epoch 88/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9948 - val_loss: 1.0673\n",
      "Epoch 89/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9947 - val_loss: 1.0671\n",
      "Epoch 90/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9946 - val_loss: 1.0669\n",
      "Epoch 91/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9946 - val_loss: 1.0668\n",
      "Epoch 92/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9945 - val_loss: 1.0666\n",
      "Epoch 93/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9944 - val_loss: 1.0664\n",
      "Epoch 94/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9943 - val_loss: 1.0663\n",
      "Epoch 95/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9943 - val_loss: 1.0662\n",
      "Epoch 96/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9942 - val_loss: 1.0661\n",
      "Epoch 97/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9942 - val_loss: 1.0658\n",
      "Epoch 98/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9941 - val_loss: 1.0657\n",
      "Epoch 99/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9940 - val_loss: 1.0656\n",
      "Epoch 100/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9940 - val_loss: 1.0655\n",
      "Epoch 101/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9940 - val_loss: 1.0654\n",
      "Epoch 102/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9939 - val_loss: 1.0653\n",
      "Epoch 103/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9939 - val_loss: 1.0652\n",
      "Epoch 104/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9938 - val_loss: 1.0651\n",
      "Epoch 105/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9938 - val_loss: 1.0650\n",
      "Epoch 106/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9938 - val_loss: 1.0649\n",
      "Epoch 107/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9938 - val_loss: 1.0648\n",
      "Epoch 108/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9937 - val_loss: 1.0648\n",
      "Epoch 109/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9937 - val_loss: 1.0646\n",
      "Epoch 110/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9937 - val_loss: 1.0646\n",
      "Epoch 111/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9936 - val_loss: 1.0645\n",
      "Epoch 112/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9936 - val_loss: 1.0645\n",
      "Epoch 113/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9936 - val_loss: 1.0644\n",
      "Epoch 114/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9936 - val_loss: 1.0643\n",
      "Epoch 115/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9936 - val_loss: 1.0642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9935 - val_loss: 1.0642\n",
      "Epoch 117/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9935 - val_loss: 1.0641\n",
      "Epoch 118/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9935 - val_loss: 1.0641\n",
      "Epoch 119/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9935 - val_loss: 1.0640\n",
      "Epoch 120/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9935 - val_loss: 1.0640\n",
      "Epoch 121/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9935 - val_loss: 1.0639\n",
      "Epoch 122/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9934 - val_loss: 1.0639\n",
      "Epoch 123/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9934 - val_loss: 1.0638\n",
      "Epoch 124/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9934 - val_loss: 1.0638\n",
      "Epoch 125/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9934 - val_loss: 1.0637\n",
      "Epoch 126/150\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.991 - 0s 2ms/step - loss: 0.9934 - val_loss: 1.0637\n",
      "Epoch 127/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9934 - val_loss: 1.0637\n",
      "Epoch 128/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9934 - val_loss: 1.0636\n",
      "Epoch 129/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9934 - val_loss: 1.0636\n",
      "Epoch 130/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9934 - val_loss: 1.0636\n",
      "Epoch 131/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9934 - val_loss: 1.0635\n",
      "Epoch 132/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9933 - val_loss: 1.0635\n",
      "Epoch 133/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9933 - val_loss: 1.0634\n",
      "Epoch 134/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9933 - val_loss: 1.0634\n",
      "Epoch 135/150\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 0.9933 - val_loss: 1.0634\n",
      "Epoch 136/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9933 - val_loss: 1.0634\n",
      "Epoch 137/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9933 - val_loss: 1.0633\n",
      "Epoch 138/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9933 - val_loss: 1.0633\n",
      "Epoch 139/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9933 - val_loss: 1.0633\n",
      "Epoch 140/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9933 - val_loss: 1.0632\n",
      "Epoch 141/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9933 - val_loss: 1.0632\n",
      "Epoch 142/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9933 - val_loss: 1.0632\n",
      "Epoch 143/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9933 - val_loss: 1.0632\n",
      "Epoch 144/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9933 - val_loss: 1.0631\n",
      "Epoch 145/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9933 - val_loss: 1.0631\n",
      "Epoch 146/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9933 - val_loss: 1.0631\n",
      "Epoch 147/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9933 - val_loss: 1.0631\n",
      "Epoch 148/150\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.9933 - val_loss: 1.0630\n",
      "Epoch 149/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9933 - val_loss: 1.0630\n",
      "Epoch 150/150\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 0.9932 - val_loss: 1.0630\n",
      "Model: \"model_74\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_50 (InputLayer)        [(None, 36)]              0         \n",
      "_________________________________________________________________\n",
      "dense_274 (Dense)            (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 720)               26640     \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_49 (TFOpLam (None, 720)               0         \n",
      "_________________________________________________________________\n",
      "tf.math.pow_49 (TFOpLambda)  (None, 720)               0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum_49 (TFOpL (None,)                   0         \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean_49 (TFOp ()                        0         \n",
      "_________________________________________________________________\n",
      "tf.__operators__.add_49 (TFO ()                        0         \n",
      "_________________________________________________________________\n",
      "add_loss_49 (AddLoss)        ()                        0         \n",
      "=================================================================\n",
      "Total params: 27,972\n",
      "Trainable params: 27,972\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 5.5301 - val_loss: 2.3715\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.9473 - val_loss: 1.5417\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.4274 - val_loss: 1.2871\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.2472 - val_loss: 1.1821\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.1651 - val_loss: 1.1309\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.1227 - val_loss: 1.1026\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0990 - val_loss: 1.0864\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0848 - val_loss: 1.0765\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0759 - val_loss: 1.0701\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0702 - val_loss: 1.0660\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0663 - val_loss: 1.0631\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0635 - val_loss: 1.0612\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0615 - val_loss: 1.0597\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0600 - val_loss: 1.0586\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0588 - val_loss: 1.0577\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0579 - val_loss: 1.0570\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0571 - val_loss: 1.0565\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0566 - val_loss: 1.0561\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0561 - val_loss: 1.0557\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0557 - val_loss: 1.0554\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0553 - val_loss: 1.0552\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0551 - val_loss: 1.0550\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0548 - val_loss: 1.0548\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0546 - val_loss: 1.0546\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0545 - val_loss: 1.0545\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0543 - val_loss: 1.0544\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0542 - val_loss: 1.0543\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0541 - val_loss: 1.0542\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0540 - val_loss: 1.0541\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0539 - val_loss: 1.0541\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0539 - val_loss: 1.0540\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0538 - val_loss: 1.0539\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0537 - val_loss: 1.0539\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0537 - val_loss: 1.0539\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0537 - val_loss: 1.0538\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0536 - val_loss: 1.0538\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0536 - val_loss: 1.0538\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0536 - val_loss: 1.0537\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0536 - val_loss: 1.0537\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0535 - val_loss: 1.0537\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0535 - val_loss: 1.0537\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0535 - val_loss: 1.0537\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0535 - val_loss: 1.0536\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0535 - val_loss: 1.0536\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0535 - val_loss: 1.0536\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0536\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0536\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0536\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0536\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0536\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0536\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.0534 - val_loss: 1.0535\n"
     ]
    }
   ],
   "source": [
    "mnist=pd.read_csv(\"mnist.csv\")\n",
    "musk=pd.read_csv(\"musk.csv\")\n",
    "optdigit=pd.read_csv(\"optdigits.csv\")\n",
    "pendigits=pd.read_csv(\"pendigits.csv\")\n",
    "satimage_2=pd.read_csv(\"satimage-2.csv\")\n",
    "dataset={\"mnist\":mnist,\"musk\":musk,\"optdigit\":optdigit,\"pendigits\":pendigits,\"satimage_2\":satimage_2}\n",
    "\n",
    "\n",
    "table_roc=pd.DataFrame()\n",
    "table_recall=pd.DataFrame()\n",
    "\n",
    "for name,data in dataset.items():\n",
    "    print(\"第\",name ,'個資料處理中....')\n",
    "    print(\"\")\n",
    "\n",
    "    #降維\n",
    "    import umap\n",
    "    reducer = umap.UMAP(random_state=69,n_neighbors=20, min_dist=0.3, n_components=2, metric='manhattan')\n",
    "    data_umap = reducer.fit_transform(data.iloc[:,0:-1])\n",
    "    \n",
    "    #split train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,0:-1],data[\"outlier\"], test_size=0.06, random_state=69)\n",
    "    X_train_umap, X_test_umap, y_train, y_test = train_test_split(data_umap,data[\"outlier\"], test_size=0.06, random_state=69)\n",
    "    \n",
    "    # standardizing data for processing\n",
    "    X_train_norm, X_test_norm = standardizer(X_train, X_test)\n",
    "    \n",
    "    roc_df=pd.DataFrame()\n",
    "    recall_df=pd.DataFrame()\n",
    "    for time in range(5):\n",
    "        \n",
    "        #split train/valid\n",
    "        X, X_valid_norm, y, y_valid = train_test_split(X_train_norm,y_train, test_size=0.25, random_state=time)\n",
    "        X_umap, X_valid_norm_umap, y, y_valid = train_test_split(X_train_umap,y_train, test_size=0.25, random_state=time)\n",
    "\n",
    "        # count outliers_ratio\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        outliers_fraction=counts[1]/counts[0]\n",
    "\n",
    "        #roc_list,recall_list\n",
    "        roc_list=[]\n",
    "        recall_list=[]\n",
    "\n",
    "        classifiers = {'One-class SVM (OCSVM)':OCSVM(contamination=outliers_fraction),\n",
    "                    'Local Outlier Factor (LOF)': LOF(contamination=outliers_fraction,n_neighbors=110),\n",
    "                    'Isolation Forest': IForest(contamination=outliers_fraction,n_estimators=200,random_state=69),\n",
    "                    'AutoEncoder': AutoEncoder(hidden_neurons=[2, 32,64,64, 32, 2],contamination=outliers_fraction,random_state=69,epochs=150),\n",
    "                    'DeepSVDD':DeepSVDD(hidden_neurons=[X.shape[1],X.shape[1]*20], contamination=outliers_fraction,random_state=69,epochs=100,validation_size=0.05) }\n",
    "\n",
    "        for clf_name, clf in classifiers.items():\n",
    "\n",
    "            # Build the Model\n",
    "            clf_name = clf_name\n",
    "            clf = clf\n",
    "\n",
    "            # Fit detector\n",
    "            clf.fit(X[y == 0])\n",
    "            # valid data\n",
    "            y_pred = clf.predict(X) \n",
    "            y_scores = clf.decision_function(X)\n",
    "\n",
    "            roc_list.append(evaluate_print(clf_name, y, y_scores)[0])\n",
    "            recall_list.append(evaluate_print(clf_name, y, y_scores)[1])\n",
    "\n",
    "        temp_df = pd.DataFrame(roc_list)\n",
    "        temp_df.index = classifiers.keys()\n",
    "        roc_df = pd.concat([roc_df, temp_df], axis=1)\n",
    "\n",
    "        temp_df = pd.DataFrame(recall_list)\n",
    "        temp_df.index = classifiers.keys()\n",
    "        recall_df = pd.concat([recall_df, temp_df], axis=1)\n",
    "        \n",
    "    #average 5 times \n",
    "    table_roc=pd.concat([table_roc, roc_df.mean(axis=1)], axis=1)\n",
    "    table_recall=pd.concat([table_recall,recall_df.mean(axis=1)], axis=1)\n",
    "\n",
    "table_roc.columns=['mnist','musk','optdigits','pendigits','satimage-2']\n",
    "table_recall.columns=['mnist','musk','optdigits','pendigits','satimage-2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5c0ad30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mnist</th>\n",
       "      <th>musk</th>\n",
       "      <th>optdigits</th>\n",
       "      <th>pendigits</th>\n",
       "      <th>satimage-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>One-class SVM (OCSVM)</th>\n",
       "      <td>0.87772</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.60342</td>\n",
       "      <td>0.96430</td>\n",
       "      <td>0.99636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Local Outlier Factor (LOF)</th>\n",
       "      <td>0.93652</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.91218</td>\n",
       "      <td>0.97948</td>\n",
       "      <td>0.99702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Isolation Forest</th>\n",
       "      <td>0.86552</td>\n",
       "      <td>0.98884</td>\n",
       "      <td>0.84948</td>\n",
       "      <td>0.97602</td>\n",
       "      <td>0.99244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AutoEncoder</th>\n",
       "      <td>0.90326</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.56820</td>\n",
       "      <td>0.94272</td>\n",
       "      <td>0.97804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSVDD</th>\n",
       "      <td>0.71202</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.52062</td>\n",
       "      <td>0.40054</td>\n",
       "      <td>0.51184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              mnist     musk  optdigits  pendigits  satimage-2\n",
       "One-class SVM (OCSVM)       0.87772  1.00000    0.60342    0.96430     0.99636\n",
       "Local Outlier Factor (LOF)  0.93652  1.00000    0.91218    0.97948     0.99702\n",
       "Isolation Forest            0.86552  0.98884    0.84948    0.97602     0.99244\n",
       "AutoEncoder                 0.90326  1.00000    0.56820    0.94272     0.97804\n",
       "DeepSVDD                    0.71202  1.00000    0.52062    0.40054     0.51184"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "098b7a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mnist</th>\n",
       "      <th>musk</th>\n",
       "      <th>optdigits</th>\n",
       "      <th>pendigits</th>\n",
       "      <th>satimage-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>One-class SVM (OCSVM)</th>\n",
       "      <td>0.44394</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.44198</td>\n",
       "      <td>0.92870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Local Outlier Factor (LOF)</th>\n",
       "      <td>0.61770</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.01352</td>\n",
       "      <td>0.44326</td>\n",
       "      <td>0.85148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Isolation Forest</th>\n",
       "      <td>0.41854</td>\n",
       "      <td>0.68452</td>\n",
       "      <td>0.06400</td>\n",
       "      <td>0.49382</td>\n",
       "      <td>0.86588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AutoEncoder</th>\n",
       "      <td>0.55492</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.34414</td>\n",
       "      <td>0.83726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSVDD</th>\n",
       "      <td>0.52176</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.28556</td>\n",
       "      <td>0.01622</td>\n",
       "      <td>0.09106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              mnist     musk  optdigits  pendigits  satimage-2\n",
       "One-class SVM (OCSVM)       0.44394  1.00000    0.00000    0.44198     0.92870\n",
       "Local Outlier Factor (LOF)  0.61770  1.00000    0.01352    0.44326     0.85148\n",
       "Isolation Forest            0.41854  0.68452    0.06400    0.49382     0.86588\n",
       "AutoEncoder                 0.55492  1.00000    0.00000    0.34414     0.83726\n",
       "DeepSVDD                    0.52176  1.00000    0.28556    0.01622     0.09106"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d727d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_roc.to_csv(\"table_roc_70.csv\")\n",
    "table_recall.to_csv(\"table_recall_70.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a72e04",
   "metadata": {},
   "source": [
    "# part data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "002bc7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv(\"mnist.csv\")\n",
    "data2=pd.read_csv(\"musk.csv\")\n",
    "data3=pd.read_csv(\"optdigits.csv\")\n",
    "data4=pd.read_csv(\"pendigits.csv\")\n",
    "data5=pd.read_csv(\"satimage-2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd34cb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1： 7603\n",
      "data2： 3062\n",
      "data3： 5216\n",
      "data4： 6870\n",
      "data5： 5803\n"
     ]
    }
   ],
   "source": [
    "print(\"data1：\",data1[\"outlier\"].count())\n",
    "print(\"data2：\",data2[\"outlier\"].count())\n",
    "print(\"data3：\",data3[\"outlier\"].count())\n",
    "print(\"data4：\",data4[\"outlier\"].count())\n",
    "print(\"data5：\",data5[\"outlier\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d09f2cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1： 0.092\n",
      "data2： 0.032\n",
      "data3： 0.029\n",
      "data4： 0.023\n",
      "data5： 0.012\n"
     ]
    }
   ],
   "source": [
    "print(\"data1：\",round(data1[\"outlier\"].mean(),3))\n",
    "print(\"data2：\",round(data2[\"outlier\"].mean(),3))\n",
    "print(\"data3：\",round(data3[\"outlier\"].mean(),3))\n",
    "print(\"data4：\",round(data4[\"outlier\"].mean(),3))\n",
    "print(\"data5：\",round(data5[\"outlier\"].mean(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39733809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "reducer = umap.UMAP(random_state=69,n_neighbors=20, min_dist=0.3, n_components=2, metric='manhattan')\n",
    "data_umap = reducer.fit_transform(data.iloc[:,0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1aa096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,0:-1],data[\"outlier\"], test_size=0.06, random_state=69)\n",
    "X_train_umap, X_test_umap, y_train, y_test = train_test_split(data_umap,data[\"outlier\"], test_size=0.06, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd8e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#標準化影響one class\n",
    "from pyod.utils.utility import standardizer\n",
    "# standardizing data for processing\n",
    "X_train_norm, X_test_norm = standardizer(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82612731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 mnist 個資料處理中....\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10336/2386063910.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mumap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mreducer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mumap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUMAP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m69\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_dist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'manhattan'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mdata_umap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreducer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m#split train/test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\umap\\umap_.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   2770\u001b[0m             \u001b[0mLocal\u001b[0m \u001b[0mradii\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mpoints\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0membedding\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtransformed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2771\u001b[0m         \"\"\"\n\u001b[1;32m-> 2772\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2773\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"embedding\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2774\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_dens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\umap\\umap_.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   2686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m                 \u001b[0minit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2688\u001b[1;33m                 \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# JH why raw data?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2689\u001b[0m             )\n\u001b[0;32m   2690\u001b[0m             \u001b[1;31m# Assign any points that are fully disconnected from our manifold(s) to have embedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\umap\\umap_.py\u001b[0m in \u001b[0;36m_fit_embed_data\u001b[1;34m(self, X, n_epochs, init, random_state)\u001b[0m\n\u001b[0;32m   2737\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2738\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2739\u001b[1;33m             \u001b[0mtqdm_kwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtqdm_kwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2740\u001b[0m         )\n\u001b[0;32m   2741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\umap\\umap_.py\u001b[0m in \u001b[0;36msimplicial_set_embedding\u001b[1;34m(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, densmap, densmap_kwds, output_dens, output_metric, output_metric_kwds, euclidean_output, parallel, verbose, tqdm_kwds)\u001b[0m\n\u001b[0;32m   1173\u001b[0m             \u001b[0mdensmap_kwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdensmap_kwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m             \u001b[0mtqdm_kwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtqdm_kwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m             \u001b[0mmove_other\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1176\u001b[0m         )\n\u001b[0;32m   1177\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\umap\\layouts.py\u001b[0m in \u001b[0;36moptimize_layout_euclidean\u001b[1;34m(head_embedding, tail_embedding, head, tail, n_epochs, n_vertices, epochs_per_sample, a, b, rng_state, gamma, initial_alpha, negative_sample_rate, parallel, verbose, densmap, densmap_kwds, tqdm_kwds, move_other)\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[0mdens_R\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[0mdens_mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m             \u001b[0mdens_mu_tot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m         )\n\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numba\\core\\dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[1;34m(self, *args, **kws)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[0mreturn_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mreturn_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mForceLiteralArg\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;31m# Received request for compiler re-entry with the list of arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numba\\core\\dispatcher.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, sig)\u001b[0m\n\u001b[0;32m    977\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrigger_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"numba:compile\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mev_details\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 979\u001b[1;33m                         \u001b[0mcres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    980\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mForceLiteralArg\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m                         \u001b[1;32mdef\u001b[0m \u001b[0mfolded\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numba\\core\\dispatcher.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, args, return_type)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compile_cached\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numba\\core\\dispatcher.py\u001b[0m in \u001b[0;36m_compile_cached\u001b[1;34m(self, args, return_type)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compile_core\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTypingError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_failed_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numba\\core\\dispatcher.py\u001b[0m in \u001b[0;36m_compile_core\u001b[1;34m(self, args, return_type)\u001b[0m\n\u001b[0;32m    171\u001b[0m                                       \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                                       \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m                                       pipeline_class=self.pipeline_class)\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[1;31m# Check typing error if object mode is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtyping_error\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_pyobject\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numba\\core\\compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[1;34m(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\u001b[0m\n\u001b[0;32m    684\u001b[0m     pipeline = pipeline_class(typingctx, targetctx, library,\n\u001b[0;32m    685\u001b[0m                               args, return_type, flags, locals)\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_extra\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numba\\core\\compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlifted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlifted_from\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compile_bytecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompile_ir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc_ir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlifted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlifted_from\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numba\\core\\compiler.py\u001b[0m in \u001b[0;36m_compile_bytecode\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m    491\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc_ir\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compile_core\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_compile_ir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numba\\core\\compiler.py\u001b[0m in \u001b[0;36m_compile_core\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    460\u001b[0m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m                     \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numba\\core\\compiler_machinery.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    332\u001b[0m                 \u001b[0mpass_inst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pass_registry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpass_inst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpass_inst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCompilerPass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_runPass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpass_inst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Legacy pass in use\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numba\\core\\compiler_lock.py\u001b[0m in \u001b[0;36m_acquire_compile_lock\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numba\\core\\compiler_machinery.py\u001b[0m in \u001b[0;36m_runPass\u001b[1;34m(self, index, pss, internal_state)\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[0mmutated\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_initialization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minternal_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSimpleTimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpass_time\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m             \u001b[0mmutated\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_pass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minternal_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSimpleTimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfinalize_time\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[0mmutated\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_finalizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minternal_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numba\\core\\compiler_machinery.py\u001b[0m in \u001b[0;36mcheck\u001b[1;34m(func, compiler_state)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompiler_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             \u001b[0mmangled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompiler_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmangled\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m                 msg = (\"CompilerPass implementations should return True/False. \"\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numba\\core\\typed_passes.py\u001b[0m in \u001b[0;36mrun_pass\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    394\u001b[0m                 lower = lowering.Lower(targetctx, library, fndesc, interp,\n\u001b[0;32m    395\u001b[0m                                        metadata=metadata)\n\u001b[1;32m--> 396\u001b[1;33m                 \u001b[0mlower\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_cpython_wrapper\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m                     \u001b[0mlower\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_cpython_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease_gil\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numba\\core\\lowering.py\u001b[0m in \u001b[0;36mlower\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator_info\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenlower\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower_normal_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfndesc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenlower\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGeneratorLower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numba\\core\\lowering.py\u001b[0m in \u001b[0;36mlower_normal_function\u001b[1;34m(self, fndesc)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;31m# Init argument values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_function_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m         \u001b[0mentry_block_tail\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower_function_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;31m# Close tail of entry block, do not emit debug metadata else the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numba\\core\\lowering.py\u001b[0m in \u001b[0;36mlower_function_body\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[0mbb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblkmap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_at_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_lower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mentry_block_tail\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numba\\core\\lowering.py\u001b[0m in \u001b[0;36mlower_block\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m    233\u001b[0m             with new_error_context('lowering \"{inst}\" at {loc}', inst=inst,\n\u001b[0;32m    234\u001b[0m                                    loc=self.loc, errcls_=defaulterrcls):\n\u001b[1;32m--> 235\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower_inst\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numba\\core\\lowering.py\u001b[0m in \u001b[0;36mlower_inst\u001b[1;34m(self, inst)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mir\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mir\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSetAttr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numba\\core\\lowering.py\u001b[0m in \u001b[0;36mdelvar\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1378\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m             \u001b[0mptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1380\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1381\u001b[0m             \u001b[1;31m# Zero-fill variable to avoid double frees on subsequent dels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1382\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpointee\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\llvmlite\\ir\\builder.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, ptr, name, align)\u001b[0m\n\u001b[0;32m    761\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"cannot load from value of type %s (%r): not a pointer\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m         \u001b[0mld\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstructions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLoadInstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mptr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m         \u001b[0mld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malign\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malign\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\llvmlite\\ir\\instructions.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, parent, ptr, name)\u001b[0m\n\u001b[0;32m    394\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mptr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         super(LoadInstr, self).__init__(parent, ptr.type.pointee, \"load\",\n\u001b[1;32m--> 396\u001b[1;33m                                         [ptr], name=name)\n\u001b[0m\u001b[0;32m    397\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malign\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\llvmlite\\ir\\instructions.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, parent, typ, opname, operands, name, flags)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mInstruction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNamedValue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_HasMetadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mInstruction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBlock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\llvmlite\\ir\\values.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, parent, type, name)\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\llvmlite\\ir\\values.py\u001b[0m in \u001b[0;36m_set_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         name = self.parent.scope.register(name,\n\u001b[1;32m--> 234\u001b[1;33m                                           deduplicate=self.deduplicate_name)\n\u001b[0m\u001b[0;32m    235\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\llvmlite\\ir\\_utils.py\u001b[0m in \u001b[0;36mregister\u001b[1;34m(self, name, deduplicate)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeduplicate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdeduplicate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeduplicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_used\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mDuplicatedNameError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\llvmlite\\ir\\_utils.py\u001b[0m in \u001b[0;36mdeduplicate\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mident\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_basenamemap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_basenamemap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mident\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"{0}.{1}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mident\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mnist=pd.read_csv(\"mnist.csv\")\n",
    "musk=pd.read_csv(\"musk.csv\")\n",
    "optdigit=pd.read_csv(\"optdigits.csv\")\n",
    "pendigits=pd.read_csv(\"pendigits.csv\")\n",
    "satimage_2=pd.read_csv(\"satimage-2.csv\")\n",
    "dataset={\"mnist\":mnist,\"musk\":musk,\"optdigit\":optdigit,\"pendigits\":pendigits,\"satimage_2\":satimage_2}\n",
    "\n",
    "\n",
    "table_roc=pd.DataFrame()\n",
    "table_recall=pd.DataFrame()\n",
    "\n",
    "for name,data in dataset.items():\n",
    "    print(\"第\",name ,'個資料處理中....')\n",
    "    print(\"\")\n",
    "\n",
    "    #降維\n",
    "    import umap\n",
    "    reducer = umap.UMAP(random_state=69,n_neighbors=20, min_dist=0.3, n_components=2, metric='manhattan')\n",
    "    data_umap = reducer.fit_transform(data.iloc[:,0:-1])\n",
    "    \n",
    "    #split train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,0:-1],data[\"outlier\"], test_size=0.06, random_state=69)\n",
    "    X_train_umap, X_test_umap, y_train, y_test = train_test_split(data_umap,data[\"outlier\"], test_size=0.06, random_state=69)\n",
    "    \n",
    "    # standardizing data for processing\n",
    "    X_train_norm, X_test_norm = standardizer(X_train, X_test)\n",
    "        \n",
    "    #split train/valid\n",
    "    X, X_valid_norm, y, y_valid = train_test_split(X_train_norm,y_train, test_size=0.25, random_state=time)\n",
    "    X_umap, X_valid_norm_umap, y, y_valid = train_test_split(X_train_umap,y_train, test_size=0.25, random_state=time)\n",
    "\n",
    "    # count outliers_ratio\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    outliers_fraction=counts[1]/counts[0]\n",
    "\n",
    "    classifiers = {'One-class SVM (OCSVM)':OCSVM(contamination=outliers_fraction),\n",
    "                'Local Outlier Factor (LOF)': LOF(contamination=outliers_fraction,n_neighbors=110),\n",
    "                'Isolation Forest': IForest(contamination=outliers_fraction,n_estimators=200,random_state=69),\n",
    "                'AutoEncoder': AutoEncoder(hidden_neurons=[2, 32,64,64, 32, 2],contamination=outliers_fraction,random_state=69,epochs=150),\n",
    "                'DeepSVDD':DeepSVDD(hidden_neurons=[data.shape[1],data.shape[1]*20], contamination=outliers_fraction,random_state=69,epochs=100,validation_size=0.05) }\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "\n",
    "        # Build the Model\n",
    "        clf_name = clf_name\n",
    "        clf = clf\n",
    "\n",
    "        # Fit detector\n",
    "        clf.fit(X[y == 0])\n",
    "        # valid data\n",
    "        y_pred = clf.predict(X) \n",
    "        y_scores = clf.decision_function(X)\n",
    "\n",
    "        roc_list.append(evaluate_print(clf_name, y, y_scores)[0])\n",
    "        recall_list.append(evaluate_print(clf_name, y, y_scores)[1])\n",
    "\n",
    "        temp_df = pd.DataFrame(roc_list)\n",
    "        temp_df.index = classifiers.keys()\n",
    "        roc_df = pd.concat([roc_df, temp_df], axis=1)\n",
    "\n",
    "        temp_df = pd.DataFrame(recall_list)\n",
    "        temp_df.index = classifiers.keys()\n",
    "        recall_df = pd.concat([recall_df, temp_df], axis=1)\n",
    "        \n",
    "    #average 5 times \n",
    "    table_roc=pd.concat([table_roc, roc_df.mean(axis=1)], axis=1)\n",
    "    table_recall=pd.concat([table_recall,recall_df.mean(axis=1)], axis=1)\n",
    "\n",
    "table_roc.columns=['mnist','musk','optdigits','pendigits','satimage-2']\n",
    "table_recall.columns=['mnist','musk','optdigits','pendigits','satimage-2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3b83af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
